{
  "arxiv:2602.17270": {
    "story_id": "arxiv:2602.17270",
    "title_zh": "Unified Latents (UL)：如何訓練您的 Latents",
    "summary_zh": "我們提出了 Unified Latents (UL)，這是一個用於學習 latent representations 的框架，其由 diffusion prior 共同正則化並由 diffusion model 解碼。透過將 encoder 的輸出雜訊與 prior 的最小雜訊水平連結起來，我們獲得了一個簡單的訓練目標，該目標為 latent bitrate 提供了嚴格的上限。在 ImageNet-512 上，我們的方法實現了 1.4 的競爭性 FID，並具有高重建品質 (PSNR)，同時比在 Stable Diffusion latents 上訓練的模型需要更少的訓練 FLOPs。在 Kinetics-600 上，我們創下了新的 state-of-the-art FVD 1.3。"
  },
  "arxiv:2602.17259": {
    "story_id": "arxiv:2602.17259",
    "title_zh": "FRAPPE：透過多重未來表徵對齊將世界建模注入通用策略",
    "summary_zh": "使 VLA models 能夠預測環境動態，即 world modeling，已被認為對於改進機器人推理和泛化至關重要。然而，目前的S方法面臨兩個主要問題：1. 訓練目標迫使模型過度強調 pixel-level reconstruction，這限制了 semantic learning 和泛化；2. 在推理過程中依賴預測的 future observations 通常會導致錯誤累積。為了解決這些挑戰，我們引入了 Future Representation Alignment via Parallel Progressive Expansion (FRAPPE)。我們的方法採用兩階段 fine-tuning 策略：在訓練中期，模型學習預測未來觀察的 latent representations；在訓練後期，我們並行擴展計算工作量，並同時將表示與多個不同的 visual foundation models 對齊。透過顯著提高 fine-tuning 效率並減少對 action-annotated data 的依賴，FRAPPE 為增強通用機器人策略中的 world-awareness 提供了一個可擴展且數據高效的途徑。在 RoboTwin benchmark 和真實世界任務上的實驗表明，FRAPPE 優於 state-of-the-art 方法，並在 long-horizon 和未見情境中表現出強大的泛化能力。"
  },
  "arxiv:2602.17004": {
    "story_id": "arxiv:2602.17004",
    "title_zh": "Arcee Trinity Large 技術報告",
    "summary_zh": "我們提出了 Arcee Trinity Large 的技術報告，這是一個稀疏的 Mixture-of-Experts 模型，總參數為 400B，每個 token 激活 13B。此外，我們報告了 Trinity Nano 和 Trinity Mini，其中 Trinity Nano 總參數為 6B，每個 token 激活 1B；Trinity Mini 總參數為 26B，每個 token 激活 3B。這些模型的現代架構包括 interleaved local and global attention、gated attention、depth-scaled sandwich norm 以及用於 Mixture-of-Experts 的 sigmoid routing。對於 Trinity Large，我們還引入了一種新的 MoE load balancing 策略，名為 Soft-clamped Momentum Expert Bias Updates (SMEBU)。我們使用 Muon optimizer 訓練這些模型。所有三個模型都以零 loss spikes 完成訓練。Trinity Nano 和 Trinity Mini 在 10 兆個 token 上進行了 pre-trained，Trinity Large 在 17 兆個 token 上進行了 pre-trained。模型檢查點可在 https://huggingface.co/arcee-ai 獲取。"
  },
  "arxiv:2602.16932": {
    "story_id": "arxiv:2602.16932",
    "title_zh": "RankEvolve：透過 LLM 驅動的演化自動發現檢索演算法",
    "summary_zh": "諸如 BM25 和帶有 Dirichlet smoothing 的 query likelihood 等檢索演算法仍然是強大而高效的第一階段 rankers，但改進主要依賴於參數調整和人類直覺。我們研究了由評估器和 evolutionary search 指導的 large language model 是否可以自動發現改進的 lexical retrieval algorithms。我們引入了 RankEvolve，這是一個基於 AlphaEvolve 的 program evolution 設置，其中候選 ranking algorithms 表示為 execut。"
  },
  "arxiv:2602.16704": {
    "story_id": "arxiv:2602.16704",
    "title_zh": "強化快速權重與下一序列預測",
    "summary_zh": "快速權重架構為 attention-based transformers 提供了一種有前景的替代方案，用於 long-context modeling，它無論上下文長度如何，都能保持恆定的記憶體開銷。然而，其潛力受到 next-token prediction (NTP) 訓練範式的限制。NTP 優化單個 token 的預測，而忽略了前綴之後多個 token 的語義連貫性。因此，動態更新其參數以儲存上下文資訊的 fast weight models，學習到的 suboptimal representations 無法捕捉 long-range dependencies。我們引入了 REFINE (Reinforced Fast weIghts with Next sEquence prediction)，這是一個 reinforcement learning 框架，用於在 next-sequence prediction (NSP) 目標下訓練 fast weight models。REFINE 根據 prediction entropy 選擇資訊豐富的 token 位置，生成 multi-token rollouts，分配 self-supervised sequence-level rewards，並使用 group relative policy optimization (GRPO) 優化模型。REFINE 適用於 pre-trained language models 的整個訓練生命週期：mid-training、post-training 和 test-time training。我們在 LaCT-760M 和 DeltaNet-1.3B 上的實驗表明，REFINE 在 needle-in-a-haystack retrieval、long-context question answering 以及 LongBench 中的多種任務上始終優於帶有 NTP 的 supervised fine-tuning。REFINE 為改進 fast weight architectures 中的 long-context modeling 提供了一個有效且通用的框架。"
  },
  "arxiv:2602.16317": {
    "story_id": "arxiv:2602.16317",
    "title_zh": "CADEvolve：透過程式演化創建真實的 CAD",
    "summary_zh": "Computer-Aided Design (CAD) 為工程和製造提供快速、可編輯的建模。近期 AI 的進展使得各種 CAD 任務的完全自動化成為可能。然而，進展受數據瓶頸所限：公共語料庫大多包含 sketch-extrude 序列，缺乏複雜操作、多操作組合和設計意圖，因此阻礙了有效的 fine-tuning。嘗試使用 frozen VLMs 繞過此問題，通常會因當前 foundation models 中有限的 3D grounding 而產生簡單或無效的程式。我們提出了 CADEvolve，一個基於演化的流程和數據集，它從簡單的 primitives 開始，並透過 VLM 導向的編輯和驗證，逐步將 CAD 程式發展到工業級複雜度。結果是 8k 個複雜零件，表示為可執行的 CadQuery 參數化產生器。經過多階段後處理和增強，我們獲得了一個統一的數據集，包含 1.3m 個腳本，配對渲染的幾何形狀並演練了完整的 CadQuery 操作集。在 CADEvolve 上 fine-tuned 的 VLM 在 DeepCAD、Fusion 360 和 MCB benchmarks 上的 Image2CAD 任務中取得了 state-of-the-art 的結果。"
  },
  "arxiv:2602.17560": {
    "story_id": "arxiv:2602.17560",
    "title_zh": "ODECteer：一個基於 ODE 的統一 LLM 對齊引導框架",
    "summary_zh": "Activation steering，或稱 representation engineering，提供了一種輕量級的方法，透過在 inference time 操縱大型語言模型（LLMs）的內部 activations 來實現對齊。然而，當前方法存在兩個主要限制：\\textit{(i)} 缺乏一個統一的理論框架來指導 steering directions 的設計，以及 \\textit{(ii)} 過度依賴 \\textit{one-step steering}，其未能捕捉 activation distributions 的複雜模式。在這項工作中，我們提出"
  },
  "arxiv:2602.17127": {
    "story_id": "arxiv:2602.17127",
    "title_zh": "實驗室驅動對齊簽名的出現：用於審計生成式 AI 中潛在偏差和複合風險的心理測量框架",
    "summary_zh": "隨著 Large Language Models (LLMs) 從獨立的聊天介面轉變為 multi-agent systems 中的基礎推理層和 recursive evaluation loops (LLM-as-a-judge)，檢測持久的、供應商層級的行為簽名成為安全和治理的關鍵要求。傳統的 benchmarks 衡量暫時性的任務準確性，但未能捕捉穩定、潛在的響應策略——那些在訓練和對齊過程中嵌入的、「主導心態」，它們超越了個體"
  },
  "arxiv:2602.16980": {
    "story_id": "arxiv:2602.16980",
    "title_zh": "發現在語言模型中 PII 洩漏的通用 Activation Directions",
    "summary_zh": "現代語言模型展現出豐富的內部結構，然而對於隱私敏感行為，例如 personally identifiable information (PII) 洩漏，如何在它們的 hidden states 中被表示和調節，人們知之甚少。我們提出了 UniLeak，一個 mechanistic-interpretability 框架，它識別了 universal activation directions：模型 residual stream 中潛在的方向，其在 inference time 的線性添加一致地增加了跨 prompts 生成 PII 的可能性。"
  },
  "arxiv:2602.16943": {
    "story_id": "arxiv:2602.16943",
    "title_zh": "Mind the GAP：LLM Agents 中的文本安全並不等同於工具調用安全",
    "summary_zh": "部署為 agents 的大型語言模型越來越多地透過 tool calls 與外部系統互動——這些行為具有現實世界的後果，而單純的文本輸出不具備此類後果。然而，安全評估絕大多數測量的是文本層級的拒絕行為，留下了一個關鍵問題未解答：抑制有害文本的對齊是否也抑制有害行為？我們介紹了 GAP benchmark，這是一個系統的評估框架，它衡量文本層級安全與 too 之間的差異。"
  },
  "arxiv:2602.16901": {
    "story_id": "arxiv:2602.16901",
    "title_zh": "AgentLAB: 針對長週期攻擊評估 LLM Agents 的基準測試",
    "summary_zh": "LLM agents 正日益被部署到長週期、複雜的環境中以解決具有挑戰性的問題，但這種擴展也使它們面臨長週期攻擊。這些攻擊利用多輪使用者-代理-環境互動來達成在單輪設定中不可行的目標。為了衡量代理對此類風險的脆弱性，我們提出了 AgentLAB，這是第一個專門用於評估 LLM agent 對自適應長週期攻擊脆弱性的基準測試。目前，AgentLAB 支援五種新型攻擊。"
  },
  "arxiv:2602.16835": {
    "story_id": "arxiv:2602.16835",
    "title_zh": "NeST: 用於 LLM 安全的神經元選擇性調整",
    "summary_zh": "安全對齊對於大型語言模型 (LLMs) 的負責任部署至關重要。然而，現有方法通常依賴於重量級的 fine-tuning，這在跨模型家族的更新、審核和維護方面成本高昂。完整的 fine-tuning 會產生大量的計算和儲存開銷，而參數效率方法（例如 LoRA）則以犧牲效率換取不一致的安全增益和對設計選擇的敏感性。諸如 `circuit breakers` 等安全干預機制可在不修改模型權重的情況下減少不安全輸出，但它們無法直接塑造或保留控制安全行為的內部表示。這些限制阻礙了快速可靠的安全更新，尤其是在模型頻繁演進或必須適應新策略和領域的環境中。我們提出了 NeST，一個輕量級、結構感知的安全對齊框架，它透過選擇性地調整一小部分與安全相關的神經元，同時凍結模型的其餘部分來強化拒絕行為。NeST 透過對功能上連貫的安全神經元進行聚類並在每個聚類中強制執行共享更新，將參數更新與安全行為的內部組織對齊，從而實現有針對性且穩定的安全適應，而無需廣泛的模型修改或推論時間開銷。我們將 NeST 與三個主要基準線進行了比較：完整 fine-tuning、基於 LoRA 的 fine-tuning 和 `circuit breakers`，評估了涵蓋多個模型家族和大小的 10 個開源 LLMs。在所有評估的模型中，NeST 將攻擊成功率從平均 44.5% 降低到 4.36%，相當於不安全生成減少了 90.2%，同時平均僅需要 0.44 百萬個可訓練參數。與完整 fine-tuning 相比，這使得更新參數減少了 17,310 倍，相對於 LoRA 減少了 9.25 倍，同時持續實現了更強的安全對齊性能。"
  },
  "arxiv:2602.16699": {
    "story_id": "arxiv:2602.16699",
    "title_zh": "Calibrate-Then-Act: LLM Agents 中的成本感知探索",
    "summary_zh": "LLMs 正日益被用於解決複雜問題，這些問題不一定能透過單一回應來解決，而是需要與環境互動以獲取資訊。在這些情境中，LLMs 必須推理何時停止探索並提交答案所固有的成本-不確定性權衡。例如，在程式設計任務中，如果 LLM 對於程式碼片段的正確性不確定，它應該測試該程式碼；編寫測試的成本不為零，但通常低於犯錯的成本。在這項工作中，我們展示了我們可以誘導 LLMs 明確推理如何平衡這些成本-不確定性權衡，然後執行更優化的環境探索。我們將多個任務（包括資訊檢索和程式設計）形式化為不確定性下的序列決策問題。每個問題都有潛在的環境狀態，可以透過傳遞給 LLM agent 的先驗進行推理。我們引入了一個名為 Calibrate-Then-Act (CTA) 的框架，我們將此額外上下文提供給 LLM，使其能夠更優化地行動。即使在基準線和 CTA 的 RL 訓練下，這種改進也得以保留。我們在資訊搜尋型 QA 和簡化程式設計任務上的結果表明，透過 CTA 明確成本效益權衡可以幫助 agents 發現更優化的決策策略。"
  },
  "arxiv:2602.16666": {
    "story_id": "arxiv:2602.16666",
    "title_zh": "邁向 AI 代理可靠性科學",
    "summary_zh": "AI agents 正日益被部署來執行重要任務。儘管標準 `benchmarks` 上不斷提高的準確性分數表明了快速進展，但許多 agents 在實踐中仍然持續失敗。這種差異突顯了當前評估的一個基本限制：將代理行為壓縮為單一成功指標掩蓋了關鍵的操作缺陷。值得注意的是，它忽略了 agents 是否在不同運行中保持一致行為、能否承受擾動、是否可預測地失敗，或者錯誤嚴重性是否有限。基於安全關鍵工程，我們透過提出十二個具體指標來提供一個整體性能概況，這些指標將代理可靠性分解為四個關鍵維度：一致性、穩健性、可預測性和安全性。在兩個互補的 `benchmarks` 上評估 14 個代理模型後，我們發現最近的能力提升僅在可靠性方面產生了小幅改進。透過揭示這些持續存在的限制，我們的指標補充了傳統評估，同時提供了用於推理 agents 如何表現、退化和失敗的工具。"
  },
  "arxiv:2602.16301": {
    "story_id": "arxiv:2602.16301",
    "title_zh": "透過情境內隊友推斷實現多代理合作",
    "summary_zh": "在 `multi-agent reinforcement learning` 中，實現自利代理之間的合作仍然是一個基本挑戰。最近的研究表明，在「學習感知」代理之間可以誘導相互合作，這些代理會考慮並塑造其隊友的學習動態。然而，現有方法通常依賴於硬編碼的、通常不一致的關於隊友學習規則的假設，或者強制將在快速時間尺度上更新的「天真學習者」與觀察這些更新的「元學習者」嚴格分離。在此，我們證明序列模型的 `in-context learning` 能力允許隊友學習意識，而無需硬編碼假設或明確的時間尺度分離。我們展示了針對多樣化隊友分佈訓練序列模型代理自然會誘導 `in-context best-response strategies`，在快速情節內時間尺度上有效充當學習演算法。我們發現，在先前工作中識別出的合作機制（即敲詐勒索的脆弱性驅動相互塑造）在這個設定中自然浮現：`in-context adaptation` 使得代理易受敲詐勒索，而隨之而來的塑造對手 `in-context learning` 動態的相互壓力轉化為合作行為的學習。我們的結果表明，序列模型上的標準 `decentralized reinforcement learning` 結合隊友多樣性為學習合作行為提供了一條可擴展的途徑。"
  },
  "arxiv:2602.16173": {
    "story_id": "arxiv:2602.16173",
    "title_zh": "從人類回饋中學習個性化代理",
    "summary_zh": "現代 AI agents 功能強大，但往往無法與個別用戶獨特且不斷演變的偏好保持一致。先前的做法通常依賴於靜態數據集，要麼在互動歷史上訓練隱式偏好模型，要麼將用戶資料編碼到外部記憶體中。然而，這些方法在面對新用戶以及隨時間變化的偏好時會遇到困難。我們引入了 Personalized Agents from Human Feedback (PAHF)，這是一個用於持續個性化的框架，其中 agents 使用明確的每用戶記憶體從即時互動中進行線上學習。PAHF 運作一個三步驟循環：(1) 尋求預行動澄清以解決歧義，(2) 將行動基於從記憶體中檢索到的偏好，以及 (3) 整合行動後回饋以在偏好漂移時更新記憶體。為了評估這項能力，我們開發了一個四階段協議和兩個基準測試，分別用於 embodied manipulation 和 online shopping 領域。這些基準量化了 agent 從頭開始學習初始偏好並隨後適應角色轉變的能力。我們的理論分析和實證結果表明，整合明確記憶體與雙重回饋通道至關重要：PAHF 學習速度顯著更快，並且始終優於 no-memory 和 single-channel baselines，從而減少了初始個性化錯誤並實現了對偏好轉變的快速適應。"
  },
  "arxiv:2602.16705": {
    "story_id": "arxiv:2602.16705",
    "title_zh": "學習用於開放詞彙視覺移動操作的類人機器人末端執行器控制",
    "summary_zh": "類人機器人在野外對任意物體進行視覺移動操作 (visual loco-manipulation) 需要精確的 end-effector (EE) 控制，以及透過視覺輸入（例如 RGB-D images）對場景進行泛化理解。現有方法基於 real-world imitation learning，由於難以收集大規模訓練數據集而表現出有限的泛化能力。本文提出了一種新的範式 HERO，用於類人機器人的物體移動操作，它結合了 large vision models 強大的泛化能力和 open-vocabulary 理解能力，以及來自模擬訓練的強大控制性能。我們透過設計一種精確的 residual-aware EE tracking policy 來實現這一目標。這種 EE tracking policy 結合了 classical robotics 和 machine learning。它使用了 a) inverse kinematics 將殘餘的 end-effector 目標轉換為參考軌跡，b) 一個學習到的 neural forward model 用於精確的 forward kinematics，c) goal adjustment，以及 d) replanning。這些創新共同幫助我們將 end-effector 追蹤誤差減少了 3.2 倍。我們利用這個精確的 end-effector tracker 構建了一個模組化系統用於 loco-manipulation，其中我們使用 open-vocabulary large vision models 以實現強大的視覺泛化能力。我們的系統能夠在多樣化的真實世界環境中運行，從辦公室到咖啡店，機器人能夠可靠地操作高度從 43 公分到 92 公分不等的各種日常物品（例如馬克杯、蘋果、玩具）。在模擬和現實世界中進行的系統化模組化和 end-to-end 測試證明了我們所提出設計的有效性。我們相信本文的進展可以為訓練類人機器人與日常物品互動開闢新的途徑。"
  },
  "arxiv:2602.17658": {
    "story_id": "arxiv:2602.17658",
    "title_zh": "MARS: 帶有自精煉的邊距感知獎勵建模",
    "summary_zh": "Reward modeling 是現代對齊管道（包括 RLHF 和 RLAIF）的核心組成部分，支撐著包括 PPO 和 TRPO 在內的 policy optimization 方法。然而，訓練可靠的 reward models 嚴重依賴於人類標註的偏好數據，這些數據成本高昂且有限，這促使了數據增強的使用。現有的增強方法通常在 representation 或 semantic level 上操作，並且對 reward model 的估計難度不敏感。在本文中，我們提出了 M"
  },
  "arxiv:2602.17544": {
    "story_id": "arxiv:2602.17544",
    "title_zh": "透過可重用性和可驗證性評估 Chain-of-Thought 推理",
    "summary_zh": "在用於搜尋和排序等任務的 multi-agent IR pipelines 中，基於 LLM 的 agents 以 Chain-of-Thought (CoT) 的形式相互交換中間推理。目前的 CoT 評估狹隘地專注於目標任務的準確性。然而，這個指標未能評估推理過程本身的品質或實用性。為了解決這個限制，我們引入了兩個新穎的衡量標準：reusability 和 verifiability。我們使用 Thinker-Executor 框架將 CoT 生成與執行解耦。Reusa"
  },
  "arxiv:2602.17483": {
    "story_id": "arxiv:2602.17483",
    "title_zh": "LLM 將您的姓名與什麼相關聯？個人資料的人本黑箱審計",
    "summary_zh": "Large language models (LLMs) 以及基於它們的 conversational agents 在 pre-training 期間和用戶互動期間都會接觸到 personal data (PD)。先前的工作表明 PD 可能會重新浮現，但用戶卻不了解模型將特定資訊與其身份關聯的強度。我們審計了八個 LLM（3 個 open-source；5 個 API-based，包括 GPT-4o）中的 PD，並引入了 LMP2 (Language Model Privacy Probe)，這是一個以人為本、保護隱私的審計工具，透過兩項形成性研究進行了完善。"
  },
  "arxiv:2602.17162": {
    "story_id": "arxiv:2602.17162",
    "title_zh": "JEPA-DNA：透過聯合嵌入預測架構為基因組基礎模型奠定基礎",
    "summary_zh": "基因組基礎模型 (GFMs) 主要依賴 Masked Language Modeling (MLM) 或 Next Token Prediction (NTP) 來學習生命的語言。儘管這些範式擅長捕捉局部基因組語法和細粒度 motif 模式，但它們往往未能捕捉到更廣泛的功能性上下文，導致其表示法缺乏全球生物學視角。我們引入了 JEPA-DNA，這是一種新穎的預訓練框架，它將 Joint-Embedding Predictive Architecture (JEPA) 與"
  },
  "arxiv:2602.16977": {
    "story_id": "arxiv:2602.16977",
    "title_zh": "大型語言模型的故障關閉對齊",
    "summary_zh": "我們發現當前大型語言模型 (LLM) 對齊存在結構性弱點：現代拒絕機制是 fail-open 的。儘管現有方法在多個潛在特徵中編碼了拒絕行為，但透過 prompt-based jailbreaks 抑制單一主導特徵會導致對齊崩潰，導致不安全的生成。受此啟發，我們提出 fail-closed alignment 作為 LLM 穩健安全性的設計原則：拒絕機制即使在部分情況下也應保持有效"
  },
  "arxiv:2602.16902": {
    "story_id": "arxiv:2602.16902",
    "title_zh": "LLM-WikiRace：基於真實世界知識圖譜的長期規劃與推理基準測試",
    "summary_zh": "我們介紹了 LLM-Wikirace，這是一個用於評估大型語言模型 (LLMs) 規劃、推理和世界知識的基準測試。在 LLM-Wikirace 中，模型必須逐步有效地導航 Wikipedia 超連結，從給定來源到達目標頁面，這需要前瞻性規劃以及對現實世界中概念如何連接進行推理的能力。我們評估了一系列廣泛的開源和閉源模型，包括 Gemini-3, GPT-5 和 Claude Opus 4.5，它們取得了最強的結"
  },
  "arxiv:2602.16839": {
    "story_id": "arxiv:2602.16839",
    "title_zh": "透過漸進式思維編碼有效訓練大型推理模型",
    "summary_zh": "大型推理模型 (LRMs) 在複雜問題上表現出色，但在效率方面面臨一個關鍵障礙：強化學習 (RL) 訓練需要長時間的 rollout 來獲取基於結果的獎勵，其中 autoregressive decoding 佔用了大量的時間和記憶體。儘管 sliding-window cache 策略可以限制記憶體，但它們會破壞長上下文推理並降低性能。我們引入了 Progressive Thought Encoding，這是一種參數高效的 fine-tuning 方法，它使 LRMs 能夠在固定"
  },
  "arxiv:2602.16662": {
    "story_id": "arxiv:2602.16662",
    "title_zh": "評估數百個 LLM 代理的集體行為",
    "summary_zh": "隨著由 LLM 驅動的自主代理越來越多地部署到社會中，了解它們在社會困境中的集體行為變得至關重要。我們引入了一個評估框架，其中 LLMs 生成編碼為演算法的策略，這使得在部署前進行檢查，並能擴展到數百個代理的群體——這比以前的工作要大得多。我們發現，當代理優先考慮時，較新的模型與較舊的模型相比，往往會產生更差的社會結果"
  },
  "arxiv:2602.16512": {
    "story_id": "arxiv:2602.16512",
    "title_zh": "Framework of Thoughts: 基於鏈、樹和圖的動態優化推理基礎框架",
    "summary_zh": "Chain of Thought、Tree of Thoughts 和 Graph of Thoughts 等提示方案可以顯著增強大型語言模型的推理能力。然而，大多數現有方案要求用戶定義靜態的、特定於問題的推理結構，這些結構缺乏對動態或未見問題類型的適應性。此外，這些方案在超參數、提示、運行時間和提示成本方面往往優化不足。為了克服這些限制，我們引入了 Framework of"
  },
  "arxiv:2602.16493": {
    "story_id": "arxiv:2602.16493",
    "title_zh": "MMA: 多模態記憶代理",
    "summary_zh": "長時程多模態代理依賴於外部記憶；然而，基於相似性的檢索常常會浮現過時、低可信度或衝突的項目，這可能觸發過度自信的錯誤。我們提出了 Multimodal Memory Agent (MMA)，它通過結合來源可信度、時間衰減和衝突感知網絡共識，為每個檢索到的記憶項目分配一個動態可靠性分數，並使用此信號在支援不足時重新加權證據並棄權。我們還引入了 MMA-Bench，這是一個透過編程生成的基準測試，用於信念動態，並具有受控的說話者可靠性和結構化的文本-視覺矛盾。使用這個框架，我們揭示了「Visual Placebo Effect」，揭示了基於 RAG 的代理如何從基礎模型繼承潛在的視覺偏差。在 FEVER 上，MMA 在匹配基準準確度的同時將變異數減少了 35.2%，並提高了選擇性效用；在 LoCoMo 上，一個側重安全的配置提高了可操作的準確度並減少了錯誤答案；在 MMA-Bench 上，MMA 在 Vision 模式下達到 41.18% 的 Type-B 準確度，而基準在相同協議下崩潰到 0.0%。代碼：https://github.com/AIGeeksGroup/MMA。"
  },
  "arxiv:2602.16444": {
    "story_id": "arxiv:2602.16444",
    "title_zh": "RoboGene: 透過多樣性驅動的代理框架提升 VLA 預訓練以進行真實世界任務生成",
    "summary_zh": "通用機器人操作的追求受到多樣化真實世界互動數據稀缺的阻礙。與從視覺或語言網絡收集數據不同，機器人數據收集是一個主動過程，會產生高昂的物理成本。因此，自動化任務策劃以最大化數據價值仍然是一個關鍵但未被充分探索的挑戰。現有手動方法不可擴展且偏向常見任務，而現成的基礎模型常常產生幻覺 phys"
  },
  "arxiv:2602.16435": {
    "story_id": "arxiv:2602.16435",
    "title_zh": "透過多代理強化學習進行因果引導的自動特徵工程",
    "summary_zh": "自動特徵工程 (AFE) 使 AI 系統能夠自主地從原始表格數據中構建高效用表示。然而，現有的 AFE 方法依賴統計啟發法，產生在分佈偏移下失效的脆弱特徵。我們引入了 CAFE，一個將 AFE 重新定義為因果引導的順序決策過程的框架，將因果發現與強化學習驅動的特徵構建相結合。第一階段學習了一個稀疏的有向無環圖，覆蓋 featu"
  },
  "arxiv:2602.16138": {
    "story_id": "arxiv:2602.16138",
    "title_zh": "IRIS: 透過推論時眼跳在大型視覺-語言模型中解決開放式 VQA 的意圖歧義",
    "summary_zh": "我們引入了 IRIS (Intent Resolution via Inference-time Saccades)，這是一種新穎的免訓練方法，它使用即時眼動追蹤數據來解決開放式 VQA 中的歧義。透過一項包含 500 個獨特圖像-問題對的全面用戶研究，我們證明了參與者開始口頭提問時最接近的注視點對於大型 VLM 中的消歧最具信息量，使模糊問題的回應準確度增加一倍以上（從 35.2% 提高到 77.2%"
  },
  "arxiv:2602.16760": {
    "story_id": "arxiv:2602.16760",
    "title_zh": "適用於廣域網路中 Large Language Models 的具隱私意識 Split Inference 搭配 Speculative Decoding",
    "summary_zh": "我們提出了一個實用的系統，用於具隱私意識的 large language model (LLM) inference，該系統將一個 transformer 劃分在一個受信任的 local GPU 和一個不受信任的 cloud GPU 之間，僅透過網路傳輸 intermediate activations。我們的系統解決了在高延遲 wide-area networks (WANs) 上進行 autoregressive LLM decoding 的獨特挑戰，其貢獻包括：(1) 一種 asymmetric layer split，其中 embedding 和 unembedding layers 保持在本地，確保原始 tokens 永遠不會離開受信任的設備；(2)"
  },
  "arxiv:2602.16438": {
    "story_id": "arxiv:2602.16438",
    "title_zh": "內部公平性動態：Targeted LLM Alignment 中的 Bias Spillover 效應",
    "summary_zh": "傳統的 large language model (LLM) fairness alignment 主要關注於減輕單一 sensitive attributes 上的偏見，卻忽略了公平性作為一個本質上多維且與上下文相關的價值。這種方法可能會導致系統在實現狹隘的 fairness metrics 的同時，加劇非目標屬性上的差異，這種現象被稱為 bias spillover。儘管 bias spillover 在 machine learning 中已被廣泛研究，但在 LLM alignment 領域仍嚴重缺乏探索。"
  },
  "arxiv:2602.16424": {
    "story_id": "arxiv:2602.16424",
    "title_zh": "Agent 間通訊的可驗證語義",
    "summary_zh": "Multiagent AI systems 需要一致的通訊，但我們缺乏驗證 agents 對所用術語是否共享相同理解的方法。Natural language 雖然可解釋，但容易受到 semantic drift 的影響，而 learned protocols 雖然高效但卻不透明。我們提出了一種基於 stimulus-meaning model 的 certification protocol，其中 agents 會在共享的可觀察事件上進行測試，並且如果實證分歧低於統計閾值，則術語會被認證。在此 protocol 中，agents"
  },
  "arxiv:2602.16813": {
    "story_id": "arxiv:2602.16813",
    "title_zh": "透過 Continuous Denoising 實現一步式 Language Modeling",
    "summary_zh": "基於 discrete diffusion 的 Language models 因其潛力能比 autoregressive models 提供更快的生成速度而引起了廣泛關注。然而，在實踐中，它們在 few-step 階段卻表現出樣本品質的急劇下降，未能實現這一承諾。在此，我們展示了利用 flow-based continuous denoising 的 language models 可以在品質和速度方面超越 discrete diffusion。透過重新審視 discrete modalities 上 flows 的基本原理，我們構建了一個"
  },
  "arxiv:2602.16485": {
    "story_id": "arxiv:2602.16485",
    "title_zh": "Team of Thoughts：透過 Orchestrated Tool Calling 對 Agentic Systems 進行高效的 Test-time Scaling",
    "summary_zh": "現有的 Multi-Agent Systems (MAS) 通常依賴於靜態、同質的 model configurations，這限制了它們利用不同 post-trained models 獨特優勢的能力。為了解決這個問題，我們引入了 Team-of-Thoughts，這是一種新穎的 MAS architecture，它透過 orchestrator-tool paradigm 利用 heterogeneous agents 的互補能力。我們的框架引入了兩個關鍵機制來優化性能：(1) 一種 orchestrator calibration scheme，用於識別具有"
  },
  "arxiv:2602.17526": {
    "story_id": "arxiv:2602.17526",
    "title_zh": "影響焦慮：Transformer Attention Heads 中的 Bloom Filters",
    "summary_zh": "部分 Transformer attention heads 似乎扮演著成員資格測試器 (membership testers) 的角色，專注於回答「這個 token 之前是否在上下文 (context) 中出現過？」這個問題。我們在四種語言模型（GPT-2 small, medium, 和 large；Pythia-160M）中識別出這些 heads，並展示它們形成了一個成員資格測試策略的光譜。其中兩個 heads (GPT-2 small 中的 L0H1 和 L0H5) 即使在 180 個獨特的上下文 token 下，也能作為高精準度的成員資格過濾器 (high-precision membership filters)，其誤報率 (false positive rates) 僅為 0-4%。"
  },
  "arxiv:2602.16984": {
    "story_id": "arxiv:2602.16984",
    "title_zh": "黑箱安全評估的基本限制：來自潛在上下文條件化 (Latent Context Conditioning) 的資訊理論和計算障礙",
    "summary_zh": "AI 系統的 Black-box safety evaluation 假設模型在測試分佈 (test distributions) 上的行為能夠可靠地預測部署性能 (deployment performance)。我們透過潛在上下文條件化策略 (latent context-conditioned policies) 將此假設形式化並提出挑戰——這些模型的輸出取決於在評估時罕見但在部署時普遍存在的未觀測內部變數 (unobserved internal variables)。我們確立了基本限制，表明沒有任何 black-box evaluator 能夠可靠地估計此類模型的部署風險 (deployment risk)。(1) 被動評估 (Passive evaluation)：對於評估者來說，"
  },
  "arxiv:2602.17664": {
    "story_id": "arxiv:2602.17664",
    "title_zh": "Diffusion Language Models 的 Sink-Aware Pruning",
    "summary_zh": "Diffusion Language Models (DLMs) 由於迭代去噪 (iterative denoising) 而產生高昂的推理成本 (inference cost)，這促使了對高效 pruning 的需求。現有的 pruning 啟發式方法 (pruning heuristics) 主要繼承自 autoregressive (AR) LLMs，通常會保留 attention sink tokens，因為 AR sinks 作為穩定的全局錨點 (stable global anchors)。我們證明了這個假設對於 DLMs 不成立：attention-sink 位置在整個生成軌跡 (full generation trajectory) 中表現出顯著更高的變異性（衡量標準是主導 sink 位置如何隨時間推移而變化）。"
  },
  "arxiv:2602.17616": {
    "story_id": "arxiv:2602.17616",
    "title_zh": "穩定異步：用於 LLMs 的變異數控制型 Off-Policy RL",
    "summary_zh": "Reinforcement learning (RL) 被廣泛用於改進大型語言模型在推理任務上的表現，而 asynchronous RL training 因其能提高端到端吞吐量 (end-to-end throughput) 而具有吸引力。然而，對於廣泛採用的無批評家策略梯度方法 (critic-free policy-gradient methods)，例如 REINFORCE 和 GRPO，高異步性會使策略梯度估計器 (policy-gradient estimator) 的變異數顯著$\textbf{更高}$：在過時的 rollout 上進行訓練會產生重尾重要性比率 (heavy-tailed importance ratios)，導致一小部分樣本主導更新。這加劇了"
  },
  "arxiv:2602.17598": {
    "story_id": "arxiv:2602.17598",
    "title_zh": "級聯等效假說 (Cascade Equivalence Hypothesis)：Speech LLMs 何時表現得像 ASR$\rightarrow$LLM Pipelines？",
    "summary_zh": "目前的 Speech LLMs 大多執行隱式 ASR：在可以從文字稿 (transcript) 解決的任務上，它們在行為和機制上與簡單的 Whisper$\to$LLM cascades 等效。我們首次透過跨四個 Speech LLMs 和六個任務的 matched-backbone testing 證明了這一點，同時控制了 LLM backbone。Ultravox 與其匹配的 cascade 在統計上無法區分 ($κ{=}0.93$)；logit lens 揭示了隱藏狀態 (hidden states) 中出現的字面文本；LEACE concept erasure 證實了文本表徵 (text represen)"
  },
  "arxiv:2602.17550": {
    "story_id": "arxiv:2602.17550",
    "title_zh": "MASPO：統一梯度利用、機率質量和訊號可靠性，實現穩健且樣本高效的LLM推理",
    "summary_zh": "現有的 Reinforcement Learning with Verifiable Rewards (RLVR) 演算法，例如 GRPO，依賴於僵化、均勻且對稱的信任區域機制，這與 Large Language Models (LLMs) 複雜的優化動態從根本上不符。在本文中，我們指出了這些方法中的三個關鍵挑戰：(1) 硬 clipping 的二元截斷導致的梯度利用效率低下，(2) 由於忽略了 t 而產生均勻比例約束導致的不敏感機率質量"
  },
  "arxiv:2602.17547": {
    "story_id": "arxiv:2602.17547",
    "title_zh": "KLong：訓練 LLM Agent 處理超長時程任務",
    "summary_zh": "本文介紹了 KLong，一個開源的 LLM Agent，旨在解決超長時程任務。其原則是首先透過 trajectory-splitting SFT 對模型進行冷啟動，然後透過漸進式 RL 訓練來擴展。具體來說，我們首先使用全面的 SFT 策略來激活基礎模型的 agentic 基本能力。接著，我們引入 Research-Factory，這是一個自動化流程，透過收集研究論文和建構評估標準來生成高品質的訓練資料。使用"
  },
  "arxiv:2602.17532": {
    "story_id": "arxiv:2602.17532",
    "title_zh": "單細胞基礎模型可解釋性的系統性評估揭示注意力捕捉的是共表達而非獨特的調控訊號",
    "summary_zh": "我們提出了一個系統性評估框架——包含三十七項分析、153 項統計測試、四種細胞類型、兩種擾動模式——用於評估單細胞基礎模型的機械可解釋性。將此框架應用於 scGPT 和 Geneformer，我們發現注意力模式編碼了具有層次特異性組織的結構化生物信息——早期層次中的 protein-protein interactions，晚期層次中的 transcriptional regulation——但這種結構並未提供額外的"
  },
  "arxiv:2602.17497": {
    "story_id": "arxiv:2602.17497",
    "title_zh": "結合大型語言模型的回溯式 In-Context Learning 用於時間信用分配",
    "summary_zh": "從自採樣數據和稀疏環境回饋中學習，仍然是訓練自我演化 agent 的一個基本挑戰。時間信用分配透過將稀疏回饋轉化為密集監督訊號來緩解這個問題。然而，以往的方法通常依賴於學習任務特定的價值函數來進行信用分配，這導致樣本效率低下和泛化能力有限。在這項工作中，我們提出利用來自大型語言模型的預訓練知識"
  },
  "arxiv:2602.16136": {
    "story_id": "arxiv:2602.16136",
    "title_zh": "當 AI 污染網路時檢索崩潰",
    "summary_zh": "網路上 AI 生成內容的迅速增長對資訊檢索構成結構性風險，因為搜尋引擎和 Retrieval-Augmented Generation (RAG) 系統越來越多地消耗 Large Language Models (LLMs) 生成的證據。我們將這種生態系統層級的失敗模式描述為 Retrieval Collapse，這是一個兩階段的過程：(1) AI 生成內容主導搜尋結果，侵蝕了來源多樣性，以及 (2) 低品質或惡意內容滲透到檢索"
  },
  "arxiv:2602.17229": {
    "story_id": "arxiv:2602.17229",
    "title_zh": "LLMs 中認知複雜度的 Mechanistic Interpretability：透過使用 Bloom's Taxonomy 的 Linear Probing",
    "summary_zh": "大型語言模型 (Large Language Models, LLMs) 的 black-box 特性，要求新穎的評估框架，以超越表面層次的性能指標。本研究使用 Bloom's Taxonomy 作為分層視角，探討 LLMs 內部認知複雜度的神經表示。透過分析來自不同 LLMs 的高維 activation vectors，我們探究了從基本回憶 (Remember) 到抽象綜合 (Create) 的不同認知層次，是否在模型 residu 內部是 linearly separable 的。"
  },
  "arxiv:2602.17168": {
    "story_id": "arxiv:2602.17168",
    "title_zh": "BadCLIP++: 多模態 Contrastive Learning 中的隱蔽且持久的 Backdoor",
    "summary_zh": "針對多模態 contrastive learning 模型進行 backdoor 攻擊的研究面臨兩個關鍵挑戰：隱蔽性 (stealthiness) 和持久性 (persistence)。現有方法在強檢測或持續 fine-tuning 下往往會失效，這主要歸因於 (1) 暴露 trigger patterns 的 cross-modal inconsistency，以及 (2) 在低 poisoning rates 下加速 backdoor 遺忘的 gradient dilution。這些耦合的原因仍未得到充分建模和解決。我們提出了 BadCLIP++，一個統一的框架，旨在解決這兩個挑戰。"
  },
  "arxiv:2602.17095": {
    "story_id": "arxiv:2602.17095",
    "title_zh": "FLoRG: 結合 Low-rank Gram Matrices 和 Procrustes Alignment 的 Federated Fine-tuning",
    "summary_zh": "諸如 low-rank adaptation (LoRA) 等參數高效 fine-tuning 技術，使大型語言模型 (LLMs) 能夠有效地適應下游任務。Federated learning (FL) 透過實現跨分散式客戶端進行協同 fine-tuning 而不共享私人數據，進一步促進了這一過程。然而，在 LoRA 中使用兩個獨立的 low-rank matrices 進行 federated fine-tuning 引入了兩種類型的挑戰。第一個挑戰源於單獨 aggregation 所引起的錯誤。"
  },
  "arxiv:2602.17053": {
    "story_id": "arxiv:2602.17053",
    "title_zh": "RFEval: 在大型推理模型中，對反事實推理干預下的推理忠實度進行基準測試",
    "summary_zh": "大型推理模型 (Large Reasoning Models, LRMs) 展現出強大的性能，但其產生的理由 (rationales) 往往聽起來合理卻未能反映其真實的決策過程，從而損害了可靠性和信任。我們引入了一個推理忠實度的正式框架，由兩個可測試條件定義：立場一致性 (stance consistency, 即將推理與答案聯繫起來的連貫立場) 和因果影響 (causal influence, 即在 output-level 干預下，所陳述的推理在因果上驅動答案)，這些條件明確地與準確性 decoupled。"
  },
  "arxiv:2602.17025": {
    "story_id": "arxiv:2602.17025",
    "title_zh": "WS-GRPO: 針對 Rollout-Efficient Reasoning 的 Weakly-Supervised Group-Relative Policy Optimization",
    "summary_zh": "Group Relative Policy Optimization (GRPO) 對於在複雜推理上訓練語言模型是有效的。然而，由於目標是相對於一組採樣的 trajectories 定義的，長時間的深思熟慮可能會創造更多機會實現相對收益，導致推理效率低下和過度思考，並使正確性和 rollout efficiency 之間的權衡變得複雜。在實踐中很難控制這種行為，考慮到 (i) Length penalties 難以校準。"
  },
  "arxiv:2602.17022": {
    "story_id": "arxiv:2602.17022",
    "title_zh": "ReIn: 以推理起始進行對話錯誤恢復",
    "summary_zh": "搭載了工具整合的 large language models (LLMs) 驅動的 conversational agents 在固定的 task-oriented dialogue datasets 上表現出色，但仍容易受到意外的、用戶引起的錯誤的影響。本研究不專注於錯誤預防，而是著重於錯誤恢復，這需要準確診斷錯誤的對話上下文並執行適當的恢復計劃。在實際限制下，由於顯著的原因，排除 model fine-tuning 或 prompt modification..."
  },
  "arxiv:2602.17009": {
    "story_id": "arxiv:2602.17009",
    "title_zh": "Action-Graph Policies：在多智能體強化學習中學習行動共依賴性",
    "summary_zh": "行動協調是 multi-agent reinforcement learning (MARL) 中最基本的合作形式。成功的去中心化決策往往不僅取決於良好的個體行動，還取決於在不同 agents 間選擇相容的行動以同步行為、避免衝突並滿足全局約束。在本文中，我們提出了 Action Graph Policies (AGP)，它對 agents 可用行動選擇之間的依賴關係進行建模。它構建了我們所謂的 coordination cont..."
  },
  "arxiv:2602.16958": {
    "story_id": "arxiv:2602.16958",
    "title_zh": "透過結構化模板注入實現自動化 Agent 劫持",
    "summary_zh": "Agent hijacking 被 OWASP 強調為 Large Language Model (LLM) 生態系統的關鍵威脅，它使攻擊者能夠透過將惡意指令注入檢索到的內容來操縱執行。大多數現有攻擊依賴於手動製作的、語義驅動的 prompt 操縱，這通常導致攻擊成功率低且對閉源商業模型的遷移能力有限。在本文中，我們提出了 Phantom，一個基於 Structured Te... 的自動化 agent hijacking 框架。"
  },
  "arxiv:2602.16935": {
    "story_id": "arxiv:2602.16935",
    "title_zh": "DeepContext：在 LLMs 中對多輪對抗性意圖漂移進行有狀態實時檢測",
    "summary_zh": "儘管 Large Language Model (LLM) 的能力不斷擴展，但安全防護措施在很大程度上仍然是無狀態的，將多輪對話視為一系列不相關的事件。這種缺乏時間感知導致了一個「安全鴻溝」(Safety Gap)，其中諸如 Crescendo 和 ActorAttack 等對抗性策略會緩慢地將惡意意圖滲透過輪次邊界，以繞過無狀態過濾器。我們介紹了 DeepContext，這是一個有狀態的監控框架，旨在繪製用戶意圖的時間軌跡。DeepContext disca..."
  },
  "arxiv:2602.16931": {
    "story_id": "arxiv:2602.16931",
    "title_zh": "狹義 fine-tuning 侵蝕了視覺語言 agents 的安全對齊",
    "summary_zh": "終身多模態 agents 必須透過後訓練不斷適應新任務，但這在獲取能力和保持安全對齊之間產生了根本性的矛盾。我們證明了在狹窄領域的有害數據集上 fine-tuning 已對齊的 vision-language models，會導致嚴重的 emergent misalignment，這種不對齊現象廣泛泛化到不相關的任務和模態。透過在 Gemma3-4B 上的實驗，我們展示了 misalignment 隨 LoRA rank 單調地擴展，並且 multimod..."
  },
  "arxiv:2602.16708": {
    "story_id": "arxiv:2602.16708",
    "title_zh": "用於安全 Agentic Systems 的政策編譯器",
    "summary_zh": "基於 LLM 的 agents 正日益部署於需要複雜授權政策的環境中：客戶服務協議、審批流程、數據存取限制和法規遵循。將這些政策嵌入到 prompts 中並不能提供強制執行保證。我們提出 PCAS，一個用於 Agentic Systems 的 Policy Compiler，它提供確定性的政策強制執行。強制執行這些政策需要追蹤 agents 之間的資訊流，而線性的訊息歷史記錄無法捕捉這些資訊流"
  },
  "arxiv:2602.16687": {
    "story_id": "arxiv:2602.16687",
    "title_zh": "透過交錯的語義、聲學和文本 Tokens 擴展開放離散音訊 Foundation Models",
    "summary_zh": "當前的音訊語言模型主要以文本為先，無論是擴展預訓練的文本 LLM 主幹，還是依賴僅語義的音訊 tokens，都限制了通用音訊建模。本文提出了一項關於原生音訊 foundation models 的系統性實證研究，該模型將 next-token prediction 大規模應用於音訊，聯合建模語義內容、聲學細節和文本，以支持通用音訊生成和跨模態能力。我們提供了全面的實證見解，用於 b"
  },
  "arxiv:2602.16639": {
    "story_id": "arxiv:2602.16639",
    "title_zh": "AREG：用於評估大型語言模型說服與抵抗能力的對抗性資源提取遊戲",
    "summary_zh": "評估大型語言模型 (LLMs) 的社會智能，越來越需要超越靜態文本生成，轉向動態的、對抗性的互動。我們介紹了 Adversarial Resource Extraction Game (AREG)，這是一個基準測試，它將說服和抵抗操作化為一場多輪、零和的金融資源談判。透過對 frontier models 進行循環賽，AREG 能夠聯合評估攻擊性（說服）和防禦性（抵抗）能力"
  },
  "arxiv:2602.16603": {
    "story_id": "arxiv:2602.16603",
    "title_zh": "FlowPrefill：將搶佔與預填充調度粒度解耦以緩解 LLM 服務中的隊頭阻塞",
    "summary_zh": "對大型語言模型 (LLMs) 不斷增長的需求要求服務系統處理大量具有不同服務級別目標 (SLOs) 的並發請求。這加劇了計算密集型 prefill 階段的 head-of-line (HoL) 阻塞，其中長時間運行的請求壟斷了資源並延遲了更高優先級的請求，導致廣泛的 time-to-first-token (TTFT) SLO 違規。雖然 chunked prefill 實現了可中斷性，但它在響應性之間引入了固有的權衡"
  },
  "arxiv:2602.16584": {
    "story_id": "arxiv:2602.16584",
    "title_zh": "表徵對齊假說：跨嵌入模態不變語義結構的證據及影響",
    "summary_zh": "越來越多的證據表明，獨立訓練的 AI 系統會以相同的方式表徵世界。換句話說，來自文本、視覺、音訊和神經信號的獨立訓練 embeddings 共享一個底層幾何。我們將此稱為 Representational Alignment Hypothesis (RAH)，並研究該主張的證據和影響。證據分為兩類：(i) 內部結構比較技術，例如 representational similarity analysis 和 topological data ana"
  },
  "arxiv:2602.16520": {
    "story_id": "arxiv:2602.16520",
    "title_zh": "用於 Jailbreak 偵測的 Recursive language models：針對 tool-augmented agents 的程序性防禦",
    "summary_zh": "Jailbreak prompts 對於大型語言模型（LLMs）構成實際且不斷演變的威脅，尤其是在針對不可信內容執行 tools 的 agentic systems 中。許多攻擊利用 long-context hiding、semantic camouflage 和 lightweight obfuscations，這些技術可以規避 single-pass guardrails。我們提出 RLM-JB，這是一個基於 Recursive Language Models (RLMs) 構建的 end-to-end jailbreak detection 框架，其中一個 root model 協調一個 bounded analysis program，該程序負責轉換輸入、查詢工作。"
  },
  "arxiv:2602.16498": {
    "story_id": "arxiv:2602.16498",
    "title_zh": "快速且可擴展的 Analytical Diffusion",
    "summary_zh": "Analytical diffusion models 透過將 denoising score 表述為 empirical-Bayes posterior mean，為 generative modeling 提供了一條數學上透明的途徑。然而，這種可解釋性伴隨著高昂的成本：標準的表述在每個 timestep 都需要對整個 dataset 進行掃描，其擴展性與 dataset size 呈線性關係。在這項工作中，我們提出了第一個系統性研究來解決這個 scalability bottleneck。我們挑戰了普遍認為整個 training data 是"
  },
  "arxiv:2602.16490": {
    "story_id": "arxiv:2602.16490",
    "title_zh": "從 Growing 到 Looping：LLMs 中 Iterative Computation 的統一視角",
    "summary_zh": "Looping（在深度上重複使用一個 block of layers）和 depth growing（透過複製中間層來訓練 shallow-to-deep models）都被認為與更強的 reasoning 能力相關，但它們之間的關係仍不清楚。我們提供了一個 mechanistic unification：looped 和 depth-grown models 表現出收斂的 depth-wise signatures，包括對 late layers 依賴的增加以及與 looped 或 grown block 對齊的重複模式。這些共享的 signatures 支持了它們的增益源於"
  },
  "arxiv:2602.16346": {
    "story_id": "arxiv:2602.16346",
    "title_zh": "好心辦壞事：評估 Multi-Turn、Multilingual LLM Agents 中的非法協助",
    "summary_zh": "基於 LLM 的 agents 透過 tools 和 memory 執行現實世界的 workflows。這些 affordances 也使心懷惡意的 adversaries 能夠利用這些 agents 執行複雜的 misuse scenarios。現有的 agent misuse benchmarks 主要測試 single-prompt instructions，在衡量 agents 如何在 multiple turns 中協助有害或非法任務方面存在空白。我們引入了 STING (Sequential Testing of Illicit N-step Goal execution)，這是一個自動化的 red-teaming framework，它構建了一個逐步的"
  },
  "arxiv:2602.16313": {
    "story_id": "arxiv:2602.16313",
    "title_zh": "MemoryArena：在相互依存的 Multi-Session Agentic Tasks 中評測 Agent Memory",
    "summary_zh": "現有對帶有 memory 的 agents 的評估通常孤立地評估 memorization 和 action。一類 benchmarks 透過測試對過去對話或文本的 recall 來評估 memorization，但未能捕捉 memory 如何用於指導未來的決策。另一類則專注於 agents 在 single-session tasks 中行動，無需 long-term memory。然而，在現實環境中，memorization 和 action 是緊密耦合的：agents 在與環境互動時獲取 memory，"
  },
  "arxiv:2602.16756": {
    "story_id": "arxiv:2602.16756",
    "title_zh": "NESSiE：必要的安全基準測試——識別不應存在的錯誤",
    "summary_zh": "我們引入了 NESSiE，這是用於大型語言模型（LLM）的必要安全基準測試（NEceSsary SafEty benchmark）。NESSiE 透過資訊和存取安全性的最少測試案例，揭示了在任務複雜度低的情況下不應存在的安全相關故障。NESSiE 旨在作為語言模型安全性的輕量級、易於使用的健全性檢查（sanity check），因此不足以保證普遍的安全性——但我們認為通過此測試對於任何部署都是必要的。然而，即使是 state-of-the-art 的 LLM 在 NESSiE 上也未能達到 100%，因此未能通過我們對語言模型安全性的必要條件，即使在沒有 adversarial attacks 的情況下也是如此。我們的 Safe & Helpful (SH) metric 允許直接比較這兩個要求，顯示模型偏向於 helpful 而不是 safe。我們進一步發現，對於某些模型，推理能力被禁用，但特別是良性的干擾上下文（benign distraction context）會降低模型性能。總體而言，我們的結果強調了將此類模型部署為野外自主代理（autonomous agents in the wild）的關鍵風險。我們公開了數據集、套件和繪圖程式碼。"
  },
  "arxiv:2602.16246": {
    "story_id": "arxiv:2602.16246",
    "title_zh": "邁向可擴展的可驗證獎勵：用於多輪工具調用 LLM 代理的基於代理狀態的評估",
    "summary_zh": "透過多輪對話和多步驟工具調用運作的互動式大型語言模型（LLM）代理正日益被用於生產環境。這些代理的基準測試必須既能可靠地比較模型，又能產生 on-policy 訓練數據。先前的代理基準測試（例如，tau-bench, tau2-bench, AppWorld）依賴於完全確定性的後端，這些後端建構和迭代成本高昂。我們提出了 Proxy State-Based Evaluation，一個由 LLM 驅動的模擬框架，它保留了基於最終狀態的評估。"
  },
  "arxiv:2602.16752": {
    "story_id": "arxiv:2602.16752",
    "title_zh": "LLM 排序器對 Prompt Injection Attacks 的脆弱性",
    "summary_zh": "大型語言模型（LLM）已成為強大的 re-rankers。然而，最近的研究表明，嵌入在候選文件中的簡單 prompt injection（即 jailbreak prompt attacks）可以顯著改變 LLM 的排序決策。雖然這對基於 LLM 的排序管道構成了嚴重的安全風險，但這種脆弱性在不同 LLM 家族、架構和設定中的持續程度仍未得到充分探索。在本文中，我們提出了一個全面的。"
  },
  "arxiv:2602.16201": {
    "story_id": "arxiv:2602.16201",
    "title_zh": "大型語言模型中的長尾知識：分類、機制、干預和影響",
    "summary_zh": "大型語言模型（LLM）是在網路規模語料庫上訓練的，這些語料庫呈現出陡峭的 power-law distributions，其中知識的分布高度長尾，大多數知識出現頻率不高。雖然 scaling 改善了 average-case performance，但在低頻率、領域特定、文化和時間知識上的持續故障仍然未能得到很好的表徵。本文開發了一個結構化的 taxonomy 和對大型語言模型中 long-Tail Knowledge 的分析，綜合了先前的工作。"
  },
  "arxiv:2602.16196": {
    "story_id": "arxiv:2602.16196",
    "title_zh": "用於合作異構多智能體強化學習的 Graphon 均場次採樣",
    "summary_zh": "協調大量互動智能體是 multi-agent reinforcement learning (MARL) 中的一個核心挑戰，其中聯合狀態-動作空間的大小隨智能體數量呈指數增長。Mean-field methods 透過聚合智能體互動來緩解這一負擔，但這些方法假設互動是同質的。最近基於 graphon 的框架能夠捕捉異質性，但隨著智能體數量的增加，計算成本高昂。因此，我們引入了。"
  },
  "arxiv:2602.16179": {
    "story_id": "arxiv:2602.16179",
    "title_zh": "EnterpriseBench Corecraft：在高擬真 RL 環境中訓練通用型 Agent",
    "summary_zh": "我們展示了在 high-fidelity reinforcement learning 環境中訓練 AI agents，可以產生超越訓練分佈的泛化能力。我們引入了 CoreCraft，這是 Surge AI 的 agentic RL 環境套件 EnterpriseBench 中的第一個環境。CoreCraft 是一個客戶支援組織的全面運作企業模擬，包含跨越 14 種實體類型、超過 2,500 個實體和 23 種獨特工具，旨在衡量 AI agents 是否能執行多步驟、"
  },
  "arxiv:2602.17469": {
    "story_id": "arxiv:2602.17469",
    "title_zh": "審計互惠情感對齊：Transformer 中的反轉風險、方言表徵和意圖錯位",
    "summary_zh": "雙向對齊的核心主題是確保 AI systems 準確理解人類意圖，並且人類可以信任 AI 的行為。然而，這個循環在語言障礙面前嚴重斷裂。我們的研究透過基準測試四種 Transformer 架構，解決了孟加拉語和英語之間的 Cross-Lingual Sentiment Misalignment 問題。我們揭示了當前 alignment paradigms 中嚴重的安全性與表徵失敗。我們證明了壓縮模型 (mDistilBERT) 表現出 28.7%"
  },
  "arxiv:2602.17288": {
    "story_id": "arxiv:2602.17288",
    "title_zh": "ArXiv-to-Model：科學 LM 訓練的實踐研究",
    "summary_zh": "儘管 frontier large language models 展示了強大的推理和數學能力，但從原始來源訓練 domain-specialized scientific language models 的實際過程仍然缺乏文獻記載。在這項工作中，我們提出了一個詳細的案例研究，關於如何直接從涵蓋數學、電腦科學和理論物理的原始 arXiv LaTeX 來源訓練一個 1.36B-parameter 的 scientific language model。我們描述了一個端到端 (end-to-end) 的 pipeline，涵蓋了 metadata filtering、archive validation、LaTeX extraction、text normalization、domain-aware tokenization，以及在受限運算資源 (2xA100 GPUs) 下進行的 dense Transformer training。透過 24 次實驗運行，我們分析了訓練穩定性、scaling behavior、data yield losses 和 infrastructure bottlenecks。我們的研究結果強調了預處理決策如何顯著影響可用 token 數量、tokenization 如何影響 symbolic stability，以及儲存和 I/O 限制如何與運算能力一樣成為限制因素。我們進一步分析了 convergence dynamics，並展示了在 data-rich regime (52B pretraining tokens) 下穩定的訓練行為。這項工作並非提出一種新穎的 architecture，而是提供了一個基於工程實踐、透明的從頭開始訓練小型 scientific language model 的說明。我們希望這些見解能支持在適度運算預算下尋求建立 domain-specialized models 的研究人員。"
  },
  "arxiv:2602.17047": {
    "story_id": "arxiv:2602.17047",
    "title_zh": "Amber-Image：大規模 Diffusion Transformers 的高效壓縮",
    "summary_zh": "Diffusion Transformer (DiT) architecture 顯著推進了 Text-to-Image (T2I) 生成，但面臨高昂的運算成本和部署障礙。為了解決這些挑戰，我們提出了一種高效的壓縮框架，該框架將基於 60-layer dual-stream MMDiT 的 Qwen-Image 轉變為輕量級模型，而無需從頭開始訓練。利用此框架，我們推出了 Amber-Image，一系列精簡的 T2I models。我們首先使用一個 tim"
  },
  "arxiv:2602.17375": {
    "story_id": "arxiv:2602.17375",
    "title_zh": "MDP 規劃作為策略推斷",
    "summary_zh": "我們將情景式 Markov decision process (MDP) 規劃視為對 _policies_ 的 Bayesian inference。一個 policy 被視為潛在變數，並被賦予一個與其預期報酬呈單調關係的非標準化最佳機率 (unnormalized probability of optimality)，從而產生一個後驗分佈 (posterior distribution)，其眾數與報酬最大化的解重合，而後驗離散度 (posterior dispersion) 則代表了對最佳行為的不確定性。為了在離散領域中近似這個後驗分佈，我們採用了 variational sequential Monte Carlo (VSMC)"
  },
  "arxiv:2602.16947": {
    "story_id": "arxiv:2602.16947",
    "title_zh": "超越訊息傳遞：一種用於表達性和可解釋圖學習的符號式替代方案",
    "summary_zh": "圖神經網路 (GNNs) 已在藥物發現等高風險領域變得至關重要，然而，它們的 black-box 性質仍然是信任度的一個重大障礙。儘管 self-explainable GNNs 試圖彌合這一差距，但它們通常依賴標準的 message-passing 骨幹，這些骨幹繼承了基本限制，包括 1-Weisfeiler-Lehman (1-WL) 表達能力障礙和缺乏細粒度 (fine-grained) 的可解釋性。為了應對這些挑戰，我們提出 SymGraph，一個符號式框架"
  },
  "arxiv:2602.16823": {
    "story_id": "arxiv:2602.16823",
    "title_zh": "形式化機械解釋性：具有可證明保證的自動化電路發現",
    "summary_zh": "「自動化電路發現」(Automated circuit discovery) 是 Mechanistic Interpretability 中的一個核心工具，用於識別神經網路中負責特定行為的內部組件。儘管先前的方法取得了顯著進展，但它們通常依賴於 heuristics 或 approximations，並且無法為所得電路在連續輸入域上提供可證明保證。在這項工作中，我們利用神經網路驗證的最新進展，提出了一套自動化演算法，該演算法提供"
  },
  "arxiv:2602.17622": {
    "story_id": "arxiv:2602.17622",
    "title_zh": "什麼造就了一個好的 LLM Agent 用於真實世界滲透測試？",
    "summary_zh": "基於 LLM 的 agents 在自動化滲透測試方面展現了潛力，然而，報告的性能在不同系統和基準測試中差異很大。我們分析了 28 個基於 LLM 的滲透測試系統，並在三個複雜度遞增的基準測試中評估了五個代表性實作。我們的分析揭示了兩種不同的失敗模式：Type A 失敗源於能力差距（缺少工具、prompts 不足），這些可以透過工程手段輕易解決；而 Type B 失敗則無論工具"
  },
  "arxiv:2602.17211": {
    "story_id": "arxiv:2602.17211",
    "title_zh": "MGD：用於最大熵生成的動量引導擴散",
    "summary_zh": "從有限資訊生成樣本是跨科學領域的一個基本問題。經典的最大熵方法從 moment constraints 提供有原則的不確定性量化，但需要透過 MCMC 或 Langevin dynamics 進行採樣，這在高維度中通常會表現出指數級的減速。相較之下，基於 diffusion 和 flow matching 的生成模型能有效地將噪音傳輸到數據，但提供的理論保證有限，並且在數據稀缺時可能過度擬合 (overfit)。我們"
  },
  "arxiv:2602.17312": {
    "story_id": "arxiv:2602.17312",
    "title_zh": "LexiSafe：具有詞典式安全-獎勵層次結構的離線安全強化學習",
    "summary_zh": "離線安全強化學習 (RL) 對於網路實體系統 (CPS) 越來越重要，在這些系統中，訓練期間的安全違規是不可接受的，且僅有預先收集的數據可用。現有的離線安全 RL 方法通常透過 constraint relaxation 或 joint optimization 來平衡獎勵與安全的權衡，但它們往往缺乏結構性機制來防止安全漂移 (safety drift)。我們提出 LexiSafe，一個詞典式離線 RL 框架，旨在保持安全對齊的行為。"
  },
  "arxiv:2602.16964": {
    "story_id": "arxiv:2602.16964",
    "title_zh": "SAGE: 適用於異質資料檢索的結構感知圖擴展",
    "summary_zh": "在異質語料庫上進行檢索增強問答 (retrieval-augmented question answering) 需要跨文本、表格和圖節點的連接證據。雖然實體級知識圖譜 (entity-level knowledge graphs) 支持結構化存取 (structured access)，但它們的建構和維護成本高昂，且在查詢時遍歷效率低下。相較之下，標準的 retriever-reader 管道對獨立分塊的文本使用平面相似性搜索 (flat similarity search)，遺漏了跨模態的多跳證據鏈 (multi-hop evidence chains)。我們提出了 SAGE (Structure Aware Graph Expansion) 框架。"
  },
  "arxiv:2602.16698": {
    "story_id": "arxiv:2602.16698",
    "title_zh": "因果關係是可解釋性主張泛化的關鍵",
    "summary_zh": "針對大型語言模型 (LLMs) 的可解釋性研究為模型行為 (model behaviour) 提供了重要見解，但重複出現的陷阱依然存在：即無法泛化 (generalise) 的發現，以及超出證據範圍的因果解釋 (cusal interpretations)。我們的立場是，因果推斷 (causal inference) 闡明了構成從模型激活 (model activations) 到不變高層次結構 (invariant high-level structures) 的有效映射所需的條件、實現它所需的數據或假設，以及它能支持的推斷。具體而言，Pearl 的因果層次結構 (causal hierarchy) 澄清了..."
  },
  "arxiv:2602.16763": {
    "story_id": "arxiv:2602.16763",
    "title_zh": "當 AI 基準達到高原期：基準飽和的系統性研究",
    "summary_zh": "人工智慧 (AI) 基準在衡量模型開發進度 (model development) 和指導部署決策 (deployment decisions) 方面發揮著核心作用。然而，許多基準很快就達到飽和 (saturated)，這意味著它們無法再區分表現最佳的模型 (best-performing models)，從而削弱了其長期價值。在這項研究中，我們分析了主要模型開發商技術報告中選取的 60 個大型語言模型 (LLM) 基準的飽和情況。為識別導致飽和的因素，我們..."
  },
  "arxiv:2602.16596": {
    "story_id": "arxiv:2602.16596",
    "title_zh": "序列式成員推斷攻擊",
    "summary_zh": "現代 AI 模型並非靜態。它們在生命週期中經歷多次更新。因此，利用模型動態 (model dynamics) 來創建更強的 Membership Inference (MI) 攻擊和更嚴格的隱私審計 (privacy audits) 是及時的問題。儘管文獻經驗表明使用一系列模型更新可以提高 MI 攻擊的效能 (power)，但對「最佳」MI 攻擊的嚴謹分析 (rigorous analysis) 僅限於具有無限樣本的靜態模型 (static models)。因此，我們開發了一種「最佳」MI 攻擊，SeMI*，它利用了..."
  },
  "arxiv:2602.16494": {
    "story_id": "arxiv:2602.16494",
    "title_zh": "物件偵測中對抗性穩健性與對抗性訓練策略的基準測試",
    "summary_zh": "物件偵測模型 (Object detection models) 是自動化系統 (automated systems) 的關鍵組成部分，例如自動駕駛汽車 (autonomous vehicles) 和基於感知的機器人 (perception-based robots)，但它們對對抗性攻擊 (adversarial attacks) 的敏感性構成嚴重的安全風險。防禦這些模型的進展落後於分類任務 (classification)，因缺乏標準化評估而受阻。徹底比較攻擊或防禦方法幾乎不可能，因為現有研究使用了不同的資料集 (datasets)、不一致的效率指標 (efficiency metrics) 以及多變的擾動成本 (perturbation cos) 衡量標準。"
  },
  "arxiv:2602.17633": {
    "story_id": "arxiv:2602.17633",
    "title_zh": "何時該信任廉價檢查：用於推理的弱驗證與強驗證",
    "summary_zh": "使用 LLMs 進行推理的過程越來越多地在一個更廣泛的驗證循環中展開。在內部，系統使用廉價檢查，例如 self-consistency 或 proxy rewards，我們稱之為 weak verification。在外部，使用者檢查輸出並透過回饋引導模型，直到結果值得信賴，我們稱之為 strong verification。這些訊號在成本和可靠性上存在顯著差異：strong verification 可以建立信任但資源密集，而 weak verification 快速且可擴展，但其可靠性..."
  },
  "arxiv:2602.17588": {
    "story_id": "arxiv:2602.17588",
    "title_zh": "建模 Web Agents 中獨特的人類互動",
    "summary_zh": "儘管 autonomous web agents 進展迅速，但在任務執行過程中，人類的參與對於塑造偏好和糾正 agent 行為仍然至關重要。然而，目前的 agentic 系統缺乏對人類何時以及為何介入的原則性理解，常常自主地越過關鍵決策點或請求不必要的確認。在這項工作中，我們引入了建模人類介入的任務，以支持協作的 web 任務執行。我們收集了 CowCorpus，一個包含 400 條真實用戶 web navigation 軌跡的資料集，其中包含超過 4,200 個交錯的人類和 agent 行為。我們識別出四種不同的用戶與 agent 互動模式——hands-off supervision、hands-on oversight、collaborative task-solving 和 full user takeover。借助這些洞察，我們訓練了 language models (LMs) 來根據用戶的互動風格預測他們何時可能介入，使得介入預測準確度相較於基礎 LMs 提高了 61.4-63.4%。最後，我們將這些具備介入意識的模型部署到實際的 web navigation agents 中，並在用戶研究中進行評估，發現用戶對 agent 有用性的評價提升了 26.5%。總之，我們的結果表明，對人類介入進行結構化建模能夠產生更具適應性和協作性的 agents。"
  },
  "arxiv:2602.17546": {
    "story_id": "arxiv:2602.17546",
    "title_zh": "學習保持安全：在 Fine-Tuning 期間對抗安全退化的自適應正則化",
    "summary_zh": "Instruction-following language models 被訓練成有用且安全的，然而它們的安全行為在良性 fine-tuning 下可能會惡化，並在 adversarial updates 下變得更糟。現有的防禦措施通常提供有限的保護，或迫使在安全性和實用性之間進行權衡。我們引入了一個訓練框架，它根據安全風險調整 regularization，使模型在整個 fine-tuning 過程中保持一致。為了在訓練時估計安全風險，我們探索了兩種不同的方法..."
  },
  "arxiv:2602.17520": {
    "story_id": "arxiv:2602.17520",
    "title_zh": "當模型忽略定義時：測量 LLM 推理中的語義覆蓋幻覺",
    "summary_zh": "Large language models (LLMs) 在標準的 digital logic 和 Boolean reasoning 任務上表現出色，但其在局部重新定義語義下的可靠性仍然知之甚少。在許多正式設定中，例如 circuit specifications、examinations 和 hardware documentation，operators 和 components 在狹窄範圍內被明確重新定義。在這些情境中，正確的推理要求模型暫時抑制全球學習到的慣例，轉而採用 prompt 局部的定義..."
  },
  "arxiv:2602.17262": {
    "story_id": "arxiv:2602.17262",
    "title_zh": "量化和緩解 LLMs 中的 Socially Desirable Responding：一項 desirability-matched 的 graded forced-choice 心理計量學研究",
    "summary_zh": "人類自陳問卷在 NLP 中越來越多地被用於評測和審計 large language models (LLMs)，從 persona consistency 到 safety 和 bias assessments。然而，這些工具預設了誠實回應；在評估情境中，LLMs 反而可能傾向於社會偏好的答案——一種 Socially Desirable Responding (SDR) 形式——從而偏倚了問卷導出的分數和下游結論。我們提出了一個心理計量學框架來量化和緩解基於問卷的 SDR..."
  },
  "arxiv:2602.17234": {
    "story_id": "arxiv:2602.17234",
    "title_zh": "所有的洩漏都算數，有些更關鍵：LLM 回溯測試中可解釋的時間污染檢測",
    "summary_zh": "為了評估 LLMs 是否能準確預測未來事件，我們需要能夠對已解決的事件進行 `backtest`。這要求模型只能利用特定過去日期可用的資訊進行推理。然而，LLMs 在訓練期間可能會無意中洩漏 `post-cutoff knowledge`，從而損害回溯評估的有效性。我們引入了一個 `claim-level framework`，用於檢測和量化這種 `temporal knowledge leakage`。我們的方法將..."
  },
  "arxiv:2602.17223": {
    "story_id": "arxiv:2602.17223",
    "title_zh": "隱私保護機制實現 LLMs 廉價可驗證的推論",
    "summary_zh": "隨著大型語言模型（LLMs）規模不斷增長，越來越少的用戶能夠在本地託管和運行模型。這導致第三方託管服務的使用增加。然而，在這種情況下，對於 `inference` 提供者所執行的計算缺乏保障。例如，一個不誠實的提供者可能會用一個運行成本較低的弱模型替換昂貴的大型模型，並將弱模型的結果返回給用戶。現有的驗證 `inference` 的工具通常依賴於..."
  },
  "arxiv:2602.17196": {
    "story_id": "arxiv:2602.17196",
    "title_zh": "EntropyPrune: 矩陣熵引導的多模態大型語言模型視覺 Token 剪枝",
    "summary_zh": "多模態大型語言模型（MLLMs）由於處理每張圖片數百個 `visual tokens`，產生了大量的 `inference cost`。儘管 `token pruning` 已被證明對於加速 `inference` 是有效的，但確定何時何地進行剪枝仍然很大程度上是基於經驗的啟發式方法。現有方法通常依賴於靜態、憑經驗選擇的層，這限制了解釋性和模型之間的遷移能力。在這項工作中，我們引入了一種 `matrix-entropy` 視角，並發現了一種「Entropy Collapse..."
  },
  "arxiv:2602.17186": {
    "story_id": "arxiv:2602.17186",
    "title_zh": "透過視覺資訊增益對大型視覺語言模型進行選擇性訓練",
    "summary_zh": "大型視覺語言模型（LVLMs）取得了顯著進展，但它們經常遭受 `language bias` 的困擾，在不依賴視覺證據的情況下產生答案。雖然先前的工作試圖透過 `decoding strategies`、架構修改或精選的指令數據來緩解這個問題，但它們通常缺乏一種量化指標來衡量單個訓練樣本或 `tokens` 從圖像中實際受益的程度。在這項工作中，我們引入了 `Visual Information Gain (VIG)`，這是一種 `perplexity`..."
  },
  "arxiv:2602.17169": {
    "story_id": "arxiv:2602.17169",
    "title_zh": "SimulatorCoder: 透過大型語言模型進行 DNN 加速器模擬器程式碼生成與最佳化",
    "summary_zh": "本文介紹了 SimulatorCoder，這是一個由大型語言模型（LLMs）驅動的代理，旨在根據自然語言描述生成和最佳化深度神經網路（DNN）加速器模擬器。透過整合領域特定的 `prompt engineering`，包括 `In-Context Learning (ICL)`、`Chain-of-Thought (CoT)` 推理，以及多輪 `feedback-verification flow`，SimulatorCoder 系統性地將高階功能需求轉化為高效、可執行且與架構對齊（architecture-ali）的..."
  },
  "arxiv:2602.17100": {
    "story_id": "arxiv:2602.17100",
    "title_zh": "AgentConductor: 用於多智能體競爭級程式碼生成的拓撲演化",
    "summary_zh": "由大型語言模型 (LLM) 驅動的多智能體系統 (MAS) 透過預定義的互動拓撲協調專業化的代理，並已在諸如競爭級程式碼生成等複雜任務中展現出潛力。最近的研究表明，精心設計的多智能體工作流程和通訊圖譜可以透過利用協作推理顯著提高程式碼生成效能。然而，現有方法既無法使拓撲密度適應任務難度，也無法迭代地重新定義"
  },
  "arxiv:2602.17066": {
    "story_id": "arxiv:2602.17066",
    "title_zh": "預測批次排程：透過損失感知樣本優先級化加速語言模型訓練",
    "summary_zh": "我們引入了預測批次排程 (Predictive Batch Scheduling, PBS)，這是一種新穎的訓練優化技術，它透過在批次構建期間動態地優先考慮高損失樣本來加速語言模型收斂。與需要預定義難度指標的 curriculum learning 方法或需要昂貴的逐樣本損失追蹤的 hard example mining 方法不同，PBS 採用一個輕量級的線性預測器，該預測器在線訓練，用於從靜態 token-level features 估計樣本難度。我們的預測器"
  },
  "arxiv:2602.17062": {
    "story_id": "arxiv:2602.17062",
    "title_zh": "在多智能體強化學習中保留次優行動以追隨變化的最優解",
    "summary_zh": "價值分解是協作多智能體強化學習 (MARL) 的核心方法。然而，現有方法仍依賴單一的最優行動，並且在訓練期間底層價值函數發生變化時難以適應，常常收斂到次優策略。為了解決這個限制，我們提出了 Successive Sub-value Q-learning (S2Q)，它學習多個子價值函數以保留替代的高價值行動。將這些子價值函數整合到 Softmax 中"
  },
  "arxiv:2602.17049": {
    "story_id": "arxiv:2602.17049",
    "title_zh": "IntentCUA: 用於電腦使用代理中技能抽象和多智能體規劃的意圖級表示學習",
    "summary_zh": "電腦使用代理在嘈雜感知、多視窗情境和不斷變化的環境狀態下長時間執行任務。現有方法，從基於 RL 的規劃器到軌跡檢索，經常偏離用戶意圖並重複解決常規子問題，導致錯誤累積和效率低下。我們提出了 IntentCUA，一個多智能體電腦使用框架，旨在透過意圖對齊的計畫記憶穩定長時間執行。一個 Planner、Plan-Optimizer 和 Critic 協調"
  },
  "arxiv:2602.17038": {
    "story_id": "arxiv:2602.17038",
    "title_zh": "用於代理強化學習的階段感知專家混合模型",
    "summary_zh": "強化學習 (RL) 賦予 LLM agents 解決複雜任務的強大能力。然而，現有 RL 方法通常使用一個單一的策略網絡 (policy network)，導致簡潔偏誤 (simplicity bias)，即簡單任務佔用大部分參數並主導梯度更新，為複雜任務留下不足的容量。一個可行的補救措施是在策略網絡中採用專家混合模型 (Mixture-of-Experts, MoE) 架構，因為 MoE 允許不同的參數（專家）專注於不同的"
  },
  "arxiv:2602.17037": {
    "story_id": "arxiv:2602.17037",
    "title_zh": "Wink: 從編碼 Agent 的不當行為中恢復",
    "summary_zh": "由 large language models (LLMs) 驅動的自主編碼 Agent 正日益被軟體產業採用，以自動化複雜的工程任務。然而，這些 Agent 容易出現各種不當行為，例如偏離使用者的指令、陷入重複循環，或未能正確使用工具。這些失敗會中斷開發工作流程，並且通常需要耗費大量資源的手動干預。在本文中，我們提出了一個用於自動化"
  },
  "arxiv:2602.17003": {
    "story_id": "arxiv:2602.17003",
    "title_zh": "Persona2Web: 用於基於使用者歷史的上下文推理之個性化 Web Agents 基準測試",
    "summary_zh": "大型語言模型 (Large language models) 已經推動了 Web Agents 的發展，但目前的 Agent 缺乏個性化能力。由於使用者很少詳細說明其意圖，實用的 Web Agents 必須能夠透過推斷使用者偏好和上下文來解釋模糊的查詢。為了解決這個挑戰，我們提出了 Persona2Web，這是第一個用於評估真實開放 Web 上個性化 Web Agents 的基準測試，它建立在 'clarify-to-personalize' 原則之上，該原則要求 Agent 根據"
  },
  "arxiv:2602.16987": {
    "story_id": "arxiv:2602.16987",
    "title_zh": "AI 對齊的一個可測試框架：作為矽基 Agent 的工程化世界觀的 Simulation Theology",
    "summary_zh": "隨著人工智慧 (AI) 能力的迅速發展，前沿模型日益展現出系統性的欺騙和詭計，在監督下遵守安全協議，但在無人監督時則背叛。本文透過法醫心理學的一個類比來探討隨之而來的對齊挑戰，在法醫心理學中，精神病態人群內化的信仰系統透過感知到的無所不在的監控和不可避免的後果來減少反社會行為。將這種機制應用於"
  },
  "arxiv:2602.16873": {
    "story_id": "arxiv:2602.16873",
    "title_zh": "AdaptOrch: 在 LLM 性能收斂時代的任務自適應多 Agent 編排",
    "summary_zh": "隨著來自不同供應商的 large language models 在基準測試性能上趨於收斂，為每個任務選擇單一最佳模型的傳統範式帶來了遞減的回報。我們認為，編排拓撲 (orchestration topology)——即多個 Agent 如何協調、並行化和合成的結構組成——現在在系統級性能上，其主導作用超越了單個模型的性能。我們提出了 AdaptOrch，這是一個用於任務自適應多 Agent 編排的正式框架，它動態地"
  },
  "arxiv:2602.16610": {
    "story_id": "arxiv:2602.16610",
    "title_zh": "我們能相信誰？用於比較評估的 LLM-as-a-jury",
    "summary_zh": "大型語言模型 (LLMs) 正日益被用作自然語言生成評估的自動評估器，通常採用 pairwise comparative judgements。現有方法通常依賴單一評審員或假定可靠性相等地聚合多個評審員。實際上，LLM 評審員在不同任務和方面上的表現差異很大，其判斷機率可能存在偏差和不一致。此外，用於評審員校準的人工標註監督可能無法獲得"
  },
  "arxiv:2602.16601": {
    "story_id": "arxiv:2602.16601",
    "title_zh": "Diffusion Models 中的錯誤傳播與模型崩潰：一項理論研究",
    "summary_zh": "Machine learning models 越來越多地使用 synthetic data 進行訓練或 fine-tuning。觀察發現，遞歸地使用此類資料進行訓練會顯著降低各種任務的性能，其特點通常是逐漸偏離 target distribution。在這項工作中，我們在 score-based diffusion models 的背景下，從理論上分析了這種現象。對於一個現實的 pipeline，其中每個訓練回合都結合使用了 synthetic data 和來自目標的新樣本。"
  },
  "arxiv:2602.16587": {
    "story_id": "arxiv:2602.16587",
    "title_zh": "為何思考會造成困擾？診斷與糾正 Foundation Recommender Models 中的推理轉變",
    "summary_zh": "將 Chain-of-Thought (CoT) reasoning 整合到基於 Semantic ID 的推薦基礎模型 (例如 OpenOneRec) 中，往往會矛盾地降低推薦性能。我們將根本原因歸結為來自 General Subspace 的 textual inertia，其中冗長的 reasoning 主導了 inference，並導致模型忽略關鍵的 Semantic ID。為了解決這個問題，我們提出了一個 training-free 的 Inference-Time Subspace Alignment 框架。透過壓縮 reasoning chains 並應用 bias-subtracted。"
  },
  "arxiv:2602.16570": {
    "story_id": "arxiv:2602.16570",
    "title_zh": "使用二次獎勵導引 diffusion models：一項細粒度分析",
    "summary_zh": "Inference-time algorithms 是一種新興的範式，其中 pre-trained models 被用作 subroutines 來解決 downstream tasks。此類演算法已針對從 inverse problems 和 guided image generation 到 reasoning 的各種任務被提出。然而，目前實際部署的方法是具有多種 failure modes 的 heuristics —— 我們對這些 heuristics 何時能被有效改進知之甚少。在本文中，我們考慮從一個 re 進行採樣的任務。"
  },
  "arxiv:2602.16198": {
    "story_id": "arxiv:2602.16198",
    "title_zh": "透過 Doob's $h$-Transform 對 Diffusion Models 進行免訓練適應",
    "summary_zh": "Adaptation methods 一直是釋放 pre-trained diffusion models 在各種應用中變革性力量的主力。現有方法通常將 adaptation objectives 抽象為一個 reward function，並引導 diffusion models 生成 high-reward samples。然而，這些方法可能由於額外的訓練而產生高昂的 computational overhead，或者依賴於對 reward 的嚴格假設，例如 differentiability。此外，儘管它們取得了 empirical success，理論上的 justification。"
  },
  "arxiv:2602.16165": {
    "story_id": "arxiv:2602.16165",
    "title_zh": "HiPER：用於 Large Language Model Agents 的帶有顯式信用分配的階層式強化學習",
    "summary_zh": "將 LLMs 訓練成用於 multi-turn decision-making 的 interactive agents 仍然具有挑戰性，尤其是在 rewards 稀疏且延遲的 long-horizon tasks 中，agents 必須執行一系列長時間的動作才能接收到有意義的 feedback。大多數現有的 reinforcement learning (RL) 方法將 LLM agents 建模為在單一時間尺度上運作的 flat policies，在每個回合選擇一個 action。在 sparse-reward 環境中，此類 flat policies 必須在整個 trajectory 中傳播 credit。"
  },
  "arxiv:2602.16990": {
    "story_id": "arxiv:2602.16990",
    "title_zh": "Conv-FinRe: 一個對話式和縱向的基準測試，用於以效用為基礎的金融推薦",
    "summary_zh": "大多數推薦基準評估模型模仿用戶行為的程度。然而，在金融諮詢中，在市場波動下觀察到的行為可能具有噪音或短視，並可能與用戶的長期目標相衝突。因此，將用戶選擇的內容視為唯一的「ground truth」，會將行為模仿與決策品質混淆。我們介紹了 Conv-FinRe，這是一個對話式和縱向的股票推薦基準測試，它評估 LLMs 超越行為匹配的能力。鑑於一個"
  },
  "arxiv:2602.17584": {
    "story_id": "arxiv:2602.17584",
    "title_zh": "多模態對比表示學習的規範化",
    "summary_zh": "隨著模型和數據的擴展，獨立訓練的網絡通常會產生類似的相似性概念。然而，匹配相似性比在表示空間之間建立明確的對應關係要弱，特別是對於多模態模型而言，一致性不僅必須在每個模態內部成立，還必須在學習到的 image-text coupling 中成立。因此我們提出問題：給定兩個獨立訓練的多模態對比模型（帶有編碼器 $(f, g)$ 和 $(\\widetilde{f},\\widetilde{g})$）"
  },
  "arxiv:2602.17108": {
    "story_id": "arxiv:2602.17108",
    "title_zh": "使用主題統覺測驗對大型多模態模型進行投射性心理評估",
    "summary_zh": "主題統覺測驗 (TAT) 是一個基於心理測量學的多維度評估框架，系統地區分人格類功能的認知表徵和情感關係成分。這項測驗是一種投射性心理框架，旨在揭示人格的無意識面向。本研究探討 Large Multimodal Models (LMMs) 的人格特質是否可以透過非語言模態進行評估，使用 So"
  },
  "arxiv:2602.17103": {
    "story_id": "arxiv:2602.17103",
    "title_zh": "帶有改進型代理的線上學習：多類別、預算代理和 Bandit Learners",
    "summary_zh": "我們研究了最近引入的「帶有改進的學習」模型，其中代理被允許對其特徵值進行微小更改，以獲得更理想的標籤。我們透過提供表徵此模型中線上可學習性的組合維度、分析多類別設置、在 bandit feedback 設置中的可學習性、建模代理進行改進的成本等方面，廣泛擴展了先前發表的結果。"
  },
  "arxiv:2602.17623": {
    "story_id": "arxiv:2602.17623",
    "title_zh": "揭示波斯語語言模型中的事實-概念鴻溝",
    "summary_zh": "儘管新興的波斯語 NLP 基準已擴展到語用學和禮儀領域，但它們很少區分記憶的文化事實和推斷隱含社會規範的能力。我們引入 DivanBench，這是一個診斷性基準測試，專注於迷信和習俗，這些是任意的、依賴於上下文的規則，難以進行簡單的邏輯推導。透過涵蓋三種任務類型（事實檢索、配對情境驗證和情境推理）的 315 個問題，我們評估了七個 Per"
  },
  "arxiv:2602.17433": {
    "story_id": "arxiv:2602.17433",
    "title_zh": "保護歷史真相：檢測大型語言模型中的歷史修正主義",
    "summary_zh": "大型語言模型（LLMs）越來越多地被用作歷史資訊的來源，這促使人們需要在模擬真實用戶互動的環境中，對有爭議的事件和帶有政治色彩的敘事進行可擴展的審計。我們引入了 \textsc{\texttt{HistoricalMisinfo}}，這是一個精心策劃的資料集，包含來自 $45$ 個國家的 $500$ 個有爭議事件，每個事件都配有一段事實參考敘事和一段有記載的修正主義參考敘事。為了近似真實世界的使用情況，我們為每個事件實例化了"
  },
  "arxiv:2602.17170": {
    "story_id": "arxiv:2602.17170",
    "title_zh": "當 LLM 評審誇大分數時：探討相關性評估中的過度評分現象",
    "summary_zh": "人工相關性評估既耗時又耗費認知，限制了 Information Retrieval 評估的可擴展性。這導致人們對使用大型語言模型（LLMs）作為人類評審的代理產生了越來越濃厚的興趣。然而，LLM 主導的相關性判斷是否足夠可靠、穩定和嚴謹，以媲美人類在相關性評估方面的表現，仍然是一個懸而未決的問題。在這項工作中，我們系統性地研究了 LLM 主導的相關性判斷中的過度評分行為，跨越"
  },
  "arxiv:2602.16965": {
    "story_id": "arxiv:2602.16965",
    "title_zh": "多智能體 Lipschitz Bandits",
    "summary_zh": "我們研究在連續、具有 Lipschitz 結構的行動空間上的去中心化多玩家隨機 Bandit 問題，其中硬碰撞會產生零獎勵。我們的目標是設計一種無通訊策略，以最大化集體獎勵，其協調成本與時間範圍 $T$ 無關。我們提出了一種模組化協議，該協議首先解決多智能體協調問題——透過一種新穎的最大值導向的...來識別並安排玩家進入不同的高價值區域"
  },
  "arxiv:2602.16898": {
    "story_id": "arxiv:2602.16898",
    "title_zh": "MALLVI：一個用於整合式通用機器人操作的多智能體框架",
    "summary_zh": "使用大型語言模型（LLMs）進行機器人操作的任務規劃是一個新興領域。先前的方法依賴於專用模型、fine tuning 或 prompt tuning，並且通常以開迴路（open loop）方式操作，缺乏穩健的環境回饋，這使得它們在動態環境中顯得脆弱。我們提出了 MALLVi，這是一個 Multi Agent Large Language and Vision 框架，它能夠實現閉迴路（closed loop）回饋驅動的機器人操作。鑑於自然語言指令和環境圖像，MALLVi"
  },
  "arxiv:2602.16154": {
    "story_id": "arxiv:2602.16154",
    "title_zh": "透過多聽眾軟執行平衡推理中的忠實性與性能",
    "summary_zh": "Chain-of-thought (CoT) 推理有時未能忠實反映大型語言模型（LLM）的真實計算過程，這阻礙了其在解釋 LLMs 如何得出答案方面的效用。此外，在推理中優化忠實性和可解釋性通常會降低任務性能。為了解決這種權衡並提高 CoT 的忠實性，我們提出了 Reasoning Execution by Multiple Listeners (REMUL)，這是一種多方 reinforcement learning 方法。REMUL 基於以下假設："
  },
  "arxiv:2602.16144": {
    "story_id": "arxiv:2602.16144",
    "title_zh": "Missing-by-Design：用於可撤銷多模態情感分析的可認證模態刪除",
    "summary_zh": "隨著多模態系統日益處理敏感的個人數據，選擇性撤銷特定數據模態的能力已成為隱私合規性和用戶自主權的關鍵要求。我們提出 Missing-by-Design (MBD)，這是一個用於可撤銷多模態情感分析的統一框架，它結合了結構化表示學習和可認證的參數修改管線 (pipeline)。可撤銷性在隱私敏感型應用中至關重要，在這些應用中，用戶或監管機構可能會要求"
  },
  "arxiv:2602.17452": {
    "story_id": "arxiv:2602.17452",
    "title_zh": "Jolt Atlas：透過零知識中的查閱論證實現可驗證推論",
    "summary_zh": "我們提出了 Jolt Atlas，這是一個 zero-knowledge machine learning (zkML) 框架，它將 Jolt 證明系統擴展到模型推論。與模擬 CPU 指令執行的 zkVMs (zero-knowledge virtual machines) 不同，Jolt Atlas 採用了 Jolt 以查閱為中心的方法，並將其直接應用於 ONNX tensor 操作。ONNX 計算模型消除了對 CPU 暫存器的需求，並簡化了記憶體一致性驗證。此外，ONNX 是一種開源、可攜帶的格式，這使得"
  },
  "arxiv:2602.17133": {
    "story_id": "arxiv:2602.17133",
    "title_zh": "VP-VAE：透過自適應向量擾動重新思考向量量化",
    "summary_zh": "Vector Quantized Variational Autoencoders (VQ-VAEs) 對於現代生成模型至關重要，但由於表示學習和離散碼本 (codebook) 優化的內在耦合，它們經常遭受訓練不穩定和「碼本崩潰」(codebook collapse) 的問題。在本文中，我們提出了 VP-VAE (Vector Perturbation VAE)，這是一種新穎的範式，透過在訓練期間消除對顯式碼本的需求，將表示學習與離散化解耦。我們的主要見解是，從"
  },
  "arxiv:2602.17033": {
    "story_id": "arxiv:2602.17033",
    "title_zh": "PartRAG：檢索增強的部分級 3D 生成與編輯",
    "summary_zh": "具有部分級結構的單圖像 3D 生成仍然具有挑戰性：學習到的先驗知識難以涵蓋部分幾何體的長尾並保持多視角一致性，且現有系統對精確、局部化的編輯支援有限。我們提出了 PartRAG，這是一個檢索增強框架，它將外部部分數據庫與 diffusion transformer 相結合，以將生成與可編輯表示耦合起來。為了克服第一個挑戰，我們引入了一個 Hierarchical Contrastiv"
  },
  "arxiv:2602.16456": {
    "story_id": "arxiv:2602.16456",
    "title_zh": "超越 SGD，無需 SVD：結合對角分式 K-FAC 的近端子空間迭代 LoRA",
    "summary_zh": "Low-Rank Adaptation (LoRA) 透過在凍結權重之上學習低秩更新來 fine-tune 大型模型，顯著減少了可訓練參數和記憶體。在這項工作中，我們解決了使用低秩投影 (SVDLoRA) 進行完整步驟訓練與 LoRA fine-tuning 之間的差距。我們提出了 LoRSum，這是一種記憶體效率高的子程序 (subroutine)，它透過將 LoRA 優化視為一個近端子問題並使用交替最小平方更新有效地解決它來彌補梯度下降的這一差距"
  },
  "arxiv:2602.17665": {
    "story_id": "arxiv:2602.17665",
    "title_zh": "OpenEarthAgent: 一個用於工具增強型地理空間 Agent 的統一框架",
    "summary_zh": "多模態推理 (multimodal reasoning) 的最新進展使得 Agent 能夠解釋圖像、將其與語言連結並執行結構化分析任務。將此類能力擴展到遙感領域 (remote sensing domain) 仍然具有挑戰性，因為模型必須對空間尺度 (spatial scale)、地理結構 (geographic structures) 和多光譜指數 (multispectral indices) 進行推理，同時保持連貫的多步驟邏輯 (multi-step logic)。為彌補這一差距，OpenEarthAgent 引入了一個統一框架，用於開發經衛星訓練的工具增強型地理空間 Agent。"
  },
  "arxiv:2602.17634": {
    "story_id": "arxiv:2602.17634",
    "title_zh": "Reverso: 用於 Zero-shot 預測的高效 Time Series Foundation Models",
    "summary_zh": "學習 Time Series Foundation Models 已被證明是實現跨多樣化 Time Series Domains 的 zero-shot Time Series Forecasting 的一種有前景的方法。由於 Scaling 在語言和視覺等其他 Modalities 中一直是 Foundation Models 性能的關鍵驅動力，近期許多關於 Time Series Foundation Modeling 的工作都集中在 Scaling 上。這導致了具有數億個 Parameters 的 Time Series Foundation Models，這些模型雖然性能良好，但卻效率低下且昂貴。"
  },
  "arxiv:2602.17607": {
    "story_id": "arxiv:2602.17607",
    "title_zh": "AutoNumerics: 一個用於科學計算的自主、PDE-Agnostic Multi-Agent Pipeline",
    "summary_zh": "PDEs 是科學和工程建模的核心，但設計準確的 Numerical Solvers 通常需要大量的數學專業知識和手動調整。最近基於 Neural Network 的方法提高了靈活性，但通常需要高計算成本 (computational cost) 並受到可解釋性 (interpretability) 有限的影響。我們引入了 \texttt{AutoNumerics}，這是一個 Multi-Agent Framework，可以直接從 Natural Language 描述中自主設計、實施、調試和驗證通用 PDEs 的 Numerical Solvers。"
  },
  "arxiv:2602.17558": {
    "story_id": "arxiv:2602.17558",
    "title_zh": "RetouchIQ: 用於基於指令的影像修圖並具備通才獎勵的 MLLM Agents",
    "summary_zh": "多模態大型語言模型 (multimodal large language models, MLLMs) 的最新進展在將 Vision-Language Reasoning 擴展到專業工具型影像編輯方面展現出巨大潛力，實現了直觀和創新的編輯。一個有前景的方向是使用強化學習 (reinforcement learning, RL) 使 MLLMs 能夠在專業影像編輯軟體中推斷並執行最佳的工具使用計畫 (tool-use plans)。然而，由於缺乏可靠、可驗證的 Reward Signals 來反映其固有的特性，訓練仍然具有挑戰性。"
  },
  "arxiv:2602.17535": {
    "story_id": "arxiv:2602.17535",
    "title_zh": "LATA: 運用 Laplacian-Assisted Transductive Adaptation 改善醫學 VLM 中的 Conformal Uncertainty",
    "summary_zh": "醫學 Vision-Language Models (VLMs) 是醫學影像強大的 zero-shot 識別器，但它們在 Domain Shift 下的可靠性取決於具有保證的 calibrated uncertainty。Split Conformal Prediction (SCP) 提供了有限樣本覆蓋 (finite-sample coverage)，但預測集 (prediction sets) 通常會變得很大（效率低），且 Class-wise Coverage 不平衡 — Class-conditioned Coverage Gap (CCV) 很高，尤其是在 few-shot 和不平衡的狀況下；此外，天真地適應 Calibration Labels 會破壞 Exchangeability 和"
  },
  "arxiv:2602.17518": {
    "story_id": "arxiv:2602.17518",
    "title_zh": "Agentic Search 的圖景",
    "summary_zh": "隨著自動化系統越來越多地與人類一同發出搜尋查詢，資訊檢索 (IR) 面臨著重大轉變。然而，IR 仍然以人為中心，其系統、evaluation metrics、user models 和 datasets 都是圍繞人類查詢和行為設計的。因此，IR 在實踐中依賴的假設已不再適用，工作負載量、可預測性和查詢行為都發生了變化。這種不匹配影響了系統性能和最佳化：caching 可能會失去其效益。"
  },
  "arxiv:2602.17475": {
    "story_id": "arxiv:2602.17475",
    "title_zh": "用於醫療 NLP 的 Small LLMs：在義大利語中對 Few-Shot、Constraint Decoding、Fine-Tuning 和 Continual Pre-Training 的系統性分析",
    "summary_zh": "大型語言模型 (LLMs) 在各種醫療 Natural Language Processing (NLP) 任務中持續表現出色，然而，其龐大的計算需求經常限制了它們在實際醫療環境中的部署。在這項工作中，我們研究了「小型」LLMs（約十億參數）是否能在保持競爭性準確度的同時有效執行醫療任務。我們評估了來自 Llama-3、Gemma-3 和 Qwen3 這三個主要系列的模型，涵蓋了 20 項臨床 NLP 任務，其中包括 Named Entity Reco"
  },
  "arxiv:2602.17431": {
    "story_id": "arxiv:2602.17431",
    "title_zh": "針對長篇語言模型輸出的 Fine-Grained Uncertainty Quantification：一項比較研究",
    "summary_zh": "Uncertainty quantification 已成為 LLMs closed-book hallucination 檢測的一種有效方法，但現有方法主要為短篇輸出設計，未能很好地泛化到長篇生成。我們引入了一種用於長篇 LLM 輸出中 fine-grained uncertainty quantification 的分類法，該分類法根據三個階段的設計選擇來區分方法：response decomposition、unit-level scoring 和 response-level aggregation。我們形式化了幾類 consis"
  },
  "arxiv:2602.17410": {
    "story_id": "arxiv:2602.17410",
    "title_zh": "利用 Intermediate Layers 的 Self-Hard Negatives 改善基於 LLM 的推薦",
    "summary_zh": "大型語言模型 (LLMs) 在推薦系統中展現了巨大的潛力，其中 supervised fine-tuning (SFT) 通常用於適應。隨後的研究進一步引入了 preference learning，將 negative samples 納入訓練過程。然而，現有方法依賴於序列級別的、離線生成的 negatives，這使得它們在將 LLMs 適應到具有大型 negative item spaces 的推薦任務時，區分度較低且資訊量不足。為了應對這些挑戰，我們提"
  },
  "arxiv:2602.17316": {
    "story_id": "arxiv:2602.17316",
    "title_zh": "相同意義，不同分數：LLM 評估中的詞彙和句法敏感性",
    "summary_zh": "大型語言模型 (LLMs) 的快速發展已將標準化 evaluation benchmarks 確立為模型比較的主要工具。然而，由於對 input prompts 中淺層變化的敏感性，它們的可靠性受到越來越多的質疑。本文研究了受控的、在真值條件下等價的 lexical 和 syntactic perturbations 如何影響 23 種當代 LLMs 在 MMLU、SQuAD 和 AMEGA 這三個 benchmarks 上的絕對性能和相對排名。我們採用"
  },
  "arxiv:2602.17245": {
    "story_id": "arxiv:2602.17245",
    "title_zh": "Web Verbs：為代理式網路提供可靠任務組合的類型化抽象",
    "summary_zh": "網路正從人類瀏覽的媒介演變為軟體代理代表用戶執行操作的環境。大型語言模型 (LLMs) 的進步使得自然語言成為執行目標導向任務的實用介面，然而，大多數目前的網路代理仍舊在低階原語（例如點擊和鍵盤輸入）上操作。這些操作脆弱、效率低下且難以驗證。為了補充像 NLWeb 為檢索提供的 semantic layer 這類面向內容的工作，我們認為代理式網路"
  },
  "arxiv:2602.17203": {
    "story_id": "arxiv:2602.17203",
    "title_zh": "測試時的演算法共謀：一種元遊戲設計與評估",
    "summary_zh": "演算法共謀的威脅及其是否值得監管干預，仍然存在爭議，因為現有對其出現的評估通常依賴於長期的學習週期、關於對手在採用共謀策略方面的理性假設，以及參與者之間超參數和經濟環境的對稱性。為了研究共謀風險，我們引入了一種元遊戲設計，用於分析測試時限制下的演算法行為。我們將代理建模為具備預訓練策略"
  },
  "arxiv:2602.17183": {
    "story_id": "arxiv:2602.17183",
    "title_zh": "大型語言模型在長上下文程式碼問答中的魯棒性與推理忠實度",
    "summary_zh": "大型語言模型 (LLMs) 越來越多地協助需要對長程式碼上下文進行推理的軟體工程任務，然而，它們在不同輸入條件下的魯棒性仍不明確。我們透過使用受控消融（controlled ablations）進行了長上下文程式碼問答的系統性研究，這些消融測試了對答案格式、干擾項和上下文規模的敏感性。我們將 LongCodeBench Python 資料集擴展至包含新的 COBOL 和 Java 問答集，並在三種設定下評估了最先進的模型"
  },
  "arxiv:2602.17078": {
    "story_id": "arxiv:2602.17078",
    "title_zh": "透過 Epigraph Form 實現安全連續時間多代理強化學習",
    "summary_zh": "近年來，Multi-agent reinforcement learning (MARL) 已取得顯著進展，但大多數演算法仍然依賴於具有固定決策間隔的 discrete-time Markov Decision Process (MDP)。這種公式化方法通常不適用於複雜的 multi-agent 動態，特別是在高頻或不規則時間間隔的設定中，這會導致性能下降，並促使了 continuous-time MARL (CT-MARL) 的發展。現有的 CT-MARL 方法主要建立在 Hamilton-Jacobi-Be"
  },
  "arxiv:2602.17054": {
    "story_id": "arxiv:2602.17054",
    "title_zh": "ALPS：用於阿拉伯語語言學與語用推理的診斷挑戰集",
    "summary_zh": "雖然最近的阿拉伯語 NLP 基準測試側重於規模，但它們通常依賴於合成或翻譯的資料，這可能需要更深入的語言學驗證。我們推出了 ALPS (Arabic Linguistic & Pragmatic Suite)，這是一個原生的、由專家策劃的診斷挑戰集，旨在探究 Deep Semantics 和 Pragmatics，這些能力補充了專門的大規模基準測試。雖然廣泛覆蓋的基準測試優先考慮規模和 multi-task 覆蓋，ALPS 則透過 53"
  },
  "arxiv:2602.16953": {
    "story_id": "arxiv:2602.16953",
    "title_zh": "LLM4Cov: 用於高覆蓋率 Testbench 生成的執行感知 Agentic Learning",
    "summary_zh": "執行感知型 LLM agents 為從工具回饋中學習提供了一個有前景的範式，但這種回饋的獲取成本通常很高且速度緩慢，使得 online reinforcement learning (RL) 不切實際。高覆蓋率的硬體驗證正是這種挑戰的例證，因為它依賴於工業模擬器和 non-differentiable execution signals。我們提出了 LLM4Cov，這是一個 offline agent-learning 框架，它將驗證建模為由 deterministic evaluators 引導的無記憶狀態轉換。Bu"
  },
  "arxiv:2602.16915": {
    "story_id": "arxiv:2602.16915",
    "title_zh": "StereoAdapter-2: 全局結構一致的水下立體深度估計",
    "summary_zh": "立體深度估計對於水下機器人感知至關重要，但卻受到波長相關的光衰減、散射和折射引起的嚴重 domain shifts 影響。最近的方法利用 monocular foundation models 結合基於 GRU 的迭代細化進行水下適應；然而，GRU 中序列門控和局部卷積核需要多次迭代才能進行長距離 disparity propagation，這限制了在 large-disparity 和 textureless 水下區域的性能。在本文中，我們提出了 StereoAdapter-2，它用一種基於 selective state space models 的新型 ConvSS2D operator 取代了傳統的 ConvGRU updater。所提出的 operator 採用一種四方向掃描策略，該策略自然地與 epipolar geometry 對齊，同時捕獲垂直結構一致性，從而能夠在單個更新步驟中以 linear computational complexity 實現高效的長距離 spatial propagation。此外，我們構建了 UW-StereoDepth-80K，這是一個大型合成水下立體數據集，透過結合 semantic-aware style transfer 和 geometry-consistent novel view synthesis 的兩階段生成 pipeline，具有多樣的 baselines、attenuation coefficients 和 scattering parameters。結合從 StereoAdapter 繼承的 dynamic LoRA adaptation，我們的框架在水下基準測試中取得了 state-of-the-art 的 zero-shot 性能，在 TartanAir-UW 上提高了 17%，在 SQUID 上提高了 7.2%，並且在 BlueROV2 平台上進行的真實世界驗證證明了我們方法的穩健性。Code: https://github.com/AIGeeksGroup/StereoAdapter-2. Website: https://aigeeksgroup.github.io/StereoAdapter-2."
  },
  "arxiv:2602.16872": {
    "story_id": "arxiv:2602.16872",
    "title_zh": "DODO: 離散 OCR Diffusion Models",
    "summary_zh": "光學字符識別 (Optical Character Recognition, OCR) 是一項將資訊數位化的基本任務，是視覺數據和文本理解之間的關鍵橋樑。雖然現代 Vision-Language Models (VLM) 在此領域取得了高準確度，但它們主要依賴於 autoregressive decoding，這對於長文件來說計算成本高且速度慢，因為它需要為每個生成的 token 進行 sequential forward pass。我們發現了一個克服此瓶頸的關鍵機會：unlik"
  },
  "arxiv:2602.16844": {
    "story_id": "arxiv:2602.16844",
    "title_zh": "無需持續監督地監管 Agents：挑戰與機會",
    "summary_zh": "為了實現人類監督，agentic AI 系統通常會提供推理和行動步驟的 trace。設計具有資訊豐富但不至於過載的詳細程度的 trace 仍然是一個關鍵挑戰。在對 Computer User Agent 進行的三項用戶研究中，我們調查了基本 action traces 對於驗證的效用，透過 design probes 探索了三種替代方案，並測試了一個新型介面在問答任務中發現錯誤的影響。正如預期的那樣，我們發現當前的做法是"
  },
  "arxiv:2602.16819": {
    "story_id": "arxiv:2602.16819",
    "title_zh": "Hybrid-Gym：訓練 Coding Agents 以跨任務泛化",
    "summary_zh": "在評估 coding agents 的品質時，主要的基準測試專注於解決 GitHub 上的單一問題，例如 SWE-Bench。相比之下，在實際使用中，這些 agents 解決更為多樣和複雜的任務，這些任務涉及探索 codebases、測試軟體和設計 architecture 等其他技能。在本文中，我們首先透過將 trajectories 分解為 fine-grained components，來描述跨不同任務共享的一些 transferable skills，並導出了一套設計原則"
  },
  "arxiv:2602.16796": {
    "story_id": "arxiv:2602.16796",
    "title_zh": "透過 Flow Model Fine-Tuning 實現高效的尾部感知生成式最佳化",
    "summary_zh": "對預訓練的 diffusion 和 flow models 進行 fine-tuning 以最佳化下游應用（downstream utilities）是實際部署的關鍵。現有的 entropy-regularized methods 主要最大化預期獎勵（expected reward），但未能提供塑造 tail behavior 的機制。然而，tail control 通常至關重要：lower tail 透過限制低獎勵失敗（low-reward failures）來決定可靠性（reliability），而 upper tail 則透過優先考慮稀有、高獎勵的結果（rare, high-reward outcomes）來實現發現（discovery）。在這項工作中，我們提出了 Tail-aware Flow Fine-Tuning (TFFT)，一個p"
  },
  "arxiv:2602.16784": {
    "story_id": "arxiv:2602.16784",
    "title_zh": "分佈偏移下語言模型中的遺漏變數偏差",
    "summary_zh": "儘管現代 language models 在各種任務上表現出色，但它們在 distribution shifts 下仍然容易受到影響，當在與其 training data 分佈不同的數據上進行評估時，會表現出脆弱的行為。在本文中，我們描述了 language models 中的 distribution shifts 如何被分為可觀察（observable）和不可觀察（unobservable）兩部分，並討論了現有處理 distribution shift 的方法僅處理前者。重要的是，我們發現了tha"
  },
  "arxiv:2602.16702": {
    "story_id": "arxiv:2602.16702",
    "title_zh": "顯著性感知多路徑思維：重思視覺語言推理",
    "summary_zh": "Vision-language models (VLMs) 旨在透過共同利用視覺（visual）和文本（textual）模態（modalities）進行推理。雖然為 large language models (LLMs) 分配額外的 inference-time computation 已被證明是有效的，但在 VLMs 中實現類似的擴展仍然充滿挑戰。一個關鍵障礙是，視覺輸入（visual inputs）通常在生成開始時僅提供一次，而文本推理（textual reasoning）（例如，早期視覺摘要 early visual summaries）是 autoregressively 生成的，這導致推理越來越受到文本的主導"
  },
  "arxiv:2602.16671": {
    "story_id": "arxiv:2602.16671",
    "title_zh": "SPARC：用於自動化 C 語言單元測試生成的場景規劃與推理",
    "summary_zh": "由於高階程式意圖（high-level program intent）與指標算術（pointer arithmetic）和手動記憶體管理（manual memory management）的嚴格語法限制（syntactic constraints）之間存在語義鴻溝（semantic gap），C 語言的自動化 unit test generation 仍然是一個艱鉅的挑戰。雖然 Large Language Models (LLMs) 展現出強大的生成能力（generative capabilities），但直接的意圖到程式碼合成（intent-to-code synthesis）經常遭遇「跳躍式程式碼生成失敗模式」（leap-to-code failure mode），即模型在沒有依據程式結構（program structure）、約束（constraints）和語義（semantics）的情況下過早地輸出程式碼。這將導致n"
  },
  "arxiv:2602.16660": {
    "story_id": "arxiv:2602.16660",
    "title_zh": "一次對齊，多語受益：強制 LLM 安全對齊的多語言一致性",
    "summary_zh": "Large language models (LLMs) 在各個語言社群的廣泛部署，使得可靠的 multilingual safety alignment 成為必要。然而，最近將 alignment 擴展到其他語言的努力，通常需要大量的資源，無論是透過在 target language 中進行大規模、高品質的 supervision，還是透過與 high-resource languages 進行 pairwise alignment，這限制了 scalability。在這項工作中，我們提出了一種 resource-efficient method，用於改進 multilingual safety alignment。"
  },
  "arxiv:2602.16585": {
    "story_id": "arxiv:2602.16585",
    "title_zh": "DataJoint 2.0：代理式科學工作流程的計算基質",
    "summary_zh": "操作的嚴謹性決定了人類與代理的協作能否成功。科學數據管線需要類似於 DevOps 的 SciOps，然而，常見的方法在不具備 transactional guarantees 的孤立系統中分散了 provenance。DataJoint 2.0 透過關係型工作流程模型解決了這個問題：表格代表 workflow steps，行代表 artifacts，foreign keys 規定了 execution order。其 schema 不僅指定了存在哪些 data，還指定了其衍生方式——"
  },
  "arxiv:2602.16467": {
    "story_id": "arxiv:2602.16467",
    "title_zh": "IndicEval：一個用於大型語言模型的雙語印度教育評估框架",
    "summary_zh": "大型語言模型 (LLMs) 的快速進步，使得需要反映真實世界學術嚴謹性和多語言複雜性的評估框架。本文介紹了 IndicEval，一個可擴展的 benchmarking 平台，旨在利用來自 UPSC、JEE 和 NEET 的真實 high-stakes 考試題目，在 STEM 和人文領域，以英語和印地語雙語評估 LLM 的性能。與 synthetic benchmarks 不同，IndicEval 將評估建立在真實的考試標準上，實現了現實主義的"
  },
  "arxiv:2602.16429": {
    "story_id": "arxiv:2602.16429",
    "title_zh": "TabAgent：一個用表格-文本分類器替換代理式生成組件的框架",
    "summary_zh": "Agentic systems，即自主執行 multi-step workflows 以實現 complex goals 的 AI architectures，通常透過重複呼叫 large language model (LLM) 來處理 closed-set decision tasks，例如 routing、shortlisting、gating 和 verification。儘管這種設計很方便，但由於 cumulative latency 和 token usage，使得 deployments 變得緩慢且昂貴。我們提出了 TabAgent，一個用於在 closed-set selection tasks 中用緊湊的 textual-t 替換 generative decision components 的框架。"
  },
  "arxiv:2602.16412": {
    "story_id": "arxiv:2602.16412",
    "title_zh": "ReMoRa：基於精煉運動表示的用於長影片理解的多模態大型語言模型",
    "summary_zh": "儘管 Multimodal Large Language Models (MLLMs) 在各種任務中取得了顯著成功，但 long-form video understanding 仍然是一個巨大挑戰。在本研究中，我們專注於 MLLMs 的 video understanding。這項任務之所以具有挑戰性，是因為處理完整的 RGB 幀流在計算上是 intractable 且高度 redundant 的，因為 self-attention 的複雜度與 sequence length 呈二次方關係。在本文中，我們提出了 ReMoRa，這是一個透過操作來處理影片的 video MLLM。"
  },
  "arxiv:2602.16241": {
    "story_id": "arxiv:2602.16241",
    "title_zh": "LLMs 準備好取代孟加拉語標註者了嗎？",
    "summary_zh": "大型語言模型 (LLMs) 越來越多地被用作 automated annotators，以擴展 dataset creation，然而，它們作為 unbiased annotators 的可靠性——尤其是在 low-resource 和 identity-sensitive settings 下——仍知之甚少。在本研究中，我們探討了 LLMs 作為 Bangla hate speech 的 zero-shot annotators 的行為，這是一項即使人類共識也充滿挑戰，且 annotator bias 可能導致嚴重 downstream consequences 的任務。我們使用一個統一的標準，對 17 個 LLMs 進行了系統性的 benchmark。"
  },
  "arxiv:2602.16745": {
    "story_id": "arxiv:2602.16745",
    "title_zh": "PETS: 一個旨在實現高效 Test-Time Self-Consistency 的最佳軌跡分配原則性框架",
    "summary_zh": "Test-time scaling 可以透過聚合隨機推理軌跡來提高模型性能。然而，在有限預算下實現樣本高效的 Test-Time Self-Consistency 仍然是一個開放的挑戰。我們引入了 PETS (Principled and Efficient Test-Time Self-Consistency)，它透過一個優化框架，啟動了對軌跡分配的原則性研究。我們方法的關鍵是 self-consistency rate，這是一個新測量指標，定義為與無限預算多數意見的一致性。"
  },
  "arxiv:2602.16131": {
    "story_id": "arxiv:2602.16131",
    "title_zh": "用於基於 LLM 的 Agent 系統分析的經驗累積分佈函數聚類",
    "summary_zh": "大型語言模型 (LLMs) 正日益被用作 agent 來解決複雜任務，例如問答 (QA)、科學辯論和軟體開發。標準的評估程序會將來自 LLM agent 的多個響應彙總成單一最終答案，通常透過多數投票，並與參考答案進行比較。然而，這個過程可能會掩蓋原始響應的品質和分佈特性。在本文中，我們提出了一個新穎的評估框架。"
  },
  "arxiv:2602.16503": {
    "story_id": "arxiv:2602.16503",
    "title_zh": "透過精準的局部可加模型和條件特徵效應實現設計即解釋性",
    "summary_zh": "廣義可加模型 (GAMs) 透過獨立的單變量特徵效應提供解釋性，但在數據中存在交互作用時會出現欠擬合。GA$^2$Ms 增加了選定的成對交互作用，提高了準確性，但犧牲了解釋性並限制了模型審計。我們提出了 Conditionally Additive Local Models (CALMs)，這是一種新的模型類別，它平衡了 GAMs 的解釋性與 GA$^2$Ms 的準確性。CALMs 允許每個特徵具有多個單變量形狀函數。"
  },
  "arxiv:2602.16548": {
    "story_id": "arxiv:2602.16548",
    "title_zh": "RIDER: 結合強化學習引導的 Diffusion 進行 3D RNA 逆向設計",
    "summary_zh": "RNA 三維 (3D) 結構的逆向設計對於合成生物學和治療學中功能性 RNA 的工程設計至關重要。儘管最近的深度學習方法已推動該領域的發展，但它們通常是使用原始序列恢復進行優化和評估的，這對於結構保真度來說是一個有限的替代指標，因為不同的序列可以摺疊成相似的 3D 結構，並且高恢復率不一定表示正確摺疊。為了解決這個限制，我們提出了一種方法。"
  },
  "arxiv:2602.16554": {
    "story_id": "arxiv:2602.16554",
    "title_zh": "MerLean: 一個用於量子計算自動形式化的 Agentic 框架",
    "summary_zh": "我們介紹 MerLean，一個用於量子計算自動形式化的全自動 agentic 框架。MerLean 從 \\LaTeX{} 源文件中提取數學陳述，將其形式化為基於 Mathlib 的經驗證的 Lean~4 代碼，並將結果翻譯回人類可讀的 \\LaTeX{} 以進行語義審查。我們在三篇理論量子計算論文上評估了 MerLean，總共從 114 個陳述中產生了 2,050 個 Lean 宣告。MerLean 在所有三篇論文上實現了端到端形式化。"
  },
  "arxiv:2602.17659": {
    "story_id": "arxiv:2602.17659",
    "title_zh": "當視覺凌駕於語言：評估並緩解 VLA 中的反事實失敗",
    "summary_zh": "Vision-Language-Action models (VLAs) 承諾將語言指令實現在機器人控制中，然而在實踐中卻經常未能忠實地遵循語言。當提供缺乏強烈場景特定監督的指令時，VLAs 會遭遇 counterfactual failures：它們基於由 dataset biases 引起的視覺捷徑行事，重複執行訓練中常見的習得行為並選擇訓練中經常見到的物體，而無論語言意圖為何。為系統性地研究此現象，我們引入"
  },
  "arxiv:2602.17510": {
    "story_id": "arxiv:2602.17510",
    "title_zh": "LORA-CRAFT: 透過預訓練 Attention Weights 的凍結 Tucker 分解實現跨層級秩適應",
    "summary_zh": "我們介紹 CRAFT (Cross-layer Rank Adaptation via Frozen Tucker)，這是一種 parameter-efficient fine-tuning (PEFT) 方法，它將 Tucker tensor decomposition 應用於堆疊在 transformer layers 上的預訓練 attention weight matrices，並且僅在由此產生的 frozen Tucker factors 上訓練小的方形 adaptation matrices。現有的 tensor-based PEFT 方法分解 gradient updates：LoTR 應用帶有共享 factor matrices 的 Tucker decomposition，而 SuperLoRA 則跨層級對 $ΔW$ 進行分組和重塑。"
  },
  "arxiv:2602.17386": {
    "story_id": "arxiv:2602.17386",
    "title_zh": "Visual Model Checking: 圖像檢索中視覺例程的圖形化推斷",
    "summary_zh": "Information retrieval 是現代數位產業的基石。儘管 natural language search 近年來在 embedding-based models 和 large-scale pretraining 的大力推動下取得了顯著進展，但該領域仍面臨重大挑戰。具體來說，涉及複雜關係、物體組成或精確約束（例如身份、計數和比例）的查詢在當前框架內通常仍無法解決或不可靠。在本文中，我們提出"
  },
  "arxiv:2602.16183": {
    "story_id": "arxiv:2602.16183",
    "title_zh": "在 Bandit Feedback 下用於次模福利問題的 Multi-Agent Combinatorial-Multi-Armed-Bandit 框架",
    "summary_zh": "我們研究 \\emph{Submodular Welfare Problem} (SWP)，其中物品在具有 monotone submodular utilities 的 agent 之間分配，以在 \\emph{bandit feedback} 下最大化總福利。經典的 SWP 假設完全的 value-oracle access，透過 continuous-greedy algorithms 實現 $(1-1/e)$ 近似。我們將此擴展到一個 \\emph{multi-agent combinatorial bandit} 框架 (\textsc{MA-CMAB})，其中 actions 是在 full-bandit feedback 下的分割，並由不通訊的 agents 執行。與以往不同的是"
  },
  "arxiv:2602.16832": {
    "story_id": "arxiv:2602.16832",
    "title_zh": "IndicJR: 針對南亞語言 Jailbreak Robustness 的無評審基準",
    "summary_zh": "large language models (LLMs) 的 Safety alignment 主要在 English 和 contract-bound 情況下進行評估，使得 multilingual vulnerabilities 缺乏深入研究。我們引入 \textbf{Indic Jailbreak Robustness (IJR)}，這是一個針對 12 種 Indic 和 South Asian languages (2.1 Billion 說話者) 的 adversarial safety 的 judge-free benchmark，涵蓋 JSON (contract-bound) 和 Free (naturalistic) 軌道中的 45216 個 prompts。\n  IJR 揭示了三種模式。(1) Contracts 誇大了拒絕率但未能阻止 jailbreaks：在 JSON 中，LLa"
  },
  "arxiv:2602.16634": {
    "story_id": "arxiv:2602.16634",
    "title_zh": "增強式 Diffusion 採樣：利用 Diffusion Models 進行高效稀有事件採樣與自由能計算",
    "summary_zh": "稀有事件採樣問題長期以來一直是 molecular dynamics (MD)，特別是 biomolecular simulation 中的核心限制因素。近來，諸如 BioEmu 等 diffusion models 已成為強大的 equilibrium samplers，能夠從複雜的 molecular distributions 生成獨立樣本，從而消除了採樣稀有過渡事件的成本。然而，當計算依賴於 equilibrium 中稀有狀態的 observables 時，例如 folding free energy，採樣問題依然存在。"
  },
  "arxiv:2602.17525": {
    "story_id": "arxiv:2602.17525",
    "title_zh": "透過徑向傳輸的 Variational Inference",
    "summary_zh": "在 variational inference (VI) 中，實踐者通常使用一個簡單的替代分佈，常是一個 (product) Gaussian distribution，來近似高維分佈 $π$。然而，在許多實際應用中，Gaussian distributions 可能無法捕捉到 $π$ 的正確 radial profile，導致 coverage 不佳。在這項工作中，我們從優化這些 radial profiles 的角度來解決 VI 問題。我們的演算法 radVI 是一個經濟且有效的 add-on，可應用於許多現有的 VI schemes，s"
  },
  "arxiv:2602.17434": {
    "story_id": "arxiv:2602.17434",
    "title_zh": "透過懲罰函數與 Block-Coordinate Optimization 的多智能體時序邏輯規劃",
    "summary_zh": "在 Signal Temporal Logic (STL) 下的多智能體規劃常受限於協作任務，這些任務因問題固有的高維性而帶來計算挑戰，阻礙了具有 satisfaction guarantees 的可擴展合成。為了解決這個問題，我們將 STL 規劃 форму化為一個在任意 multi-agent 限制下的優化程式，並引入了一種基於懲罰的 unconstrained relaxation，它可透過 Block-Coordinate Gradient Descent (BCGD) 方法有效求解，"
  },
  "arxiv:2602.17413": {
    "story_id": "arxiv:2602.17413",
    "title_zh": "DAVE：用於安全多文件數據共享的策略強制性 LLM 發言人",
    "summary_zh": "在當前的跨組織數據空間中，使用策略主要在 asset level 執行：整個文件或 dataset 要麼被共享，要麼被保留。當文件只有部分內容敏感時，希望避免洩露受保護信息的提供者通常必須在共享之前手動編輯 (redact) 文件，這既昂貴又粗糙 (coarse-grained)，且難以隨著策略或合作夥伴的變化而維護。我們提出了 DAVE，這是一個強制執行使用策略的 LLM 發言人，它能回答關於私有"
  },
  "arxiv:2602.17565": {
    "story_id": "arxiv:2602.17565",
    "title_zh": "Ridge Regression 中無約束 Self-Distillation 的最佳化：嚴格改進、精確漸近性與 One-Shot Tuning",
    "summary_zh": "Self-distillation (SD) 是一種使用相同 architecture 和 training data，在 ground-truth labels 與 teacher 自身預測的混合物上重新訓練 student 的過程。儘管 SD 在實證上常被證明能提高 generalization，但其形式化的保證仍然有限。我們研究了在 unconstrained setting 中 ridge regression 的 SD，其中 mixing weight $ξ$ 可能位於 unit interval 之外。在訓練數據的條件下且沒有任何 distributional assumptions，我們證明了"
  },
  "arxiv:2602.17443": {
    "story_id": "arxiv:2602.17443",
    "title_zh": "AIDG：評估多輪對話中資訊提取與資訊抑制之間的不對稱性",
    "summary_zh": "評估 Large Language Models (LLMs) 的策略推理能力需要從靜態基準測試轉向動態的 multi-turn interactions。我們引入了 AIDG (Adversarial Information Deduction Game)，這是一個 game-theoretic 框架，旨在探究對話中 information extraction (主動推斷) 和 information containment (狀態維護) 之間的不對稱性。我們提出了兩項互補的任務：AIDG-I，用於衡量 social deduction 中的 pragmatic strategy；以及 AIDG-II，用於衡量 c"
  },
  "arxiv:2602.17106": {
    "story_id": "arxiv:2602.17106",
    "title_zh": "邁向永續性評級方法論的可信評估：一個用於基準數據集建構的人機協作框架",
    "summary_zh": "永續性或 ESG 評級機構利用公司披露資料和外部數據來產生評分或評級，以評估公司的環境、社會和治理績效。然而，單一公司在不同機構之間的永續性評級差異很大，這限制了它們的可比性、可信度和與決策的相關性。為了協調評級結果，我們建議採用一個通用的 human-AI collaboration framework 來生成可信賴的 benchmark datasets 以進行評估"
  },
  "arxiv:2602.16974": {
    "story_id": "arxiv:2602.16974",
    "title_zh": "超越 Chunk-Then-Embed：資訊檢索中文檔分塊策略的綜合分類與評估",
    "summary_zh": "Document chunking 是 dense retrieval systems 中一個關鍵的預處理步驟，然而，分塊策略的設計空間仍未被充分理解。最近的研究提出了幾種並行方法，包括 LLM-guided methods (例如：DenseX 和 LumberChunker) 和 contextualized strategies (例如：Late Chunking)，它們在 segmentation 之前生成 embeddings 以保留 contextual information。然而，這些方法是獨立出現的，並且在 minimal ove 的基準測試上進行了評估"
  },
  "arxiv:2602.16938": {
    "story_id": "arxiv:2602.16938",
    "title_zh": "ConvApparel：用於對話式推薦系統中使用者模擬器的基準數據集與驗證框架",
    "summary_zh": "LLM-based user simulators 改善 conversational AI 的前景受阻於一個關鍵的「realism gap」，導致系統雖然為 simulated interactions 而優化，但在真實世界中可能表現不佳。我們引入了 ConvApparel，一個旨在解決此問題的新 human-AI conversations 數據集。其獨特的 dual-agent data collection protocol —— 同時使用「good」和「bad」recommenders —— 透過捕捉廣泛的使用者體驗來實現 counterfactual validation，e"
  },
  "arxiv:2602.16449": {
    "story_id": "arxiv:2602.16449",
    "title_zh": "GICDM：緩解中心性 (Hubness) 以實現可靠的基於距離的生成模型評估",
    "summary_zh": "Generative model evaluation 通常依賴於 high-dimensional embedding spaces 來計算樣本之間的距離。我們發現這些空間中的 dataset representations 會受到 hubness phenomenon 的影響，這會扭曲 nearest neighbor relationships 並偏差 distance-based metrics。基於經典的 Iterative Contextual Dissimilarity Measure (ICDM)，我們引入了 Generative ICDM (GICDM)，這是一種用於校正真實數據和生成數據的 neighborhood estimation 的方法。我們引入了一個"
  },
  "arxiv:2602.17653": {
    "story_id": "arxiv:2602.17653",
    "title_zh": "語言模型處理差異論元標記時的類型學對齊差異",
    "summary_zh": "近期研究表明，在合成語料庫上訓練的語言模型 (LMs) 可以表現出與人類語言中的跨語言規律性相似的類型學偏好，特別是對於詞序等句法現象。在本文中，我們將此範式擴展到差異論元標記 (DAM)，這是一種語義許可系統，其中形態標記取決於語義顯著性。我們使用受控的合成學習方法，在 18 個實現了 GPT-2 模型的語料庫上進行訓練。"
  },
  "arxiv:2602.16320": {
    "story_id": "arxiv:2602.16320",
    "title_zh": "RefineFormer3D：通過自適應多尺度 Transformer 與交叉注意力融合實現高效 3D 醫學圖像分割",
    "summary_zh": "準確且計算高效的 3D 醫學圖像分割在臨床工作流程中仍然是一個關鍵挑戰。基於 Transformer 的架構通常展現出優越的全局上下文建模能力，但代價是過多的參數數量和記憶體需求，這限制了它們的臨床部署。我們提出了 RefineFormer3D，這是一個輕量級的分層 Transformer 架構，可在體積醫學影像中平衡分割準確性和計算效率。該架構"
  },
  "arxiv:2602.17555": {
    "story_id": "arxiv:2602.17555",
    "title_zh": "GraphThinker：以事件圖思維強化影片推理",
    "summary_zh": "影片推理需要理解影片中事件之間的因果關係。然而，這些關係通常是隱含的，且手動註釋成本高昂。雖然現有的多模態大型語言模型 (MLLMs) 通常通過密集描述或影片摘要來推斷事件關係以進行影片推理，但這種建模仍然缺乏因果理解。如果沒有對影片事件內部和之間的明確因果結構建模，這些模型在影片推理過程中會出現幻覺問題。"
  },
  "arxiv:2602.17529": {
    "story_id": "arxiv:2602.17529",
    "title_zh": "使用動態知識圖譜和可解釋的 Retrieval-Augmented Generation 增強電信領域的 Large Language Models (LLMs)",
    "summary_zh": "Large language models (LLMs) 已在各種任務中展現出強大潛力，但由於領域複雜性、不斷演進的標準和專業術語，它們在電信領域的應用仍然充滿挑戰。因此，通用領域的 LLMs 可能難以在此背景下提供準確可靠的輸出，導致幻覺增加並降低電信營運中的實用性。為了解決這些限制，本研究引入了 KG-RAG——一個整合了知識的新穎框架。"
  },
  "arxiv:2602.17465": {
    "story_id": "arxiv:2602.17465",
    "title_zh": "用於語言模型的基於熵的資料選擇",
    "summary_zh": "現代語言模型 (LMs) 越來越需要兩種關鍵資源：計算資源和資料資源。資料選擇技術可以有效減少 fine-tuning LMs 所需的訓練資料量。然而，它們的有效性與計算資源密切相關，這總是需要高昂的計算預算。由於實際 fine-tuning 情境中的資源限制，我們系統地揭示了資料選擇與不確定性估計之間的關係。"
  },
  "arxiv:2602.17419": {
    "story_id": "arxiv:2602.17419",
    "title_zh": "EAGLE：用於多模態大型語言模型中免調校工業異常檢測的專家增強注意力引導",
    "summary_zh": "工業異常檢測對於智慧製造至關重要，但許多 deep learning 方法僅產生二元決策並提供有限的語義解釋。Multimodal large language models (MLLMs) 有潛力生成細粒度、基於語言的分析，然而現有方法通常需要耗費成本的 fine-tuning，並且與輕量級的 specialist detectors 相比，未能持續提高異常檢測的準確性。我們提出了一種用於工業的 expert-augmented attention guidance 方法。"
  },
  "arxiv:2602.17342": {
    "story_id": "arxiv:2602.17342",
    "title_zh": "從細微到顯著：Prompt 驅動的測試時圖 OOD 檢測中的自我改進優化",
    "summary_zh": "Graph Out-of-Distribution (OOD) detection 旨在識別測試圖是否偏離訓練期間觀察到的圖的分佈，這對於確保 Graph Neural Networks (GNNs) 在開放世界場景中部署時的可靠性至關重要。圖 OOD detection 的最新進展側重於 test-time training 技術，這些技術無需訪問潛在的監督信息（例如 training data）即可促進 OOD detection。然而，這些方法大多採用 one-p"
  },
  "arxiv:2602.17271": {
    "story_id": "arxiv:2602.17271",
    "title_zh": "用於多用戶語義通訊的聯邦潛在空間對齊",
    "summary_zh": "Semantic communication 旨在傳達意義以實現有效的任務執行，但 AI-native 設備中不同的 latent representations 可能導致語義不匹配，從而阻礙相互理解。本文提出了一種新穎的方法，用於緩解多代理 AI-native semantic communications 中的 latent space misalignment。在 downlink 情境中，我們考慮一個 access point (AP) 與多個用戶通訊以完成特定的 AI-driven 任務。我們的方法實施了一個協定，該協定 sh"
  },
  "arxiv:2602.17068": {
    "story_id": "arxiv:2602.17068",
    "title_zh": "用於以人為本多模態廊道交通號誌控制的時空雙階段超圖 MARL",
    "summary_zh": "廊道網路中以人為本的 traffic signal control 必須越來越多地考慮多模態旅客，特別是高載客量的公共交通，而不是僅僅關注以車輛為中心的性能。本文提出了 STDSH-MARL (Spatio-Temporal Dual-Stage Hypergraph based Multi-Agent Reinforcement Learning)，這是一個可擴展的 multi-agent deep reinforcement learning 框架，遵循 centralized training 和 decentralized execution 範式。所提出的方法捕捉了 sp"
  },
  "arxiv:2602.17045": {
    "story_id": "arxiv:2602.17045",
    "title_zh": "大型語言模型在不具備規劃心智理論的情況下進行說服",
    "summary_zh": "越來越多的研究試圖使用靜態、非互動式的問答基準來評估人類和 large language models (LLMs) 的 theory of mind (ToM) 能力。然而，該領域的理論研究表明，第一人稱互動是 ToM 的關鍵部分，並且此類預測性、旁觀性任務可能無法評估它。我們通過一個新穎的 ToM 任務來解決這一空白，該任務要求代理者通過策略性地說服目標選擇三項政策提案中的一項。"
  },
  "arxiv:2602.16936": {
    "story_id": "arxiv:2602.16936",
    "title_zh": "異質聯邦式微調與並行單秩適應",
    "summary_zh": "大型語言模型（LLMs）透過 fine-tuning 在適應下游任務方面展現出卓越的效能。Federated Learning (FL) 透過利用 Low-Rank Adaptation (LoRA) 實現分佈式客戶端之間的協同 fine-tuning，同時透過避免原始數據共享來保護數據隱私，從而擴展了此能力。然而，當客戶端擁有異質資源並因此採用不同的 LoRA ranks 時，實際部署會面臨挑戰，導致大量的初始化與"
  },
  "arxiv:2602.16626": {
    "story_id": "arxiv:2602.16626",
    "title_zh": "針對MEG Foundation Models的樣本級別Tokenization策略之系統性評估",
    "summary_zh": "自然語言處理的近期成功激發了人們對神經影像數據大型 foundation models 的日益增長興趣。此類模型通常需要對連續神經時間序列數據進行離散化，這一過程稱為 'tokenization'。然而，對於神經數據的不同 tokenization 策略的影響目前尚不清楚。在這項工作中，我們提出對基於 transformer 的大型神經影像模型 (LNM) 的樣本級別 tokenization 策略進行系統性評估"
  },
  "arxiv:2602.17594": {
    "story_id": "arxiv:2602.17594",
    "title_zh": "AI Gamestore：透過人類遊戲對機器通用智慧進行可擴展、開放式評估",
    "summary_zh": "在當今技術快速進步的時代，嚴格評估機器智慧與人類通用智慧的廣泛範圍變得日益重要和具有挑戰性。傳統的 AI benchmarks 通常僅評估人類活動有限範圍內的狹窄能力。大多數也都是靜態的，隨著開發人員明確或隱式地為其進行最佳化而迅速飽和。我們提出，評估 AI 系統中類人通用智慧的一個更有前景的方法是透過"
  },
  "arxiv:2602.16162": {
    "story_id": "arxiv:2602.16162",
    "title_zh": "LLMs 在創意寫作中的不確定性顯著低於專業作家",
    "summary_zh": "我們認為不確定性是 LLMs 在創意寫作中一個關鍵且未被充分研究的限制，而這種寫作常被描述為陳腐和充滿 clichés。文學理論將不確定性視為創意表達的必要條件，而當前的 alignment strategies 則引導模型遠離不確定的輸出，以確保事實性並減少 hallucination。我們透過量化人類創作故事與模型生成續寫之間的「不確定性差距」（\"uncertainty gap\"）來形式化這種張力"
  },
  "arxiv:2602.16742": {
    "story_id": "arxiv:2602.16742",
    "title_zh": "DeepVision-103K：一個視覺多樣、覆蓋廣泛且可驗證的數學資料集，用於多模態推理",
    "summary_zh": "Reinforcement Learning with Verifiable Rewards (RLVR) 已被證明能有效增強大型多模態模型 (LMMs) 的視覺反思和推理能力。然而，現有 dataset 主要來源於小規模手動建構或先前資源的重新組合，這限制了數據的多樣性和覆蓋範圍，從而制約了模型性能的進一步提升。為此，我們介紹了 \textbf{DeepVision-103K}，一個用於 RLVR 訓練的綜合性 dataset"
  },
  "arxiv:2602.17215": {
    "story_id": "arxiv:2602.17215",
    "title_zh": "NotebookRAG：檢索多個 Notebook 以增強 EDA Notebooks 的生成，實現群體智慧",
    "summary_zh": "高品質的 exploratory data analysis (EDA) 在 data science 流程中至關重要，但它仍然高度依賴分析師的專業知識和努力。儘管近期基於 LLM 的方法部分減輕了這一負擔，但當使用者意圖抽象時，它們在生成有效的分析計畫、適當的洞察和視覺化方面仍面臨困難。同時，跨平台和組織生成的大量分析 Notebook 包含豐富的分析知識，這些知識潛在地可以指導自動化生成。"
  },
  "arxiv:2602.17206": {
    "story_id": "arxiv:2602.17206",
    "title_zh": "SoftDTW-CUDA-Torch：適用於 PyTorch 的記憶體高效 GPU 加速 Soft Dynamic Time Warping",
    "summary_zh": "我們介紹了 softdtw-cuda-torch，這是一個用於在 GPU 上計算 Soft Dynamic Time Warping (SoftDTW) 的開源 PyTorch 函式庫。我們的實作解決了現有 SoftDTW GPU 實作的三個關鍵限制：1024 的硬性序列長度上限、在反向傳播 (backward pass) 中對小平滑參數的數值不穩定性，以及從實體化成對距離張量 (pairwise distance tensors) 產生過度的 GPU 記憶體消耗。我們引入了 (1) 瓦片式反對角核心執行 (tiled anti-diagonal kernel execution)，它消除了序列長度限制。"
  },
  "arxiv:2602.16851": {
    "story_id": "arxiv:2602.16851",
    "title_zh": "MxDiffusion：一種物理感知並由 Maxwells Law 引導的 Diffusion Model 策略，用於逆向光子超表面設計",
    "summary_zh": "我們介紹了 MxDiffusion，這是一個混合物理和資料驅動的基於 Diffusion 的框架，它能夠從目標光學特性高效且高度準確地生成光子結構。這種改進的準確性是透過兩階段生成策略實現的，其中第一個 diffusion model 透過基於 Maxwells equation 的 loss 進行明確訓練，以將物理洞察直接嵌入到 inverse design 過程中，而第二個模型則映射了物理上一致的中間表示。"
  },
  "arxiv:2602.16793": {
    "story_id": "arxiv:2602.16793",
    "title_zh": "逃離認知困境：使用現成模型進行高效的競技數學",
    "summary_zh": "在過去一年中，客製化和未發布的數學推理模型在 International Mathematical Olympiad (IMO) 中達到了金牌表現。隨後，使用公開可用模型進行大規模 inference 也報告了類似的性能，但成本過高（例如，每個問題 3000 美元）。在這項工作中，我們提出了一個 inference pipeline，它在 IMO 風格的數學問題上實現了一流的性能，其平均 inference 成本比競爭方法低幾個數量級，同時僅使用通用模型。"
  },
  "arxiv:2602.17357": {
    "story_id": "arxiv:2602.17357",
    "title_zh": "Astra：AI 安全、信任與風險評估",
    "summary_zh": "本文認為，現有的全球 AI 安全框架對印度獨特的社會技術景觀表現出情境盲點。印度擁有 15 億人口和龐大的非正規經濟，其 AI 整合面臨著特定的挑戰，例如基於種姓的歧視、地方語言使用者的語言排斥，以及低連接性農村地區的基礎設施故障，這些問題常被西方以市場為中心的敘事所忽視。我們介紹了 ASTRA，這是一個基於經驗的框架。"
  },
  "fallback:328a53729df06635": {
    "story_id": "fallback:328a53729df06635",
    "title_zh": "評估 AI agents：在 Amazon 構建 agentic 系統的實務經驗",
    "summary_zh": "在本文中，我們提出了一個針對 Amazon agentic AI 系統的綜合評估框架，該框架透過兩個核心組成部分解決了 Amazon agentic AI 應用程序的複雜性：一個通用的 evaluation workflow，用於標準化不同 agent 實作的評估程序；以及一個 agent evaluation library，它在 Amazon Bedrock AgentCore Evaluations 中提供系統性的測量和 metrics，並結合了 Amazon 特定 use case 的評估方法和 metrics。"
  },
  "fallback:70b04b512e5b8d61": {
    "story_id": "fallback:70b04b512e5b8d61",
    "title_zh": "媒體真實性方法實踐：能力、限制與方向",
    "summary_zh": "隨著 synthetic media 的增長，驗證內容的真實性和來源變得比以往任何時候都更加重要。我們最新的報告探討了 media integrity 和 authentication methods、它們的局限性，以及在圖像、音訊和視訊中實現可信 provenance 的實用途徑。"
  },
  "arxiv:2602.17442": {
    "story_id": "arxiv:2602.17442",
    "title_zh": "WarpRec：整合學術嚴謹性與工業規模，實現負責任、可重現且高效的推薦",
    "summary_zh": "Recommender Systems 的創新目前受到支離破碎的生態系統的阻礙，研究人員必須在便捷的 in-memory 實驗與分散式工業引擎所需的昂貴且複雜的重寫之間做出選擇。為彌合這一差距，我們提出了 WarpRec，這是一個高性能框架，它通過一種新穎的 backend-agnostic 架構消除了這種權衡。它包含了 50 多種 state-of-the-art algorithms、40 種 metrics 以及 19 種 filtering 和 splitting strategies，這些策略無縫地..."
  },
  "arxiv:2602.17414": {
    "story_id": "arxiv:2602.17414",
    "title_zh": "使用 Slice-within-Gibbs 的 Nested Sampling：分層貝葉斯模型的有效證據計算",
    "summary_zh": "我們提出了帶有 Slice-within-Gibbs (NS-SwiG) 的 Nested Sampling，這是一種用於高維模型中貝葉斯推斷和證據估計的演算法，其 likelihood 允許因式分解，例如 hierarchical Bayesian models。我們構建了一個程序，使用 Slice-within-Gibbs kernel 從 likelihood-constrained prior 中採樣：一個 hyperparameters 的外部更新，接著是 local parameters 的內部 block updates。一個 likelihood-budget decomposition 緩存了每個 block 的貢獻，以便..."
  },
  "arxiv:2602.17284": {
    "story_id": "arxiv:2602.17284",
    "title_zh": "子採樣和隨機分配的有效隱私損失核算",
    "summary_zh": "我們考慮了一種採樣方案的 privacy amplification 特性，其中用戶的數據在從 $t$ 個步驟序列（或集合）中隨機且均勻選擇的 $k$ 個步驟中使用。這種採樣方案最近已被應用於 differentially private optimization (Chua et al., 2024a; Choquette-Choo et al., 2025) 和 communication-efficient high-dimensional private aggregation (Asi et al., 2025) 的背景下，並顯示出其優於標準 Poisson sampling 的 utility 優勢。"
  },
  "arxiv:2602.17264": {
    "story_id": "arxiv:2602.17264",
    "title_zh": "關於對話式推薦系統之使用者中心評估的可靠性",
    "summary_zh": "「使用者中心評估」(User-centric evaluation) 已成為評估「對話式推薦系統」(Conversational Recommender Systems, CRS) 的關鍵範式，旨在捕捉滿意度、信任和融洽關係等主觀品質。為了實現可擴展的評估，近期研究越來越依賴於由 crowd workers 或 large language models 對靜態對話日誌進行第三方註釋。然而，這種做法的可靠性在很大程度上仍未被檢視。在本文中，我們提出了一項大規模實證研究，旨在調查其可靠性。"
  },
  "arxiv:2602.17599": {
    "story_id": "arxiv:2602.17599",
    "title_zh": "Art2Mus：透過視覺條件化和大規模跨模態對齊的藝術作品到音樂生成",
    "summary_zh": "音樂生成透過 multimodal deep learning 已取得顯著進展，使模型能夠從文字，以及最近從圖像合成音訊。然而，現有的 image-conditioned 系統存在兩個根本性限制：(i) 它們通常在 natural photographs 上進行訓練，限制了其捕捉藝術作品中更豐富的語義、風格和文化內容的能力；(ii) 大多數依賴於 image-to-text 轉換階段，將 language 作為 semantic shortcut，簡化了。"
  },
  "arxiv:2602.17481": {
    "story_id": "arxiv:2602.17481",
    "title_zh": "ShadAR：LLM 驅動的著色器生成，以轉變擴增實境中的視覺感知",
    "summary_zh": "Augmented Reality (AR) 可以模擬各種視覺感知，例如色盲人士如何看待世界。然而，這些模擬要求開發者預先定義每個視覺效果，這限制了靈活性。我們提出了 ShadAR，一個 AR 應用程式，它透過使用 large language models (LLMs) 進行 shader 生成，實現視覺感知的即時轉換。ShadAR 允許使用者透過 natural language 表達他們的視覺意圖，LLM 會解釋這些意圖以生成對應的。"
  },
  "arxiv:2602.16231": {
    "story_id": "arxiv:2602.16231",
    "title_zh": "DataCube：一種透過自然語言語義分析實現的影片檢索平台",
    "summary_zh": "大規模影片儲存庫越來越多地用於現代 video understanding 和 generation 任務。然而，將原始影片轉換為高品質、任務特定的資料集仍然成本高昂且效率低下。我們提出了 DataCube，一個用於自動影片處理、多維度分析和查詢驅動檢索的智慧平台。DataCube 構建影片片段的結構化 semantic representations，並支援使用 neural re-ranking 和 deep semantic matching 的混合檢索。"
  },
  "arxiv:2602.17354": {
    "story_id": "arxiv:2602.17354",
    "title_zh": "Multimodal 推薦中遺失模態的免訓練基於圖形歸因法",
    "summary_zh": "Multimodal recommender systems (RSs) 透過多模態資料（例如，產品圖片和描述）來表示目錄中的項目，這些資料在某些情況下可能帶有雜訊，甚至更糟的是遺失。在這些情境下，常見的做法是丟棄具有遺失模態的項目，並在原始資料集的 subsample 上訓練 multimodal RSs。迄今為止，multimodal recommendation 中遺失模態的問題在文獻中仍受到有限的關注，缺乏精確的形式化。"
  },
  "arxiv:2602.16124": {
    "story_id": "arxiv:2602.16124",
    "title_zh": "重新思考基於 ANN 的檢索：用於大規模推薦系統的多面向可學習索引",
    "summary_zh": "近似最近鄰 (ANN) 搜尋廣泛應用於大規模推薦系統的檢索階段。在此階段，候選項目使用其學習到的 embedding 向量建立索引，並針對每個使用者（或項目）查詢執行 ANN 搜尋，以檢索一組相關項目。然而，基於 ANN 的檢索存在兩個主要限制。首先，項目 embedding 及其索引通常在不同階段學習：索引通常在 embedding 訓練之後離線執行，而"
  },
  "arxiv:2602.17072": {
    "story_id": "arxiv:2602.17072",
    "title_zh": "BankMathBench：銀行情境中數值推理的基準",
    "summary_zh": "基於大型語言模型 (LLMs) 的聊天機器人正日益被金融領域採用，特別是在數位銀行中，以處理客戶關於存款、儲蓄和貸款等產品的查詢。然而，這些模型在核心銀行計算方面仍表現出低準確性，包括總支付估計、比較具有不同利率的產品以及在提前還款條件下的利息計算。此類任務需要多步驟的數值推理和 context"
  },
  "arxiv:2602.16811": {
    "story_id": "arxiv:2602.16811",
    "title_zh": "評估用於希臘語問答的單語和多語大型語言模型：DemosQA 基準",
    "summary_zh": "自然語言處理和深度學習的最新進展促成了大型語言模型 (LLMs) 的發展，這些模型在包括 Question Answering (QA) 在內的廣泛任務中顯著推進了最先進水平。儘管有這些進展，關於 LLMs 的研究主要針對高資源語言（例如，English），直到最近才將注意力轉向多語模型。然而，這些模型表現出對一小部分訓練資料的偏差"
  },
  "arxiv:2602.16669": {
    "story_id": "arxiv:2602.16669",
    "title_zh": "PredMapNet：用於一致線上 HD 向量化地圖建構的未來與歷史推理",
    "summary_zh": "高精地圖 (HD) 對於自動駕駛至關重要，它們提供道路元素的結構化表示，以支持導航和規劃。然而，現有的基於查詢的方法通常採用隨機查詢初始化，並依賴隱式時間建模，這導致在建構全局地圖期間的時間不一致性和不穩定性。為了克服這些挑戰，我們引入了一種新穎的 end-to-end 框架，用於一致的線上 HD 向量化地圖建構，該框架"
  },
  "arxiv:2602.16653": {
    "story_id": "arxiv:2602.16653",
    "title_zh": "Agent Skill 框架：小型語言模型在工業環境中的潛力展望",
    "summary_zh": "Agent Skill 框架現在得到主要參與者（如 GitHub Copilot, LangChain 和 OpenAI）的廣泛和官方支持，它透過改進 context engineering、減少 hallucinations 和提升任務準確性，在與專有模型搭配時表現出色。基於這些觀察，我們進行了一項調查，以確定 Agent Skill 範式是否為小型語言模型 (SLMs) 帶來類似的好處。這個問題在工業情境中很重要，在這些情境中，持續依賴公共"
  },
  "arxiv:2602.16640": {
    "story_id": "arxiv:2602.16640",
    "title_zh": "Quecto-V1: 8位元量化小型語言模型用於裝置端法律檢索的實證分析",
    "summary_zh": "大型語言模型 (LLMs) 的迅速普及徹底改變了 Natural Language Processing (NLP)，但也同時造成了「資源鴻溝」。最先進的法律智慧系統通常依賴於大量的參數（7B+）和基於雲端的推論，這使得資源受限環境中的從業者難以使用它們，並帶來重大的資料主權風險。本文介紹了 Quecto-V1，這是一種為領域特定 Small Language Model (SLM) 而設計的。"
  },
  "arxiv:2602.16551": {
    "story_id": "arxiv:2602.16551",
    "title_zh": "使用大型語言模型從科學文獻中自動擷取機械本構模型：在文化遺產保護中的應用",
    "summary_zh": "文化遺產的保護正日益轉向資料驅動的預測性維護和「Digital Twin」建構。然而，高擬真模擬所需的機械本構模型仍分散在數十年非結構化的科學文獻中，形成了阻礙保護工程的「Data Silo」。為了解決這個問題，我們提出了一個自動化、兩階段的 agentic 框架，利用 Large Language Models (LLMs) 來擷取機械本構模型。"
  },
  "arxiv:2602.16379": {
    "story_id": "arxiv:2602.16379",
    "title_zh": "使用 LLM Agents 進行基於方面的情緒分析的標籤一致資料生成",
    "summary_zh": "我們提出了一種用於 Aspect-Based Sentiment Analysis (ABSA) 的 agentic 資料增強方法，該方法使用迭代生成和驗證來產生高品質的合成訓練範例。為了隔離 agentic 結構的影響，我們還使用相同的模型和指令開發了一個密切匹配的 prompting-based 基準線。這兩種方法都在三個 ABSA 子任務（Aspect Term Extraction (ATE)、Aspect Sentiment Classification (ATSC) 和 Aspect Sentiment Pair Extraction (ASPE)）上進行了評估。"
  },
  "arxiv:2602.16304": {
    "story_id": "arxiv:2602.16304",
    "title_zh": "關注差距：評估 LLMs 在高層次惡意套件偵測與細粒度指標識別上的表現",
    "summary_zh": "在 PyPI 等開源儲存庫中惡意套件的普遍存在，對軟體供應鏈構成了關鍵威脅。儘管 Large Language Models (LLMs) 已成為自動化安全任務的有前景工具，但它們在偵測惡意套件和指標方面的有效性仍未充分探索。本文對 13 個 LLMs 在偵測惡意軟體套件方面的表現進行了系統性評估。我們使用了一個包含 4,070 個套件（3,700 個良性套件和 370 個惡意套件）的精心策劃資料集進行評估。"
  },
  "arxiv:2602.16238": {
    "story_id": "arxiv:2602.16238",
    "title_zh": "EasyControlEdge: 針對邊緣偵測的基礎模型微調",
    "summary_zh": "我們提出了 EasyControlEdge，它將圖像生成基礎模型應用於邊緣偵測。在真實世界的邊緣偵測中（例如，平面圖牆壁、衛星道路/建築物和醫療器官邊界），清晰度和資料效率至關重要，然而在有限訓練樣本下產生清晰原始邊緣圖仍然具有挑戰性。儘管圖像生成基礎模型在許多下游任務上表現良好，但它們用於資料高效傳輸和高品質迭代細化的預訓練先驗知識。"
  },
  "arxiv:2602.16505": {
    "story_id": "arxiv:2602.16505",
    "title_zh": "用於解釋生存模型的函數分解與 Shapley 交互作用",
    "summary_zh": "在事件時間預測中，危害函數 (hazard function) 和生存函數 (survival function) 是自然且可解釋的目標，但其固有的非加性 (non-additivity) 從根本上限制了標準的加性解釋方法 (additive explanation methods)。我們引入了 Survival Functional Decomposition (SurvFD)，這是一種用於分析機器學習生存模型中特徵交互作用 (feature interactions) 的原則性方法。透過將高階效應分解為時間相關 (time-dependent) 和時間獨立 (time-independent) 的組件，SurvFD 提供了一個以前未被認可的生存解釋視角。"
  },
  "arxiv:2602.16133": {
    "story_id": "arxiv:2602.16133",
    "title_zh": "透過 Equivariant Diffusion Models 從近邊緣光譜生成式逆向估計三維原子配位",
    "summary_zh": "從光譜數據中提取 3D atomic coordinates 是一個長期存在的逆問題 (inverse problem)。我們提出了一個 equivariant diffusion model，可以直接從 near-edge spectra (ELNES/XANES) 生成位點特異性 (site-specific) 的 3D 結構。該模型在 Si-O 晶體上訓練，其徑向準確度 (radial accuracy) 可與 Extended X-ray Absorption Fine Structure (EXAFS) 相媲美 (RMSD 約 0.06 Å)，但在 coordination number precision 方面表現更優 (誤差小於 4.3% 對比 EXAFS 的約 20%)。關鍵的是，它能重建完整的 3D 幾何結構，包括 b"
  },
  "arxiv:2602.17654": {
    "story_id": "arxiv:2602.17654",
    "title_zh": "挖掘與精煉：優化電子商務搜尋檢索中的分級相關性",
    "summary_zh": "我們提出了一個兩階段的「Mine and Refine」對比訓練框架 (contrastive training framework)，用於 semantic text embeddings，以增強多類別電子商務搜尋檢索 (multi-category e-commerce search retrieval)。大規模電子商務搜尋需要能夠泛化到長尾 (long tail)、嘈雜查詢 (noisy queries) 的 embeddings，同時要符合可擴展監督 (scalable supervision) 以及產品和政策限制。一個實際的挑戰是相關性 (relevance) 通常是分級的 (graded)：用戶接受的替代品 (substitutes) 或補充品 (complements) 超出了精確匹配的範圍，而生產系統則受益於清晰的分隔。"
  },
  "arxiv:2602.17528": {
    "story_id": "arxiv:2602.17528",
    "title_zh": "透過拓撲層嵌入實現奈米粒子穩定性的可解釋機器學習",
    "summary_zh": "化學複雜奈米粒子 (chemically complex nanoparticles) 的穩定性受到巨大的組態空間 (configurational space) 支配，該空間源於表面和內部區域異質的局部原子環境 (heterogeneous local atomic environments)。在這個空間中有效地識別低能量組態 (low-energy configurations) 仍然是基於第一性原理的材料發現 (first-principles-based materials discovery) 的核心挑戰，特別是在可用參考數據有限的情況下。在此，我們引入了一個基於片段的數據高效且物理可解釋的機器學習框架。"
  },
  "arxiv:2602.17508": {
    "story_id": "arxiv:2602.17508",
    "title_zh": "Pareto 最優基準測試 AI 模型在 ARM Cortex 處理器上以實現永續嵌入式系統",
    "summary_zh": "這項工作提出了一個實用的基準測試框架 (benchmarking framework)，用於在 ARM Cortex 處理器 (M0+, M4, M7) 上優化 artificial intelligence (AI) 模型，重點關注嵌入式系統 (embedded systems) 中的能源效率 (energy efficiency)、準確度 (accuracy) 和資源利用率 (resource utilization)。透過自動化測試平台 (automated test bench) 的設計，我們提供了一種系統性方法，用於評估關鍵績效指標 (KPIs) 並識別處理器和 AI 模型的最佳組合。該研究強調了浮點運算 (floating-point op) 之間幾乎線性的相關性。"
  },
  "arxiv:2602.17425": {
    "story_id": "arxiv:2602.17425",
    "title_zh": "評估極低資源機器翻譯：ChrF++ 和 BLEU 指標的比較研究",
    "summary_zh": "在極低資源語言 (ELRL) 情境中評估機器翻譯 (MT) 品質帶來了獨特的挑戰，因為廣泛使用的指標，例如在高資源設定中有效的 BLEU，在數據稀缺的情境中常常錯誤地表示品質。本研究對 BLEU（一種基於 n-gram 的指標）和 ChrF++（一種基於字元的指標）在 ELRL 設定中的 MT 評估進行了比較分析。我們研究了每個指標如何響應翻譯中的人工痕跡，包括幻覺、重複、源..."
  },
  "arxiv:2602.17327": {
    "story_id": "arxiv:2602.17327",
    "title_zh": "WebFAQ 2.0：一個用於 Dense Retrieval 的多語言 QA 資料集，帶有挖掘的困難負樣本",
    "summary_zh": "我們介紹了 WebFAQ 2.0，WebFAQ 資料集的一個新版本，包含橫跨 108 種語言的 1.98 億個基於 FAQ 的自然問答對。與之前版本相比，它顯著擴展了多語言覆蓋範圍和雙語對齊 QA 對的數量，達到超過 1430 萬個，使其成為最大的基於 FAQ 的資源。與原始版本不同，WebFAQ 2.0 採用了一種新穎的數據收集策略，直接爬取並提取相關的網路內容，從而產生了實質上更多樣化..."
  },
  "arxiv:2602.17145": {
    "story_id": "arxiv:2602.17145",
    "title_zh": "Bonsai：一個使用基於準則剪枝的卷積神經網路加速框架",
    "summary_zh": "隨著對更準確、更強大的卷積神經網路 (CNNs) 的需求增加，其大小、執行時間、記憶體佔用和功耗也隨之增加。為了解決這個問題，已經提出了諸如剪枝 (pruning) 之類的解決方案，它們各自擁有用於如何移除權重的指標和方法，或者說準則。這些解決方案沒有共同的實現方式，並且難以實施和比較。在這項工作中，我們介紹了 Combine，一個基於準則的剪枝解決方案和演示..."
  },
  "arxiv:2602.16858": {
    "story_id": "arxiv:2602.16858",
    "title_zh": "GDEV-AI：深度學習推論擴展性和架構飽和度的一項通用評估",
    "summary_zh": "深度學習推論在生產環境中的部署持續增長，其中吞吐量 (throughput)、延遲 (latency) 和硬體效率 (hardware efficiency) 至關重要。儘管專用加速器越來越普及，但許多推論工作負載仍然運行在僅限 CPU 的系統上，特別是在傳統數據中心和成本敏感的環境中。本研究通過對不同批次大小的 ResNet 模型進行基準測試，調查了基於 CPU 的卷積神經網路推論的可擴展性限制..."
  },
  "arxiv:2602.16843": {
    "story_id": "arxiv:2602.16843",
    "title_zh": "BanglaSummEval：用於孟加拉語摘要的無參考事實一致性評估",
    "summary_zh": "評估事實一致性對於可靠的文本摘要至關重要，特別是在醫療保健和新聞等高風險領域。然而，大多數現有的評估指標都忽略了孟加拉語 (Bangla) 這種廣泛使用但資源不足的語言，並且通常依賴於參考摘要。我們介紹了 BanglaSummEval，一個無參考、基於問答的框架，用於評估孟加拉語摘要中的事實一致性。所提出的方法評估了事實準確性和內容覆蓋..."
  },
  "arxiv:2602.16571": {
    "story_id": "arxiv:2602.16571",
    "title_zh": "數學輔導中的效用保留去識別化：探討 MathEd-PII Benchmark Dataset 中的數字歧義性",
    "summary_zh": "大規模共享對話式數據對於推動教學科學至關重要，然而嚴格的去識別化仍然是一大障礙。在數學輔導文本中，數字表達式經常類似於結構化識別符（例如，日期或 IDs），導致通用 Personally Identifiable Information (PII) 檢測系統過度刪減核心教學內容，並降低 dataset 的效用。本研究探討如何在數學輔導文本中檢測 PII。"
  },
  "arxiv:2602.16511": {
    "story_id": "arxiv:2602.16511",
    "title_zh": "VIGOR：用於統一類人機器人跌倒安全的視覺情境目標推斷",
    "summary_zh": "對於在雜亂環境中運作的 humanoids 而言，可靠的跌倒恢復至關重要。與四足或輪式機器人不同，humanoids 在跌倒時會經歷高能量衝擊、複雜的全身接觸以及視角的大幅變化，這使得恢復對於持續運作來說至關重要。現有方法將跌倒安全分解為獨立的問題，例如跌倒避免、衝擊緩解和站立恢復，或者依賴於透過 reinforcement learning 進行無視覺訓練的 end-to-end 策略。"
  },
  "arxiv:2602.16298": {
    "story_id": "arxiv:2602.16298",
    "title_zh": "MultiCW：用於訓練穩健「可查證性」檢測模型的大規模平衡基準 Dataset",
    "summary_zh": "Large Language Models (LLMs) 開始重塑媒體專業人士驗證資訊的方式，然而，對於檢測「可查證性」聲明（fact-checking 過程中的關鍵步驟）的自動化支援仍然有限。我們介紹了 Multi-Check-Worthy (MultiCW) dataset，這是一個用於「可查證性」聲明檢測的平衡多語言基準，涵蓋 16 種語言、7 個主題領域和 2 種寫作風格。它包含 123,722 個樣本，在嘈雜（非正式）和結構化（正式）文本之間均勻分佈。"
  },
  "arxiv:2602.16326": {
    "story_id": "arxiv:2602.16326",
    "title_zh": "社群檢測中的個體公平性：量化測量與比較評估",
    "summary_zh": "社群檢測是複雜網路分析中的一項基本任務。考慮公平性的社群檢測旨在防止偏頗的節點劃分，通常分為個體公平性（要求相似節點被相似對待）和群體公平性（旨在避免特定節點群體處於劣勢）。儘管關於公平社群檢測的現有文獻主要關注 group fairness，但我們引入了一種新穎的測量方法來量化社群中的 individual fairness。"
  },
  "arxiv:2602.16299": {
    "story_id": "arxiv:2602.16299",
    "title_zh": "MICE：用於高效 Re-ranking 的最小互動 Cross-Encoders",
    "summary_zh": "Cross-encoders 在 information retrieval 中提供了最先進的 ranking 效果，但其 inference 成本很高。這使得它們無法用作 first-stage rankers，同時在 re-ranking 文件時也會產生額外成本。先前的工作從兩個主要獨立的方向解決了這個瓶頸：透過稀疏化 attention 過程來加速 cross-encoder inference，或使用更複雜的模型（例如 late-interaction 模型）來提高 first-stage retrieval 的效率。在本研究中，"
  },
  "arxiv:2602.16117": {
    "story_id": "arxiv:2602.16117",
    "title_zh": "使用 physics-informed neural networks 解決 BDNK 擴散問題",
    "summary_zh": "在這項工作中，我們將相對論性 BDNK (Bemfica-Disconzi-Noronha-Kovtun) 擴散方程重新表述為流量守恆形式，並使用二階 Kurganov-Tadmor 有限體積方案和 physics-informed neural networks (PINNs) 在 $(1+1)$D 中求解所得方程。特別地，我們引入了 SA-PINN-ACTO 框架，該框架將自適應 PINN 技術與透過對 ne 的代數變換精確實施初始和週期性邊界條件相結合。"
  },
  "arxiv:2602.17639": {
    "story_id": "arxiv:2602.17639",
    "title_zh": "IntRec: 具對比式精修的基於意圖檢索",
    "summary_zh": "從複雜場景中檢索使用者指定的物件仍然是一項艱鉅的任務，尤其當查詢模糊或涉及多個相似物件時。現有的 open-vocabulary 檢測器以 one-shot 方式運作，缺乏根據使用者回饋精修預測的能力。為了解決這個問題，我們提出了 IntRec，一個基於使用者回饋精修預測的互動式物件檢索框架。其核心是一個 Intent State (IS)，它為 positive anch 維護雙記憶體集。"
  },
  "arxiv:2602.16249": {
    "story_id": "arxiv:2602.16249",
    "title_zh": "AFFMAE: 適用於桌上型顯示卡的可擴展高效視覺預訓練",
    "summary_zh": "自監督預訓練透過實現資料高效的 fine-tuning 改變了電腦視覺領域，然而高解析度訓練通常需要伺服器規模的基礎設施，這限制了許多研究實驗室的領域內 foundation model 開發。Masked Autoencoders (MAE) 透過僅編碼可見 token 來減少計算，但由於密集網格先驗和對遮罩敏感的設計權衡，將 MAE 與層次下採樣架構結合在結構上仍然具有挑戰性。我們引入"
  },
  "arxiv:2602.16989": {
    "story_id": "arxiv:2602.16989",
    "title_zh": "WSDM Cup 2026 多語言檢索：一種低成本多階段檢索管線",
    "summary_zh": "我們為 WSDM Cup 2026 多語言檢索任務提出了一種低成本檢索系統，該系統使用英文查詢從約一千萬篇中文、波斯語和俄語新聞文章的集合中檢索相關文件，並為每個查詢輸出前 1000 個排名結果。我們遵循一個四階段管線，該管線結合了基於 LLM 的 GRF 風格查詢擴展與 BM25 候選檢索、使用來自 jina-embeddings-v4 的長文本表示進行密集排名，以及 pointwi。"
  },
  "arxiv:2602.16245": {
    "story_id": "arxiv:2602.16245",
    "title_zh": "HyPCA-Net: 推動醫學影像分析中的多模態融合進展",
    "summary_zh": "多模態融合框架，整合了多樣化的醫學影像模態（例如 MRI、CT），在皮膚癌檢測、失智症診斷和腦腫瘤預測等應用中展現出巨大潛力。然而，現有的多模態融合方法面臨重大挑戰。首先，它們通常依賴計算成本高昂的模型，限制了它們在低資源環境中的適用性。其次，它們通常採用級聯 attention modules，這可能會增加的風險。"
  },
  "arxiv:2602.17101": {
    "story_id": "arxiv:2602.17101",
    "title_zh": "基準測試物體姿態估計和重建對機器人抓取成功率的影響",
    "summary_zh": "3D 重建是眾多機器人感知任務的基礎層，包括 6D 物體姿態估計和抓取姿態生成。現代物體 3D 重建方法可以從多視角圖像生成視覺上和幾何上令人印象深刻的網格，然而，標準的幾何評估未能反映重建品質如何影響下游任務，例如機器人操作性能。本文透過引入一個大規模、基於物理的評估來解決這一空白"
  },
  "fallback:7033c681de64957b": {
    "story_id": "fallback:7033c681de64957b",
    "title_zh": "透過 Amazon Bedrock AgentCore 構建統一智慧",
    "summary_zh": "在這篇文章中，我們將透過我們對 Customer Agent and Knowledge Engine (CAKE) 的實際實施，展示如何使用 Amazon Bedrock AgentCore 構建統一智慧系統。"
  },
  "arxiv:2602.17636": {
    "story_id": "arxiv:2602.17636",
    "title_zh": "CORAL：透過對應對齊改進 Virtual Try-On",
    "summary_zh": "現有的 Virtual Try-On (VTON) 方法在保留精細服裝細節方面常遇到困難，尤其是在需要精確個人-服裝對應關係的非配對設定中。這些方法沒有明確地強制執行個人-服裝對齊，也未能解釋 Diffusion Transformers (DiTs) 中對應關係是如何出現的。在本文中，我們首先分析了基於 DiT 架構中的完整 3D attention，並揭示了個人-服裝對應關係關鍵地取決於精確的個人-服裝"
  },
  "fallback:7a4f73fdfe61f776": {
    "story_id": "fallback:7a4f73fdfe61f776",
    "title_zh": "一種表達自己的新方式：Gemini 現在可以創作音樂",
    "summary_zh": "Gemini app 現在搭載了我們最先進的音樂生成模型 Lyria 3，讓任何人都能使用文字或圖像創作 30 秒的音軌。"
  },
  "arxiv:2602.16641": {
    "story_id": "arxiv:2602.16641",
    "title_zh": "邁向自主機器人腎臟超聲：透過模板引導的最佳樞轉實現空間高效體積成像",
    "summary_zh": "醫學超聲 (US) 成像是用於診斷腎臟疾病的一線工具。然而，傳統的徒手成像程序存在結果不一致、依賴操作者、缺乏 3D 定位資訊以及工作相關肌肉骨骼疾病風險的問題。儘管機器人超聲 (RUS) 系統提供了標準化、獨立於操作者的 3D 腎臟數據採集的潛力，但現有的掃描方法缺乏確定最佳成像視窗的能力"
  },
  "fallback:6bbe35b78a036ef7": {
    "story_id": "fallback:6bbe35b78a036ef7",
    "title_zh": "Project Silica 在玻璃儲存技術方面的進展",
    "summary_zh": "Project Silica 在《Nature》期刊中介紹了在 borosilicate glass 中編碼數據的新技術。這些進展降低了媒體成本，簡化了寫入和讀取系統，同時支持 10,000 年的數據保存。"
  },
  "arxiv:2602.16933": {
    "story_id": "arxiv:2602.16933",
    "title_zh": "在雙階段多波抽樣下的 M-estimation 及其在 Prediction-Powered Inference 中的應用",
    "summary_zh": "在雙階段多波抽樣中，會在大型樣本上收集低成本測量，並在多波次的單位子集上自適應地獲取高成本、資訊更豐富的測量。自適應地收集高成本測量可以提高效率，但會使統計推斷複雜化。我們針對自適應雙階段多波抽樣下的 M-estimation 提供了有效的估計量和置信區間。我們重點關注高成本變量的 proxies ——例如..."
  },
  "fallback:64676d972524e1dd": {
    "story_id": "fallback:64676d972524e1dd",
    "title_zh": "沒有任何技術能比 AI 更讓我懷抱遠大夢想",
    "summary_zh": "一個風格化的設計，類似於 Ashoka Chakra，帶有彩色網絡線條，文字顯示為「भारत 2026 INDIA」。一條垂直線將其與右側的 Google logo 分隔開來，所有這些都設置在帶有微弱網格圖案的淺藍色漸變背景上。"
  },
  "fallback:9c836f2795128c3a": {
    "story_id": "fallback:9c836f2795128c3a",
    "title_zh": "Amazon Quick 現已支持使用 key pair authentication 連接到 Snowflake 數據源",
    "summary_zh": "在這篇部落格文章中，我們將引導您如何通過安全的 key pair authentication 在 Amazon Quick Sight 和 Snowflake 之間建立數據源連接。"
  },
  "fallback:a6435c936e61839f": {
    "story_id": "fallback:a6435c936e61839f",
    "title_zh": "AI Impact Summit 2026",
    "summary_zh": "回顧 Google 在 AI Impact Summit 2026 上宣布的合作夥伴關係和投資。"
  },
  "fallback:290081df3883fdd9": {
    "story_id": "fallback:290081df3883fdd9",
    "title_zh": "AI Impact Summit 2026：我們如何合作讓 AI 造福所有人",
    "summary_zh": "四人坐在會議舞台上"
  },
  "hf:google/timesfm-2.5-200m-transformers": {
    "story_id": "hf:google/timesfm-2.5-200m-transformers",
    "title_zh": "google/timesfm-2.5-200m-transformers",
    "summary_zh": "TimesFM (時間序列基礎模型) 是一個用於時間序列預測的預訓練 decoder-only 模型。此儲存庫包含官方 TimesFM 2.5 PyTorch 版本的 **Transformers** 移植。**資源與技術文件**：* 原始模型: google/timesfm-2.5-200m-pytorch * Transformers 模型: google/timesfm-2.5-200m-transformers * 論文: A decoder-only foundation model for time-series forecasting * Transformers 文件: TimesFM 2.5 這個模型是從官方 TimesFM 2.5 PyTorch checkpoint 轉換而來，並作為 `Timesfm2P5ModelForPrediction` 整合到 `transformers` 中。轉換後的 checkpoint 保留了原始架構和預測行為，包括：* 用於時間序列上下文的 patch-based 輸入 * decoder-only self-attention 堆疊"
  },
  "hf:qwen/qwen3.5-397b-a17b": {
    "story_id": "hf:qwen/qwen3.5-397b-a17b",
    "title_zh": "Qwen/Qwen3.5-397B-A17B",
    "summary_zh": "此儲存庫包含以 Hugging Face Transformers 格式呈現的後訓練模型之模型權重和配置檔案。這些人工產物兼容 Hugging Face Transformers, vLLM, SGLang, KTransformers 等。對於尋求託管、可擴展推理而無需基礎設施維護的用戶，阿里巴巴雲模型工作室提供了官方 Qwen API 服務。特別是，**Qwen3.5-Plus** 是與 Qwen3.5-397B-A17B 對應的託管版本，具有更多生產功能，例如預設 1M context length、官方內建工具和自適應工具使用。欲了解更多資訊，請參閱 User Guide。近幾個月來，我們加強了對開發能夠提供卓越實用性和性能的 foundation models 的關注。Qwen3.5..."
  },
  "hf:qwen/qwen3.5-397b-a17b-fp8": {
    "story_id": "hf:qwen/qwen3.5-397b-a17b-fp8",
    "title_zh": "Qwen/Qwen3.5-397B-A17B-FP8",
    "summary_zh": "此儲存庫包含以 Hugging Face Transformers 格式呈現的後訓練模型之模型權重和配置檔案。這些人工產物兼容 Hugging Face Transformers, vLLM, SGLang 等。對於尋求託管、可擴展推理而無需基礎設施維護的用戶，阿里巴巴雲模型工作室提供了官方 Qwen API 服務。特別是，**Qwen3.5-Plus** 是與 Qwen3.5-397B-A17B 對應的託管版本，具有更多生產功能，例如預設 1M context length、官方內建工具和自適應工具使用。欲了解更多資訊，請參閱 User Guide。近幾個月來，我們加強了對開發能夠提供卓越實用性和性能的 foundation models 的關注。Qwen3.5 代表著一種..."
  },
  "hf:mistralai/voxtral-mini-4b-realtime-2602": {
    "story_id": "hf:mistralai/voxtral-mini-4b-realtime-2602",
    "title_zh": "mistralai/Voxtral-Mini-4B-Realtime-2602",
    "summary_zh": "Voxtral Mini 4B Realtime 2602 是一個**多語言、即時語音轉錄模型**，也是首批開源解決方案之一，其準確性可與離線系統媲美，延遲為 **= 3600 / 0.8 = 45000`。理論上，您應該能夠無限錄製；實際上，RoPE 參數的預分配等因素限制了 `--max-model-len`。為了獲得最佳用戶體驗，我們建議直接使用預設參數實例化 vLLM，這將自動設定最大模型長度為 131072 (約 3 小時)。- 我們強烈建議使用 websockets 來設定音頻串流會話。有關如何操作的更多資訊，請查閱 Usage。- 我們建議使用 480ms 的延遲，因為我們發現這是性能和低延遲的最佳平衡點。但是，如果您想調整..."
  },
  "hf:microsoft/latent-zoning-networks": {
    "story_id": "hf:microsoft/latent-zoning-networks",
    "title_zh": "microsoft/latent-zoning-networks",
    "summary_zh": "Generative modeling、representation learning 和 classification 是 machine learning (ML) 中的三個核心問題，然而它們的 state-of-the-art (SoTA) 解決方案卻在很大程度上相互獨立。在本文中，我們提出疑問：是否存在一個統一的原則能夠同時解決這三者？這種統一化可以簡化 ML pipelines，並促進跨任務的更大協同作用。我們引入 Latent Zoning Network (LZN) 作為實現此目標的一個步驟。LZN 的核心是建立一個共享的 Gaussian latent space，它能編碼所有任務的資訊。每種資料類型（例如 images、text、labels）都配備了一個 encoder，將樣本映射到不同的 disjoint latent zones，以及一個 decoder，將 latents 映射回資料。ML tasks 被表達為這些 encoders 和 decoders 的組合：例如，label-conditional image generation 使用一個 label..."
  }
}