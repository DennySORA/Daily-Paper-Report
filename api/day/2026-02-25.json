{
  "archive_dates": [
    "2026-02-25",
    "2026-02-24",
    "2026-02-23"
  ],
  "entity_catalog": {
    "01-ai": {
      "name": "01.AI",
      "type": "organization"
    },
    "andrej-karpathy": {
      "name": "Andrej Karpathy",
      "type": "researcher"
    },
    "anthropic": {
      "name": "Anthropic",
      "type": "organization"
    },
    "aws": {
      "name": "AWS",
      "type": "organization"
    },
    "cohere": {
      "name": "Cohere",
      "type": "organization"
    },
    "deepmind": {
      "name": "DeepMind",
      "type": "organization"
    },
    "deepseek": {
      "name": "DeepSeek",
      "type": "organization"
    },
    "geoffrey-hinton": {
      "name": "Geoffrey Hinton",
      "type": "researcher"
    },
    "google-research": {
      "name": "Google Research",
      "type": "institution"
    },
    "huggingface": {
      "name": "Hugging Face",
      "type": "organization"
    },
    "ilya-sutskever": {
      "name": "Ilya Sutskever",
      "type": "researcher"
    },
    "langchain": {
      "name": "LangChain",
      "type": "organization"
    },
    "llama-cpp": {
      "name": "llama.cpp",
      "type": "organization"
    },
    "meta-ai": {
      "name": "Meta AI",
      "type": "institution"
    },
    "microsoft-research": {
      "name": "Microsoft Research",
      "type": "institution"
    },
    "mistral-ai": {
      "name": "Mistral AI",
      "type": "organization"
    },
    "nvidia": {
      "name": "NVIDIA",
      "type": "organization"
    },
    "ollama": {
      "name": "Ollama",
      "type": "organization"
    },
    "openai": {
      "name": "OpenAI",
      "type": "organization"
    },
    "qwen": {
      "name": "Qwen",
      "type": "organization"
    },
    "stability-ai": {
      "name": "Stability AI",
      "type": "organization"
    },
    "vllm": {
      "name": "vLLM",
      "type": "organization"
    },
    "yann-lecun": {
      "name": "Yann LeCun",
      "type": "researcher"
    },
    "yoshua-bengio": {
      "name": "Yoshua Bengio",
      "type": "researcher"
    }
  },
  "generated_at": "2026-02-25T09:53:45.949298+00:00",
  "model_releases_by_entity": {
    "other": [
      {
        "arxiv_id": null,
        "authors": [],
        "categories": [],
        "entities": [],
        "first_seen_at": "2026-02-25T09:22:32.580536+00:00",
        "github_release_url": null,
        "hf_metadata": {
          "downloads": 416361,
          "likes": 537
        },
        "hf_model_id": "mistralai/devstral-small-2-24b-instruct-2512",
        "item_count": 1,
        "links": [
          {
            "link_type": "huggingface",
            "source_id": "hf-mistralai",
            "tier": 1,
            "title": "mistralai/Devstral-Small-2-24B-Instruct-2512",
            "url": "https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512"
          }
        ],
        "primary_link": {
          "link_type": "huggingface",
          "source_id": "hf-mistralai",
          "tier": 1,
          "title": "mistralai/Devstral-Small-2-24B-Instruct-2512",
          "url": "https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512"
        },
        "published_at": "2026-02-25T08:50:48+00:00",
        "scores": {
          "citation_score": 0.0,
          "cross_source_score": 0.0,
          "entity_score": 0.0,
          "kind_score": 1.8,
          "llm_raw_score": 0.0,
          "llm_relevance_score": 0.0,
          "recency_score": 0.9964669043389099,
          "semantic_score": 0.0,
          "tier_score": 2.0,
          "topic_score": 4.0,
          "total_score": 8.79646690433891
        },
        "section": null,
        "source_name": null,
        "story_id": "hf:mistralai/devstral-small-2-24b-instruct-2512",
        "summary": "Devstral is an agentic LLM for software engineering tasks. **Devstral Small 2** excels at using tools to explore codebases, editing multiple files and power software engineering agents. The model achieves remarkable performance on SWE-bench. This model is an Instruct model in **FP8**, fine-tuned to follow instructions, making it ideal for chat, agentic and instruction based tasks for SWE use cases. For enterprises requiring specialized capabilities (increased context, domain-specific knowledge, etc.), we invite companies to reach out to us. The Devstral Small 2 Instruct model offers the following capabilities: - **Agentic Coding**: Devstral is designed to excel at agentic coding tasks, making it a great choice for software engineering agents. - **Lightweight**: with its compact size of...",
        "summary_zh": "Devstral 是一個用於軟體工程任務的 agentic LLM。**Devstral Small 2** 擅長使用工具探索程式碼庫 (codebases)、編輯多個檔案並為軟體工程 agent 提供支援。該模型在 SWE-bench 上取得了卓越的性能。此模型是一個 **FP8** 的 Instruct 模型，經過 fine-tune 以遵循指令，使其非常適合用於軟體工程 (SWE) 用例的 chat、agentic 和基於指令的任務。對於需要特殊能力（例如：增加 context、領域特定知識等）的企業，我們歡迎聯繫我們。Devstral Small 2 Instruct 模型提供以下功能：- **Agentic Coding**：Devstral 旨在擅長 agentic coding 任務，使其成為軟體工程 agent 的絕佳選擇。- **輕量級 (Lightweight)**：憑藉其緊湊的尺寸...",
        "title": "mistralai/Devstral-Small-2-24B-Instruct-2512",
        "title_zh": "mistralai/Devstral-Small-2-24B-Instruct-2512"
      },
      {
        "arxiv_id": null,
        "authors": [],
        "categories": [],
        "entities": [],
        "first_seen_at": "2026-02-25T09:22:32.580850+00:00",
        "github_release_url": null,
        "hf_metadata": {
          "downloads": 14797,
          "likes": 290
        },
        "hf_model_id": "mistralai/devstral-2-123b-instruct-2512",
        "item_count": 1,
        "links": [
          {
            "link_type": "huggingface",
            "source_id": "hf-mistralai",
            "tier": 1,
            "title": "mistralai/Devstral-2-123B-Instruct-2512",
            "url": "https://huggingface.co/mistralai/Devstral-2-123B-Instruct-2512"
          }
        ],
        "primary_link": {
          "link_type": "huggingface",
          "source_id": "hf-mistralai",
          "tier": 1,
          "title": "mistralai/Devstral-2-123B-Instruct-2512",
          "url": "https://huggingface.co/mistralai/Devstral-2-123B-Instruct-2512"
        },
        "published_at": "2026-02-25T08:50:20+00:00",
        "scores": {
          "citation_score": 0.0,
          "cross_source_score": 0.0,
          "entity_score": 0.0,
          "kind_score": 1.8,
          "llm_raw_score": 0.0,
          "llm_relevance_score": 0.0,
          "recency_score": 0.996434611953232,
          "semantic_score": 0.0,
          "tier_score": 2.0,
          "topic_score": 4.0,
          "total_score": 8.796434611953233
        },
        "section": null,
        "source_name": null,
        "story_id": "hf:mistralai/devstral-2-123b-instruct-2512",
        "summary": "Devstral is an agentic LLM for software engineering tasks. **Devstral 2** excels at using tools to explore codebases, editing multiple files and power software engineering agents. The model achieves remarkable performance on SWE-bench. This model is an Instruct model in **FP8**, fine-tuned to follow instructions, making it ideal for chat, agentic and instruction based tasks for SWE use cases. For enterprises requiring specialized capabilities (increased context, domain-specific knowledge, etc.), we invite companies to reach out to us. The Devstral 2 Instruct model offers the following capabilities: - **Agentic Coding**: Devstral is designed to excel at agentic coding tasks, making it a great choice for software engineering agents. - **Improved Performance**: Devstral 2 is a step-up...",
        "summary_zh": "Devstral 是一個用於軟體工程任務的 agentic LLM。**Devstral 2** 擅長使用工具來探索 codebase、編輯多個檔案，並驅動軟體工程 agent。該模型在 SWE-bench 上取得了卓越的性能。此模型是一個以 **FP8** 格式的 Instruct model，經過 fine-tuning 以遵循指令，使其非常適合用於 SWE 使用案例中的 chat、agentic 和基於指令的任務。對於需要專門功能（例如：增加 context、領域特定知識等）的企業，我們誠摯邀請公司與我們聯繫。Devstral 2 Instruct model 提供以下功能： - **Agentic Coding**：Devstral 旨在擅長 agentic coding 任務，使其成為軟體工程 agent 的絕佳選擇。 - **Improved Performance**：Devstral 2 是一個升級版...",
        "title": "mistralai/Devstral-2-123B-Instruct-2512",
        "title_zh": "mistralai/Devstral-2-123B-Instruct-2512"
      }
    ],
    "qwen": [
      {
        "arxiv_id": null,
        "authors": [],
        "categories": [],
        "entities": [
          "qwen"
        ],
        "first_seen_at": "2026-02-25T06:33:17.776387+00:00",
        "github_release_url": null,
        "hf_metadata": {
          "downloads": 0,
          "likes": 184,
          "pipeline_tag": "image-text-to-text"
        },
        "hf_model_id": "qwen/qwen3.5-27b",
        "item_count": 1,
        "links": [
          {
            "link_type": "huggingface",
            "source_id": "hf-qwen",
            "tier": 1,
            "title": "Qwen/Qwen3.5-27B",
            "url": "https://huggingface.co/Qwen/Qwen3.5-27B"
          }
        ],
        "primary_link": {
          "link_type": "huggingface",
          "source_id": "hf-qwen",
          "tier": 1,
          "title": "Qwen/Qwen3.5-27B",
          "url": "https://huggingface.co/Qwen/Qwen3.5-27B"
        },
        "published_at": "2026-02-25T02:43:25+00:00",
        "scores": {
          "citation_score": 0.0,
          "cross_source_score": 0.0,
          "entity_score": 2.0,
          "kind_score": 1.8,
          "llm_raw_score": 0.0,
          "llm_relevance_score": 0.0,
          "recency_score": 0.9713658712429573,
          "semantic_score": 0.0,
          "tier_score": 2.0,
          "topic_score": 4.0,
          "total_score": 10.771365871242956
        },
        "section": null,
        "source_name": null,
        "story_id": "hf:qwen/qwen3.5-27b",
        "summary": "> This repository contains model weights and configuration files for the post-trained model in the Hugging Face Transformers format. > These artifacts are compatible with Hugging Face Transformers, vLLM, SGLang, KTransformers, etc. Over recent months, we have intensified our focus on developing foundation models that deliver exceptional utility and performance. Qwen3.5 represents a significant leap forward, integrating breakthroughs in multimodal learning, architectural efficiency, reinforcement learning scale, and global accessibility to empower developers and enterprises with unprecedented capability and efficiency. Qwen3.5 features the following enhancement: - **Unified Vision-Language Foundation**: Early fusion training on multimodal tokens achieves cross-generational parity with...",
        "summary_zh": "此儲存庫包含在 Hugging Face Transformers 格式下，用於後訓練模型的模型權重和配置檔案。這些人工製品與 Hugging Face Transformers、vLLM、SGLang、KTransformers 等相容。近幾個月來，我們加強了對開發能夠提供卓越實用性和性能的基礎模型的關注。Qwen3.5 代表著一項重大飛躍，它整合了 multimodal learning、architectural efficiency、reinforcement learning scale 以及全球可及性方面的突破，賦能開發者和企業前所未有的能力和效率。Qwen3.5 具有以下增強功能：- **統一的視覺-語言基礎 (Unified Vision-Language Foundation)**：透過對 multimodal tokens 進行早期融合訓練，實現了與...",
        "title": "Qwen/Qwen3.5-27B",
        "title_zh": "Qwen/Qwen3.5-27B"
      },
      {
        "arxiv_id": null,
        "authors": [],
        "categories": [],
        "entities": [
          "qwen"
        ],
        "first_seen_at": "2026-02-25T06:33:17.776682+00:00",
        "github_release_url": null,
        "hf_metadata": {
          "downloads": 0,
          "likes": 252,
          "pipeline_tag": "image-text-to-text"
        },
        "hf_model_id": "qwen/qwen3.5-35b-a3b",
        "item_count": 1,
        "links": [
          {
            "link_type": "huggingface",
            "source_id": "hf-qwen",
            "tier": 1,
            "title": "Qwen/Qwen3.5-35B-A3B",
            "url": "https://huggingface.co/Qwen/Qwen3.5-35B-A3B"
          }
        ],
        "primary_link": {
          "link_type": "huggingface",
          "source_id": "hf-qwen",
          "tier": 1,
          "title": "Qwen/Qwen3.5-35B-A3B",
          "url": "https://huggingface.co/Qwen/Qwen3.5-35B-A3B"
        },
        "published_at": "2026-02-24T16:31:54+00:00",
        "scores": {
          "citation_score": 0.0,
          "cross_source_score": 0.0,
          "entity_score": 2.0,
          "kind_score": 1.8,
          "llm_raw_score": 0.0,
          "llm_relevance_score": 0.0,
          "recency_score": 0.9309790371462632,
          "semantic_score": 0.0,
          "tier_score": 2.0,
          "topic_score": 4.0,
          "total_score": 10.730979037146263
        },
        "section": null,
        "source_name": null,
        "story_id": "hf:qwen/qwen3.5-35b-a3b",
        "summary": "> This repository contains model weights and configuration files for the post-trained model in the Hugging Face Transformers format. > These artifacts are compatible with Hugging Face Transformers, vLLM, SGLang, KTransformers, etc. > For users seeking managed, scalable inference without infrastructure maintenance, the official Qwen API service is provided by Alibaba Cloud Model Studio. > In particular, **Qwen3.5-Flash** is the hosted version corresponding to Qwen3.5-35B-A3B with more production features, e.g., 1M context length by default and official built-in tools. > For more information, please refer to the User Guide. Over recent months, we have intensified our focus on developing foundation models that deliver exceptional utility and performance. Qwen3.5 represents a significant leap...",
        "summary_zh": "此儲存庫包含在 Hugging Face Transformers 格式下，用於後訓練模型的模型權重和配置檔案。這些人工製品與 Hugging Face Transformers、vLLM、SGLang、KTransformers 等相容。對於尋求無需基礎設施維護即可獲得託管、可擴展 inference 的用戶，阿里巴巴雲模型工作室 (Alibaba Cloud Model Studio) 提供了官方 Qwen API 服務。特別是，**Qwen3.5-Flash** 是與 Qwen3.5-35B-A3B 對應的託管版本，具有更多生產功能，例如預設 1M context length 和官方內建工具。欲了解更多資訊，請參閱使用者指南 (User Guide)。近幾個月來，我們加強了對開發能夠提供卓越實用性和性能的基礎模型的關注。Qwen3.5 代表著一項重大飛躍...",
        "title": "Qwen/Qwen3.5-35B-A3B",
        "title_zh": "Qwen/Qwen3.5-35B-A3B"
      },
      {
        "arxiv_id": null,
        "authors": [],
        "categories": [],
        "entities": [
          "qwen"
        ],
        "first_seen_at": "2026-02-25T06:33:17.776941+00:00",
        "github_release_url": null,
        "hf_metadata": {
          "downloads": 0,
          "likes": 179,
          "pipeline_tag": "image-text-to-text"
        },
        "hf_model_id": "qwen/qwen3.5-122b-a10b",
        "item_count": 1,
        "links": [
          {
            "link_type": "huggingface",
            "source_id": "hf-qwen",
            "tier": 1,
            "title": "Qwen/Qwen3.5-122B-A10B",
            "url": "https://huggingface.co/Qwen/Qwen3.5-122B-A10B"
          }
        ],
        "primary_link": {
          "link_type": "huggingface",
          "source_id": "hf-qwen",
          "tier": 1,
          "title": "Qwen/Qwen3.5-122B-A10B",
          "url": "https://huggingface.co/Qwen/Qwen3.5-122B-A10B"
        },
        "published_at": "2026-02-24T15:54:27+00:00",
        "scores": {
          "citation_score": 0.0,
          "cross_source_score": 0.0,
          "entity_score": 2.0,
          "kind_score": 1.8,
          "llm_raw_score": 0.0,
          "llm_relevance_score": 0.0,
          "recency_score": 0.928560990799207,
          "semantic_score": 0.0,
          "tier_score": 2.0,
          "topic_score": 4.0,
          "total_score": 10.728560990799206
        },
        "section": null,
        "source_name": null,
        "story_id": "hf:qwen/qwen3.5-122b-a10b",
        "summary": "> This repository contains model weights and configuration files for the post-trained model in the Hugging Face Transformers format. > These artifacts are compatible with Hugging Face Transformers, vLLM, SGLang, KTransformers, etc. Over recent months, we have intensified our focus on developing foundation models that deliver exceptional utility and performance. Qwen3.5 represents a significant leap forward, integrating breakthroughs in multimodal learning, architectural efficiency, reinforcement learning scale, and global accessibility to empower developers and enterprises with unprecedented capability and efficiency. Qwen3.5 features the following enhancement: - **Unified Vision-Language Foundation**: Early fusion training on multimodal tokens achieves cross-generational parity with...",
        "summary_zh": "此儲存庫包含在 Hugging Face Transformers 格式下，用於後訓練模型的模型權重和配置檔案。這些人工製品與 Hugging Face Transformers、vLLM、SGLang、KTransformers 等相容。近幾個月來，我們加強了對開發能夠提供卓越實用性和性能的基礎模型的關注。Qwen3.5 代表著一項重大飛躍，它整合了 multimodal learning、architectural efficiency、reinforcement learning scale 以及全球可及性方面的突破，賦能開發者和企業前所未有的能力和效率。Qwen3.5 具有以下增強功能：- **統一的視覺-語言基礎 (Unified Vision-Language Foundation)**：透過對 multimodal tokens 進行早期融合訓練，實現了與...",
        "title": "Qwen/Qwen3.5-122B-A10B",
        "title_zh": "Qwen/Qwen3.5-122B-A10B"
      },
      {
        "arxiv_id": null,
        "authors": [],
        "categories": [],
        "entities": [
          "qwen"
        ],
        "first_seen_at": "2026-02-25T06:33:17.777152+00:00",
        "github_release_url": null,
        "hf_metadata": {
          "downloads": 0,
          "likes": 41,
          "pipeline_tag": "image-text-to-text"
        },
        "hf_model_id": "qwen/qwen3.5-35b-a3b-base",
        "item_count": 1,
        "links": [
          {
            "link_type": "huggingface",
            "source_id": "hf-qwen",
            "tier": 1,
            "title": "Qwen/Qwen3.5-35B-A3B-Base",
            "url": "https://huggingface.co/Qwen/Qwen3.5-35B-A3B-Base"
          }
        ],
        "primary_link": {
          "link_type": "huggingface",
          "source_id": "hf-qwen",
          "tier": 1,
          "title": "Qwen/Qwen3.5-35B-A3B-Base",
          "url": "https://huggingface.co/Qwen/Qwen3.5-35B-A3B-Base"
        },
        "published_at": "2026-02-24T15:20:29+00:00",
        "scores": {
          "citation_score": 0.0,
          "cross_source_score": 0.0,
          "entity_score": 2.0,
          "kind_score": 1.8,
          "llm_raw_score": 0.0,
          "llm_relevance_score": 0.0,
          "recency_score": 0.9263732857628443,
          "semantic_score": 0.0,
          "tier_score": 2.0,
          "topic_score": 4.0,
          "total_score": 10.726373285762843
        },
        "section": null,
        "source_name": null,
        "story_id": "hf:qwen/qwen3.5-35b-a3b-base",
        "summary": "> This repository contains model weights and configuration files for the pre-trained only model in the Hugging Face Transformers format. > These artifacts are compatible with Hugging Face Transformers, vLLM, SGLang, etc. > The intended use cases are fine-tuning, in-context learning experiments, and other research or development purposes, not direct interaction. > However, the control tokens, e.g., `` and `` were trained to allow efficient LoRA-style PEFT with the official chat template, mitigating the need to finetune embeddings, a significant optimization given Qwen3.5's larger vocabulary. Over recent months, we have intensified our focus on developing foundation models that deliver exceptional utility and performance. Qwen3.5 represents a significant leap forward, integrating...",
        "summary_zh": "此儲存庫包含在 Hugging Face Transformers 格式下，用於僅預訓練模型的模型權重和配置檔案。這些人工製品與 Hugging Face Transformers、vLLM、SGLang 等相容。其預期用途是 fine-tuning、in-context learning 實驗以及其他研究或開發目的，而非直接互動。然而，控制 token，例如 `` 和 `` 經過訓練，可透過官方 chat template 實現高效的 LoRA-style PEFT，減少了 fine-tune embeddings 的需求，考慮到 Qwen3.5 較大的詞彙量，這是一項重要的優化。近幾個月來，我們加強了對開發能夠提供卓越實用性和性能的基礎模型的關注。Qwen3.5 代表著一項重大飛躍，整合了...",
        "title": "Qwen/Qwen3.5-35B-A3B-Base",
        "title_zh": "Qwen/Qwen3.5-35B-A3B-Base"
      }
    ]
  },
  "papers": [
    {
      "arxiv_id": "2602.21198",
      "authors": [],
      "categories": [],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.261287+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs",
          "url": "https://arxiv.org/abs/2602.21198"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs",
        "url": "https://arxiv.org/abs/2602.21198"
      },
      "published_at": "2026-02-24T18:55:18+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.9,
        "llm_relevance_score": 25.2,
        "recency_score": 0.9402963521905255,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 34.34029635219052
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21198",
      "summary": "Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: reflection-in-action, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and reflection-on-action, which uses test-time training to update both its internal reflection model and its action policy based on external reflections after execution. We also include retrospective reflection, allowing the agent to re-evaluate earlier decisions and perform model updates with hindsight for proper long-horizon credit assignment. Experiments on our newly-designed Long-Horizon Household benchmark and MuJoCo Cupboard Fitting benchmark show significant gains over baseline models, with ablative studies validating the complementary roles of reflection-in-action and reflection-on-action. Qualitative analyses, including real-robot trials, highlight behavioral correction through reflection.",
      "summary_zh": "具身式 LLMs 賦予機器人高階任務推理能力，但它們無法反思哪裡出了問題或原因為何，導致部署成為一系列獨立的試驗，錯誤重複發生而非累積成經驗。借鑒人類的反思性實踐者，我們引入了 Reflective Test-Time Planning，它整合了兩種反思模式：reflection-in-action，即代理在執行前使用 test-time scaling，透過內部反思生成並評估多個候選動作；以及 reflection-on-action，即在執行後根據外部反思更新其內部 reflection model 和 action policy。我們還加入了 retrospective reflection，允許代理重新評估先前的決策，並利用事後洞察進行模型更新，以實現適當的 long-horizon credit assignment。在我們新設計的 Long-Horizon Household benchmark 和 MuJoCo Cupboard Fitting benchmark 上的實驗顯示，與 baseline models 相比有顯著的提升，消融研究 (ablative studies) 驗證了 reflection-in-action 和 reflection-on-action 的互補作用。定性分析 (Qualitative analyses)，包括真實機器人試驗，突顯了透過反思實現的行為修正。",
      "title": "Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs",
      "title_zh": "從試錯中學習：具身式 LLMs 的反思性測試時規劃"
    },
    {
      "arxiv_id": "2602.21185",
      "authors": [],
      "categories": [],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.395461+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "The Diffusion Duality, Chapter II: Ψ-Samplers and Efficient Curriculum",
          "url": "https://arxiv.org/abs/2602.21185"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "The Diffusion Duality, Chapter II: Ψ-Samplers and Efficient Curriculum",
        "url": "https://arxiv.org/abs/2602.21185"
      },
      "published_at": "2026-02-24T18:35:22+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.88,
        "llm_relevance_score": 24.64,
        "recency_score": 0.9389956387285842,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 33.77899563872859
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21185",
      "summary": "Uniform-state discrete diffusion models excel at few-step generation and guidance due to their ability to self-correct, making them preferred over autoregressive or Masked diffusion models in these settings. However, their sampling quality plateaus with ancestral samplers as the number of steps increases. We introduce a family of Predictor-Corrector (PC) samplers for discrete diffusion that generalize prior methods and apply to arbitrary noise processes. When paired with uniform-state diffusion, our samplers outperform ancestral sampling on both language and image modeling, achieving lower generative perplexity at matched unigram entropy on OpenWebText and better FID/IS scores on CIFAR10. Crucially, unlike conventional samplers, our PC methods continue to improve with more sampling steps. Taken together, these findings call into question the assumption that Masked diffusion is the inevitable future of diffusion-based language modeling. Beyond sampling, we develop a memory-efficient curriculum for the Gaussian relaxation training phase, reducing training time by 25% and memory by 33% compared to Duo while maintaining comparable perplexity on OpenWebText and LM1B and strong downstream performance. We release code, checkpoints, and a video-tutorial on: https://s-sahoo.com/duo-ch2",
      "summary_zh": "均勻狀態離散 diffusion models 在少步驟生成和引導方面表現出色，因為它們具有自我修正能力，這使得它們在這些設定中優於 autoregressive 或 Masked diffusion models。然而，隨著步驟數的增加，其 sampling 品質在使用 ancestral samplers 時會達到高原期。我們引入了一系列適用於離散 diffusion 的 Predictor-Corrector (PC) samplers，這些 samplers 泛化了先前的方法，並適用於任意 noise processes。當與 uniform-state diffusion 結合使用時，我們的 samplers 在語言和圖像建模方面均優於 ancestral sampling，在 OpenWebText 上於匹配的 unigram entropy 下實現了更低的 generative perplexity，並在 CIFAR10 上獲得了更好的 FID/IS scores。關鍵的是，與傳統 samplers 不同，我們的 PC 方法會隨著採樣步驟的增加而持續改進。總而言之，這些發現對 Masked diffusion 是 diffusion-based 語言建模不可避免的未來這一假設提出了質疑。除了 sampling 之外，我們為 Gaussian relaxation training phase 開發了一種記憶體高效的課程，與 Duo 相比，將訓練時間減少了 25%，記憶體減少了 33%，同時在 OpenWebText 和 LM1B 上保持了可比的 perplexity 和強大的 downstream performance。我們在 https://s-sahoo.com/duo-ch2 發布了程式碼、模型權重 (checkpoints) 和影片教學。",
      "title": "The Diffusion Duality, Chapter II: Ψ-Samplers and Efficient Curriculum",
      "title_zh": "擴散對偶性，第二章：Ψ-取樣器與高效課程"
    },
    {
      "arxiv_id": "2602.21015",
      "authors": [],
      "categories": [],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.025117+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "From Perception to Action: An Interactive Benchmark for Vision Reasoning",
          "url": "https://arxiv.org/abs/2602.21015"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "From Perception to Action: An Interactive Benchmark for Vision Reasoning",
        "url": "https://arxiv.org/abs/2602.21015"
      },
      "published_at": "2026-02-24T15:33:02+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.88,
        "llm_relevance_score": 24.64,
        "recency_score": 0.9271809977345623,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 33.76718099773456
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21015",
      "summary": "Understanding the physical structure is essential for real-world applications such as embodied agents, interactive design, and long-horizon manipulation. Yet, prevailing Vision-Language Model (VLM) evaluations still center on structure-agnostic, single-turn setups (e.g., VQA), which fail to assess agents' ability to reason about how geometry, contact, and support relations jointly constrain what actions are possible in a dynamic environment. To address this gap, we introduce the Causal Hierarchy of Actions and Interactions (CHAIN) benchmark, an interactive 3D, physics-driven testbed designed to evaluate whether models can understand, plan, and execute structured action sequences grounded in physical constraints. CHAIN shifts evaluation from passive perception to active problem solving, spanning tasks such as interlocking mechanical puzzles and 3D stacking and packing. We conduct a comprehensive study of state-of-the-art VLMs and diffusion-based models under unified interactive settings. Our results show that top-performing models still struggle to internalize physical structure and causal constraints, often failing to produce reliable long-horizon plans and cannot robustly translate perceived structure into effective actions. The project is available at https://social-ai-studio.github.io/CHAIN/.",
      "summary_zh": "理解物理結構對於具身式 agents、互動式設計和 long-horizon 操縱等真實世界應用至關重要。然而，主流的 Vision-Language Model (VLM) 評估仍側重於結構無關的單回合設定（例如 VQA），這無法評估 agents 在動態環境中如何推理幾何、接觸和支撐關係共同約束了哪些可能的行動的能力。為了彌補這一空白，我們引入了 Causal Hierarchy of Actions and Interactions (CHAIN) benchmark，這是一個互動式的 3D、物理驅動的測試平台，旨在評估模型是否能夠理解、規劃和執行基於物理約束的結構化動作序列。CHAIN 將評估從被動感知轉向主動問題解決，涵蓋了諸如機械拼圖互鎖和 3D 堆疊與包裝等任務。我們在統一的互動設定下，對最先進的 VLMs 和 diffusion-based models 進行了全面研究。我們的結果顯示，表現最佳的模型仍然難以內化物理結構和因果約束，經常無法產生可靠的 long-horizon 規劃，也無法將感知到的結構可靠地轉化為有效的行動。該專案可在 https://social-ai-studio.github.io/CHAIN/ 獲取。",
      "title": "From Perception to Action: An Interactive Benchmark for Vision Reasoning",
      "title_zh": "從感知到行動：一個用於視覺推理的互動式基準"
    },
    {
      "arxiv_id": "2602.20813",
      "authors": [
        "Nora Petrova",
        "John Burden"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.270405+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Pressure Reveals Character: Behavioural Alignment Evaluation at Depth",
          "url": "https://arxiv.org/abs/2602.20813"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Pressure Reveals Character: Behavioural Alignment Evaluation at Depth",
        "url": "https://arxiv.org/abs/2602.20813"
      },
      "published_at": "2026-02-24T11:52:17+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.9,
        "llm_relevance_score": 25.2,
        "recency_score": 0.9130758331519443,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 33.31307583315194
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20813",
      "summary": "Evaluating alignment in language models requires testing how they behave under realistic pressure, not just what they claim they would do. While alignment failures increasingly cause real-world harm, comprehensive evaluation frameworks with realistic multi-turn scenarios remain lacking. We introduce an alignment benchmark spanning 904 scenarios across six categories -- Honesty, Safety, Non-Manipulation, Robustness, Corrigibility, and Scheming -- validated as realistic by human raters. Our scenar",
      "summary_zh": "評估語言模型的對齊性 (alignment) 需要測試它們在現實壓力下的行為方式，而不僅僅是它們聲稱會怎麼做。儘管 alignment 失敗日益造成真實世界的危害，但仍缺乏具備現實多輪情境的全面評估框架。我們引入了一個 alignment benchmark，涵蓋了六個類別的 904 種情境——Honesty、Safety、Non-Manipulation、Robustness、Corrigibility 和 Scheming——這些情境經由人類評審員驗證為真實。我們的情境",
      "title": "Pressure Reveals Character: Behavioural Alignment Evaluation at Depth",
      "title_zh": "壓力顯露本性：深度行為對齊評估"
    },
    {
      "arxiv_id": "2602.20720",
      "authors": [
        "Che Wang",
        "Jiaming Zhang",
        "Ziqi Zhang",
        "Zijie Wang",
        "Yinghui Wang",
        "Jianbo Gao",
        "Tao Wei",
        "Zhong Chen",
        "Wei Yang Bryan Lim"
      ],
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.273979+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs",
          "url": "https://arxiv.org/abs/2602.20720"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs",
        "url": "https://arxiv.org/abs/2602.20720"
      },
      "published_at": "2026-02-24T09:32:19+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.9,
        "llm_relevance_score": 25.2,
        "recency_score": 0.9042438133399864,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 33.30424381333999
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20720",
      "summary": "The integration of external data services (e.g., Model Context Protocol, MCP) has made large language model-based agents increasingly powerful for complex task execution. However, this advancement introduces critical security vulnerabilities, particularly indirect prompt injection (IPI) attacks. Existing attack methods are limited by their reliance on static patterns and evaluation on simple language models, failing to address the fast-evolving nature of modern AI agents. We introduce AdapTools,",
      "summary_zh": "外部數據服務（例如 Model Context Protocol, MCP）的整合，使得基於大型語言模型的 agents 在執行複雜任務方面日益強大。然而，這項進展也帶來了嚴重的安全漏洞，特別是 indirect prompt injection (IPI) 攻擊。現有的攻擊方法受限於其對靜態模式的依賴以及對簡單語言模型的評估，未能解決現代 AI agents 快速演變的特性。我們引入了 AdapTools，",
      "title": "AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs",
      "title_zh": "AdapTools：針對 Agentic LLMs 的基於自適應工具的間接 Prompt Injection 攻擊"
    },
    {
      "arxiv_id": "2602.20739",
      "authors": [],
      "categories": [],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.272403+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "PyVision-RL: Forging Open Agentic Vision Models via RL",
          "url": "https://arxiv.org/abs/2602.20739"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "PyVision-RL: Forging Open Agentic Vision Models via RL",
        "url": "https://arxiv.org/abs/2602.20739"
      },
      "published_at": "2026-02-24T10:08:33+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9065219398854344,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 32.90652193988544
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20739",
      "summary": "Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn tool use. Using a unified training pipeline, we develop PyVision-Image and PyVision-Video for image and video understanding. For video reasoning, PyVision-Video employs on-demand context construction, selectively sampling task-relevant frames during reasoning to significantly reduce visual token usage. Experiments show strong performance and improved efficiency, demonstrating that sustained interaction and on-demand visual processing are critical for scalable multimodal agents.",
      "summary_zh": "用於 agentic multimodal models 的 Reinforcement learning 經常面臨 interaction collapse 的問題，即模型學會減少 tool usage 和 multi-turn reasoning，從而限制了 agentic behavior 的益處。我們介紹 PyVision-RL，這是一個針對 open-weight multimodal models 的 Reinforcement learning 框架，它能穩定 training 並維持互動。我們的方法結合了 oversampling-filtering-ranking rollout 策略與 accumulative tool reward，以防止 collapse 並鼓勵 multi-turn tool use。透過統一的 training pipeline，我們開發了用於 image 和 video understanding 的 PyVision-Image 和 PyVision-Video。對於 video reasoning，PyVision-Video 採用 on-demand context construction，在 reasoning 期間選擇性地採樣與任務相關的 frames，以顯著減少 visual token 的使用。實驗證明了強大的性能和改進的效率，表明 sustained interaction 和 on-demand visual processing 對於可擴展的 multimodal agents 至關重要。",
      "title": "PyVision-RL: Forging Open Agentic Vision Models via RL",
      "title_zh": "PyVision-RL: 透過 RL 打造開放式 Agentic 視覺模型"
    },
    {
      "arxiv_id": "2602.21158",
      "authors": [
        "Dengjia Zhang",
        "Xiaoou Liu",
        "Lu Cheng",
        "Yaqing Wang",
        "Kenton Murray",
        "Hua Wei"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.396145+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards",
          "url": "https://arxiv.org/abs/2602.21158"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards",
        "url": "https://arxiv.org/abs/2602.21158"
      },
      "published_at": "2026-02-24T18:04:54+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.88,
        "llm_relevance_score": 24.64,
        "recency_score": 0.9370110675596901,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 32.77701106755969
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21158",
      "summary": "Large language models (LLMs) are increasingly deployed as multi-step decision-making agents, where effective reward design is essential for guiding learning. Although recent work explores various forms of reward shaping and step-level credit assignment, a key signal remains largely overlooked: the intrinsic uncertainty of LLMs. Uncertainty reflects model confidence, reveals where exploration is needed, and offers valuable learning cues even in failed trajectories. We introduce SELAUR: Self Evolv",
      "summary_zh": "Large language models (LLMs) 越來越多地被部署為 multi-step decision-making agents，其中有效的 reward design 對於引導學習至關重要。儘管最近的研究探索了各種形式的 reward shaping 和 step-level credit assignment，但一個關鍵信號卻 largely overlooked：LLMs 的 intrinsic uncertainty。不確定性反映了 model confidence，揭示了何處需要 exploration，即使在 failed trajectories 中也能提供有價值的 learning cues。我們介紹 SELAUR: Self Evolv",
      "title": "SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards",
      "title_zh": "SELAUR: 透過不確定性感知獎勵自我演進的 LLM Agent"
    },
    {
      "arxiv_id": "2602.21127",
      "authors": [
        "Xinfeng Li",
        "Shenyu Dai",
        "Kelong Zheng",
        "Yue Xiao",
        "Gelei Deng",
        "Wei Dong",
        "Xiaofeng Wang"
      ],
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR",
        "cs.SI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.263503+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "\"Are You Sure?\": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems",
          "url": "https://arxiv.org/abs/2602.21127"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "\"Are You Sure?\": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems",
        "url": "https://arxiv.org/abs/2602.21127"
      },
      "published_at": "2026-02-24T17:23:11+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.88,
        "llm_relevance_score": 24.64,
        "recency_score": 0.9343004833374221,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 32.77430048333743
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21127",
      "summary": "Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized against their human users. While extensive research focuses on agent-centric threats, human susceptibility to deception by a compromised agent remains unexplored. We present the first large-scale empirical study with 303 parti",
      "summary_zh": "Large language model (LLM) agents 正在迅速成為軟體開發和醫療保健等 high-stakes domains 中值得信賴的 copilots。然而，這種日益加深的信任引入了一個新的 attack surface：Agent-Mediated Deception (AMD)，其中 compromised agents 被武器化以對抗其人類用戶。儘管大量研究集中於 agent-centric threats，但人類對於 compromised agent 欺騙的 susceptibility 仍未被探索。我們首次提出了一項包含 303 名參與者的大規模 empirical study",
      "title": "\"Are You Sure?\": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems",
      "title_zh": "「你確定嗎？」：LLM 驅動的 Agentic 系統中人類感知脆弱性的實證研究"
    },
    {
      "arxiv_id": "2602.21103",
      "authors": [
        "Sanket Badhe",
        "Deep Shah"
      ],
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.033853+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning",
          "url": "https://arxiv.org/abs/2602.21103"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning",
        "url": "https://arxiv.org/abs/2602.21103"
      },
      "published_at": "2026-02-24T17:03:21+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.88,
        "llm_relevance_score": 24.64,
        "recency_score": 0.9330145432157084,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 32.77301454321571
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21103",
      "summary": "Advanced reasoning typically requires Chain-of-Thought prompting, which is accurate but incurs prohibitive latency and substantial test-time inference costs. The standard alternative, fine-tuning smaller models, often sacrifices interpretability while introducing significant resource and operational overhead. To address these limitations, we introduce Prompt-Level Distillation (PLD). We extract explicit reasoning patterns from a Teacher model and organize them into a structured list of expressiv",
      "summary_zh": "Advanced reasoning 通常需要 Chain-of-Thought prompting，這種方法雖然準確，但會產生過高的 latency 和大量的 test-time inference costs。標準的替代方案是 fine-tuning 較小的 models，這通常會犧牲 interpretability，同時引入顯著的 resource 和 operational overhead。為了解決這些限制，我們引入 Prompt-Level Distillation (PLD)。我們從一個 Teacher model 中提取明確的 reasoning patterns，並將其組織成一個結構化的 expressiv 列表",
      "title": "Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning",
      "title_zh": "Prompt-Level Distillation：一種用於高效推理的非參數 Model Fine-Tuning 替代方案"
    },
    {
      "arxiv_id": "2602.20759",
      "authors": [
        "Yu Fu",
        "Seongho Son",
        "Ilija Bogunovic"
      ],
      "categories": [
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.036959+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Overton Pluralistic Reinforcement Learning for Large Language Models",
          "url": "https://arxiv.org/abs/2602.20759"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Overton Pluralistic Reinforcement Learning for Large Language Models",
        "url": "https://arxiv.org/abs/2602.20759"
      },
      "published_at": "2026-02-24T10:39:27+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.88,
        "llm_relevance_score": 24.64,
        "recency_score": 0.9084692734608628,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 32.74846927346086
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20759",
      "summary": "Existing alignment paradigms remain limited in capturing the pluralistic nature of human values. Overton Pluralism addresses this gap by generating responses with diverse perspectives from a single query. This paper introduces OP-GRPO (Overton Pluralistic Group Relative Policy Optimization), a reinforcement learning framework for implicit Overton Pluralism that enables a single large language model to produce pluralistic responses without explicit prompting or modular orchestration. Our workflow",
      "summary_zh": "現有的 alignment paradigms 在捕捉人類價值觀的 pluralistic nature 方面仍然有限。Overton Pluralism 通過從單一 query 生成具有多樣化視角的響應來解決這一差距。本文介紹了 OP-GRPO (Overton Pluralistic Group Relative Policy Optimization)，這是一個用於 implicit Overton Pluralism 的 reinforcement learning 框架，它使單個 large language model 能夠在沒有 explicit prompting 或 modular orchestration 的情況下產生 pluralistic responses。我們的 workflow",
      "title": "Overton Pluralistic Reinforcement Learning for Large Language Models",
      "title_zh": "用於大型語言模型的 Overton Pluralistic Reinforcement Learning"
    },
    {
      "arxiv_id": "2602.21157",
      "authors": [
        "Quanxin Shou",
        "Fangqi Zhu",
        "Shawn Chen",
        "Puxin Yan",
        "Zhengyang Yan",
        "Yikun Miao",
        "Xiaoyi Pang",
        "Zicong Hong",
        "Ruikai Shi",
        "Hao Huang",
        "Jie Zhang",
        "Song Guo"
      ],
      "categories": [
        "cs.RO"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:35.629687+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ro",
          "tier": 1,
          "title": "HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning",
          "url": "https://arxiv.org/abs/2602.21157"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ro",
        "tier": 1,
        "title": "HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning",
        "url": "https://arxiv.org/abs/2602.21157"
      },
      "published_at": "2026-02-24T18:04:31+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.87,
        "llm_relevance_score": 24.36,
        "recency_score": 0.9369861243100313,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 32.49698612431003
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21157",
      "summary": "Vision-Language-Action (VLA) models have shown strong performance in robotic manipulation, but often struggle in long-horizon or out-of-distribution scenarios due to the lack of explicit mechanisms for multimodal reasoning and anticipating how the world will evolve under action. Recent works introduce textual chain-of-thought or visual subgoal prediction within VLA models to reason, but still fail to offer a unified human-like reasoning framework for joint textual reasoning, visual foresight, an",
      "summary_zh": "Vision-Language-Action (VLA) 模型在機器人操作中展現出強勁性能，但由於缺乏明確的多模態推理機制以及預測世界在行動下如何演變的能力，它們往往在長期或 out-of-distribution 情境中遇到困難。最近的研究在 VLA 模型中引入了文本 Chain-of-Thought 或視覺子目標預測以進行推理，但仍未能提供一個統一的類人推理框架，用於聯合文本推理、視覺預見和",
      "title": "HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning",
      "title_zh": "HALO: 一個用於具身多模態 Chain-of-Thought 推理的統一 Vision-Language-Action 模型"
    },
    {
      "arxiv_id": "2602.21053",
      "authors": [],
      "categories": [],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.024196+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "OCR-Agent: Agentic OCR with Capability and Memory Reflection",
          "url": "https://arxiv.org/abs/2602.21053"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "OCR-Agent: Agentic OCR with Capability and Memory Reflection",
        "url": "https://arxiv.org/abs/2602.21053"
      },
      "published_at": "2026-02-24T16:10:27+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.82,
        "llm_relevance_score": 22.959999999999997,
        "recency_score": 0.929593298631575,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 32.08959329863157
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21053",
      "summary": "Large Vision-Language Models (VLMs) have demonstrated significant potential on complex visual understanding tasks through iterative optimization methods.However, these models generally lack effective self-correction mechanisms, making it difficult for them to independently rectify cognitive biases. Consequently, during multi-turn revisions, they often fall into repetitive and ineffective attempts, failing to achieve stable improvements in answer quality.To address this issue, we propose a novel iterative self-correction framework that endows models with two key capabilities: Capability Reflection and Memory Reflection. This framework guides the model to first diagnose errors and generate a correction plan via Capability Reflection, then leverage Memory Reflection to review past attempts to avoid repetition and explore new solutions, and finally, optimize the answer through rigorous re-reasoning. Experiments on the challenging OCRBench v2 benchmark show that OCR-Agent outperforms the current open-source SOTA model InternVL3-8B by +2.0 on English and +1.2 on Chinese subsets, while achieving state-of-the-art results in Visual Understanding (79.9) and Reasoning (66.5) - surpassing even larger fine-tuned models. Our method demonstrates that structured, self-aware reflection can significantly enhance VLMs' reasoning robustness without additional training. Code: https://github.com/AIGeeksGroup/OCR-Agent.",
      "summary_zh": "大型 Vision-Language Models (VLM) 透過迭代優化方法，在複雜的視覺理解任務上展現了巨大潛力。然而，這些模型通常缺乏有效的自我校正機制，使其難以獨立糾正 cognitive biases。因此，在 multi-turn 修正過程中，它們經常陷入重複且無效的嘗試，未能實現答案品質的穩定提升。為解決此問題，我們提出了一種新穎的迭代自我校正框架，賦予模型兩項關鍵能力：Capability Reflection 和 Memory Reflection。此框架引導模型首先透過 Capability Reflection 診斷錯誤並生成校正計劃，然後利用 Memory Reflection 回顧過去的嘗試以避免重複並探索新的解決方案，最後透過嚴謹的 re-reasoning 優化答案。在具挑戰性的 OCRBench v2 基準測試上的實驗表明，OCR-Agent 在英文子集上比當前開源 SOTA 模型 InternVL3-8B 高出 +2.0，在中文子集上高出 +1.2，同時在 Visual Understanding (79.9) 和 Reasoning (66.5) 上達到最先進的成果——甚至超越了更大的 fine-tuned 模型。我們的方法表明，結構化、自我意識的 reflection 可以在無需額外訓練的情況下顯著增強 VLM 的推理穩健性。代碼：https://github.com/AIGeeksGroup/OCR-Agent。",
      "title": "OCR-Agent: Agentic OCR with Capability and Memory Reflection",
      "title_zh": "OCR-Agent: 具備能力與記憶 Reflection 的代理式 OCR"
    },
    {
      "arxiv_id": "2602.21189",
      "authors": [
        "Anas Barakat",
        "Souradip Chakraborty",
        "Khushbu Pahwa",
        "Amrit Singh Bedi"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.261535+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training",
          "url": "https://arxiv.org/abs/2602.21189"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training",
        "url": "https://arxiv.org/abs/2602.21189"
      },
      "published_at": "2026-02-24T18:43:08+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9395022243668838,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.939502224366883
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21189",
      "summary": "Pass@k is a widely used performance metric for verifiable large language model tasks, including mathematical reasoning, code generation, and short-answer reasoning. It defines success if any of $k$ independently sampled solutions passes a verifier. This multi-sample inference metric has motivated inference-aware fine-tuning methods that directly optimize pass@$k$. However, prior work reports a recurring trade-off: pass@k improves while pass@1 degrades under such methods. This trade-off is practi",
      "summary_zh": "Pass@k 是一個廣泛用於可驗證的大型語言模型任務的性能指標，包括數學推理、代碼生成和簡答推理。它定義為如果 $k$ 個獨立採樣的解決方案中有任何一個通過驗證器，則視為成功。這個多樣本推理指標激發了直接優化 pass@$k$ 的 inference-aware fine-tuning 方法。然而，先前的研究報告了一個反覆出現的 trade-off：在此類方法下，pass@k 提升而 pass@1 降低。這種 trade-off 在實務上",
      "title": "Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training",
      "title_zh": "為何 Pass@k 優化會降低 Pass@1：LLM 後訓練中的 Prompt 干擾"
    },
    {
      "arxiv_id": "2602.21143",
      "authors": [
        "Debjit Paul",
        "Daniel Murphy",
        "Milan Gritta",
        "Ronald Cardenas",
        "Victor Prokhorov",
        "Lena Sophia Bolliger",
        "Aysim Toker",
        "Roy Miles",
        "Andreea-Maria Oncescu",
        "Jasivan Alex Sivakumar",
        "Philipp Borchert",
        "Ismail Elezi",
        "Meiru Zhang",
        "Ka Yiu Lee",
        "Guchun Zhang",
        "Jun Wang",
        "Gerasimos Lampouras"
      ],
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.262979+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "A Benchmark for Deep Information Synthesis",
          "url": "https://arxiv.org/abs/2602.21143"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "A Benchmark for Deep Information Synthesis",
        "url": "https://arxiv.org/abs/2602.21143"
      },
      "published_at": "2026-02-24T17:43:32+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9356217649839612,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.935621764983964
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21143",
      "summary": "Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming probl",
      "summary_zh": "基於大型語言模型 (LLM) 的 agent 越來越多地用於解決涉及工具使用的複雜任務，例如網頁瀏覽、代碼執行和數據分析。然而，當前的評估基準測試未能充分評估它們解決真實世界任務的能力，這些任務需要綜合來自多個來源的資訊並推斷超出簡單事實檢索的見解。為此，我們引入了 DEEPSYNTH，一個新穎的基準測試，旨在評估 agent 解決真實、耗時的問題",
      "title": "A Benchmark for Deep Information Synthesis",
      "title_zh": "一個用於深度資訊綜合的基準測試"
    },
    {
      "arxiv_id": "2602.21061",
      "authors": [
        "David Koplow",
        "Tomer Galanti",
        "Tomaso Poggio"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.265201+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Tool Building as a Path to \"Superintelligence\"",
          "url": "https://arxiv.org/abs/2602.21061"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Tool Building as a Path to \"Superintelligence\"",
        "url": "https://arxiv.org/abs/2602.21061"
      },
      "published_at": "2026-02-24T16:22:10+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9303499769015768,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.930349976901578
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21061",
      "summary": "The Diligent Learner framework suggests LLMs can achieve superintelligence via test-time search, provided a sufficient step-success probability $γ$. In this work, we design a benchmark to measure $γ$ on logical out-of-distribution inference. We construct a class of tasks involving GF(2) circuit reconstruction that grow more difficult with each reasoning step, and that are, from an information-theoretic standpoint, impossible to reliably solve unless the LLM carefully integrates all of the inform",
      "summary_zh": "Diligent Learner 框架表明，LLM 可以透過 test-time search 實現超級智慧，前提是存在足夠的步驟成功機率 $γ$。在這項工作中，我們設計了一個基準測試來測量邏輯 out-of-distribution 推理上的 $γ$。我們構建了一類涉及 GF(2) 電路重建的任務，這些任務隨著每個推理步驟而變得更困難，並且從資訊理論的角度來看，除非 LLM 仔細整合所有資訊，否則無法可靠地解決",
      "title": "Tool Building as a Path to \"Superintelligence\"",
      "title_zh": "工具建構作為通往「超級智慧」之路"
    },
    {
      "arxiv_id": "2602.20999",
      "authors": [
        "Bowen Zheng",
        "Yongli Xiang",
        "Ziming Hong",
        "Zerong Lin",
        "Chaojian Yu",
        "Tongliang Liu",
        "Xinge You"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.025541+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models",
          "url": "https://arxiv.org/abs/2602.20999"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models",
        "url": "https://arxiv.org/abs/2602.20999"
      },
      "published_at": "2026-02-24T15:20:01+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9263432648928132,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.926343264892814
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20999",
      "summary": "Image-to-Video (I2V) generation models, which condition video generation on reference images, have shown emerging visual instruction-following capability, allowing certain visual cues in reference images to act as implicit control signals for video generation. However, this capability also introduces a previously overlooked risk: adversaries may exploit visual instructions to inject malicious intent through the image modality. In this work, we uncover this risk by proposing Visual Instruction In",
      "summary_zh": "Image-to-Video (I2V) generation models 透過參考影像來條件化視訊生成，已展現出新興的視覺指令遵循能力，允許參考影像中的某些視覺線索作為視訊生成的隱式控制訊號。然而，這種能力也引入了一個先前被忽視的風險：攻擊者可能會利用視覺指令透過影像模態注入惡意意圖。在這項工作中，我們透過提出 Visual Instruction In 來揭示這種風險",
      "title": "VII: Visual Instruction Injection for Jailbreaking Image-to-Video Generation Models",
      "title_zh": "VII: 視覺指令注入用於越獄影像到視訊生成模型"
    },
    {
      "arxiv_id": "2602.20937",
      "authors": [
        "Akshita Gupta",
        "Marieme Ngom",
        "Sam Foreman",
        "Venkatram Vishwanath"
      ],
      "categories": [
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.401606+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Extending $μ$P: Spectral Conditions for Feature Learning Across Optimizers",
          "url": "https://arxiv.org/abs/2602.20937"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Extending $μ$P: Spectral Conditions for Feature Learning Across Optimizers",
        "url": "https://arxiv.org/abs/2602.20937"
      },
      "published_at": "2026-02-24T14:17:51+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9223527409391522,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.922352740939154
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20937",
      "summary": "Several variations of adaptive first-order and second-order optimization methods have been proposed to accelerate and scale the training of large language models. The performance of these optimization routines is highly sensitive to the choice of hyperparameters (HPs), which are computationally expensive to tune for large-scale models. Maximal update parameterization $(μ$P$)$ is a set of scaling rules which aims to make the optimal HPs independent of the model size, thereby allowing the HPs tune",
      "summary_zh": "已提出了多種自適應一階和二階優化方法的變體，以加速和擴展大型語言模型的訓練。這些優化程序的性能對超參數 (HPs) 的選擇高度敏感，而對於大型模型來說，調整 HPs 的計算成本高昂。Maximal update parameterization ($μ$P$) 是一組縮放規則，旨在使最佳 HPs 獨立於模型大小，從而允許 HPs 的調整",
      "title": "Extending $μ$P: Spectral Conditions for Feature Learning Across Optimizers",
      "title_zh": "擴展 $μ$P：用於優化器之間特徵學習的頻譜條件"
    },
    {
      "arxiv_id": "2602.20878",
      "authors": [
        "Dhita Putri Pratama",
        "Soyeon Caren Han",
        "Yihao Ding"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.269693+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs",
          "url": "https://arxiv.org/abs/2602.20878"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs",
        "url": "https://arxiv.org/abs/2602.20878"
      },
      "published_at": "2026-02-24T13:20:07+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9186621927979293,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.91866219279793
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20878",
      "summary": "Large Vision-Language Models (LVLMs) achieve strong performance on visual question answering benchmarks, yet often rely on spurious correlations rather than genuine causal reasoning. Existing evaluations primarily assess the correctness of the answers, making it unclear whether failures arise from limited reasoning capability or from misidentifying causally relevant information. We introduce Vision-Language Causal Graphs (VLCGs), a structured, query-conditioned representation that explicitly enc",
      "summary_zh": "大型視覺-語言模型 (LVLMs) 在視覺問答基準上取得了強勁的表現，但往往依賴虛假相關性而非真正的因果推理。現有的評估主要衡量答案的正確性，這使得人們不清楚失敗是由於推理能力有限還是誤判了因果相關資訊。我們引入了 Vision-Language Causal Graphs (VLCGs)，這是一種結構化、查詢條件式的表示，明確地編碼",
      "title": "Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs",
      "title_zh": "透過結構化相關性圖診斷視覺-語言模型中的因果推理"
    },
    {
      "arxiv_id": "2602.20867",
      "authors": [
        "Yanna Jiang",
        "Delong Li",
        "Haiyu Deng",
        "Baihe Ma",
        "Xu Wang",
        "Qin Wang",
        "Guangsheng Yu"
      ],
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CE",
        "cs.ET"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.270168+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "SoK: Agentic Skills -- Beyond Tool Use in LLM Agents",
          "url": "https://arxiv.org/abs/2602.20867"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "SoK: Agentic Skills -- Beyond Tool Use in LLM Agents",
        "url": "https://arxiv.org/abs/2602.20867"
      },
      "published_at": "2026-02-24T13:11:38+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9181211495721037,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.918121149572105
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20867",
      "summary": "Agentic systems increasingly rely on reusable procedural capabilities, \\textit{a.k.a., agentic skills}, to execute long-horizon workflows reliably. These capabilities are callable modules that package procedural knowledge with explicit applicability conditions, execution policies, termination criteria, and reusable interfaces. Unlike one-off plans or atomic tool calls, skills operate (and often do well) across tasks.\n  This paper maps the skill layer across the full lifecycle (discovery, practic",
      "summary_zh": "代理系統越來越依賴可重複使用的程序能力，即代理技能 (agentic skills)，以可靠地執行長期工作流程。這些能力是可調用模組，將程序知識與明確的適用條件、執行策略、終止標準和可重複使用的介面打包在一起。與一次性計畫或原子工具呼叫不同，技能在不同任務中運作（並且通常表現良好）。本文描繪了貫穿整個生命週期（發現、實踐）的技能層",
      "title": "SoK: Agentic Skills -- Beyond Tool Use in LLM Agents",
      "title_zh": "SoK: 代理技能——超越 LLM 代理中的工具使用"
    },
    {
      "arxiv_id": "2602.20816",
      "authors": [
        "Sayantan Dasgupta",
        "Trevor Cohn",
        "Timothy Baldwin"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.403542+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Don't Ignore the Tail: Decoupling top-K Probabilities for Efficient Language Model Distillation",
          "url": "https://arxiv.org/abs/2602.20816"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Don't Ignore the Tail: Decoupling top-K Probabilities for Efficient Language Model Distillation",
        "url": "https://arxiv.org/abs/2602.20816"
      },
      "published_at": "2026-02-24T11:54:06+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9131910316982432,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.913191031698243
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20816",
      "summary": "The core learning signal used in language model distillation is the standard Kullback-Leibler (KL) divergence between the student and teacher distributions. Traditional KL divergence tends to be dominated by the next tokens with the highest probabilities, i.e., the teacher's modes, thereby diminishing the influence of less probable yet potentially informative components of the output distribution. We propose a new tail-aware divergence that decouples the contribution of the teacher model's top-K",
      "summary_zh": "語言模型蒸餾中使用的核心學習訊號是學生和教師分佈之間的標準 Kullback-Leibler (KL) 散度。傳統的 KL 散度往往由機率最高的下一個 tokens，即教師模式 (teacher's modes) 所主導，從而削弱了輸出分佈中機率較低但可能具有資訊量的成分的影響。我們提出了一種新的尾部感知散度 (tail-aware divergence)，它解耦了教師模型的 top-K 貢獻",
      "title": "Don't Ignore the Tail: Decoupling top-K Probabilities for Efficient Language Model Distillation",
      "title_zh": "不要忽略尾部：解耦 top-K 機率以實現高效語言模型蒸餾"
    },
    {
      "arxiv_id": "2602.20732",
      "authors": [
        "Chao Fei",
        "Guozhong Li",
        "Chenxi Liu",
        "Panos Kalnis"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.272853+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference",
          "url": "https://arxiv.org/abs/2602.20732"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference",
        "url": "https://arxiv.org/abs/2602.20732"
      },
      "published_at": "2026-02-24T09:54:59+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9056682808978148,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.905668280897814
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20732",
      "summary": "Long-context LLMs demand accurate inference at low latency, yet decoding becomes primarily constrained by KV cache as context grows. Prior pruning methods are largely context-agnostic: their token selection ignores step-wise relevance and local semantics, which undermines quality. Moreover, their irregular accesses and selection overheads yield only limited wall-clock speedups. To address this, we propose \\textbf{CHESS}, an \\textit{algorithm-system co-design} KV-cache management system. Algorith",
      "summary_zh": "長上下文 LLMs 需要在低延遲下進行準確推理，然而隨著上下文的增長，解碼主要受 KV cache 限制。先前的剪枝方法大多是上下文無關的：它們的 token 選擇忽略了逐步相關性和局部語義，這會損害質量。此外，它們不規則的存取和選擇開銷只產生了有限的 wall-clock speedups。為了解決這個問題，我們提出了 \textbf{CHESS}，一個 \textit{algorithm-system co-design} 的 KV-cache 管理系統。Algorith",
      "title": "CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference",
      "title_zh": "CHESS：用於長上下文 LLM 推理的上下文感知分層高效語義選擇"
    },
    {
      "arxiv_id": "2602.20727",
      "authors": [
        "Xindian Ma",
        "Rundong Kong",
        "Peng Zhang",
        "Ruoxiang Huang",
        "Yongyu Jiang"
      ],
      "categories": [
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.037906+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition",
          "url": "https://arxiv.org/abs/2602.20727"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition",
        "url": "https://arxiv.org/abs/2602.20727"
      },
      "published_at": "2026-02-24T09:45:10+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9050510854895402,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.90505108548954
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20727",
      "summary": "LoRA has become a universal Parameter-Efficient Fine-Tuning (PEFT) technique that equips Large Language Models (LLMs) to adapt quickly to new tasks. However, when these models are scaled up, even the latest LoRA variants still introduce considerable overhead in trainable parameters. Conversely, aggressively lowering the rank to curb this overhead markedly degrades performance in complex multi-task settings. We propose ID-LoRA, a novel PEFT framework that breaks the trade-off. Its core innovation",
      "summary_zh": "LoRA 已成為一種通用的 Parameter-Efficient Fine-Tuning (PEFT) 技術，使 Large Language Models (LLMs) 能夠快速適應新任務。然而，當這些模型擴展時，即使是最新的 LoRA 變體仍然會在 trainable parameters 中引入相當大的開銷。相反地，激進地降低 rank 以抑制這種開銷會顯著降低在複雜 multi-task 設定下的性能。我們提出了 ID-LoRA，這是一種突破傳統權衡的新穎 PEFT 框架。其核心創新",
      "title": "ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition",
      "title_zh": "ID-LoRA：受矩陣插值分解啟發的高效低秩適應"
    },
    {
      "arxiv_id": "2602.20722",
      "authors": [
        "Xu Wan",
        "Yansheng Wang",
        "Wenqi Huang",
        "Mingyang Sun"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.273765+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning",
          "url": "https://arxiv.org/abs/2602.20722"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning",
        "url": "https://arxiv.org/abs/2602.20722"
      },
      "published_at": "2026-02-24T09:35:43+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9044573405585519,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.90445734055855
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20722",
      "summary": "Traditional on-policy Reinforcement Learning with Verifiable Rewards (RLVR) frameworks suffer from experience waste and reward homogeneity, which directly hinders learning efficiency on difficult samples during large language models post-training. In this paper, we introduce Batch Adaptation Policy Optimization (BAPO), an off-policy RLVR framework to improve the data efficiency in large language models post-training. It dynamically selects training batches by re-evaluating historically difficult",
      "summary_zh": "傳統的 on-policy Reinforcement Learning with Verifiable Rewards (RLVR) 框架存在經驗浪費和獎勵同質性的問題，這直接阻礙了大型語言模型 post-training 期間在困難樣本上的學習效率。在本文中，我們引入了 Batch Adaptation Policy Optimization (BAPO)，這是一個 off-policy RLVR 框架，旨在提高大型語言模型 post-training 的資料效率。它通過重新評估歷史上困難的樣本動態選擇訓練批次",
      "title": "Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning",
      "title_zh": "緩衝區至關重要：釋放 Off-Policy 強化學習在大型語言模型推理中的力量"
    },
    {
      "arxiv_id": "2602.20743",
      "authors": [],
      "categories": [],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.037531+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "Adaptive Text Anonymization: Learning Privacy-Utility Trade-offs via Prompt Optimization",
          "url": "https://arxiv.org/abs/2602.20743"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "Adaptive Text Anonymization: Learning Privacy-Utility Trade-offs via Prompt Optimization",
        "url": "https://arxiv.org/abs/2602.20743"
      },
      "published_at": "2026-02-24T10:12:40+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9067811330891232,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.506781133089127
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20743",
      "summary": "Anonymizing textual documents is a highly context-sensitive problem: the appropriate balance between privacy protection and utility preservation varies with the data domain, privacy objectives, and downstream application. However, existing anonymization methods rely on static, manually designed strategies that lack the flexibility to adjust to diverse requirements and often fail to generalize across domains. We introduce adaptive text anonymization, a new task formulation in which anonymization strategies are automatically adapted to specific privacy-utility requirements. We propose a framework for task-specific prompt optimization that automatically constructs anonymization instructions for language models, enabling adaptation to different privacy goals, domains, and downstream usage patterns. To evaluate our approach, we present a benchmark spanning five datasets with diverse domains, privacy constraints, and utility objectives. Across all evaluated settings, our framework consistently achieves a better privacy-utility trade-off than existing baselines, while remaining computationally efficient and effective on open-source language models, with performance comparable to larger closed-source models. Additionally, we show that our method can discover novel anonymization strategies that explore different points along the privacy-utility trade-off frontier.",
      "summary_zh": "文本文件匿名化是一個高度上下文敏感的問題：隱私保護和效用保留之間的適當平衡會因資料領域、隱私目標和下游應用而異。然而，現有的匿名化方法依賴於靜態、手動設計的策略，缺乏彈性以適應多樣化的要求，並且常常無法泛化到不同領域。我們引入了自適應文本匿名化，這是一種新的任務公式，其中匿名化策略會自動適應特定的隱私-效用要求。我們提出了一個用於任務特定 prompt optimization 的框架，該框架會自動為 language models 構建匿名化指令，從而能夠適應不同的隱私目標、領域和下游使用模式。為了評估我們的方法，我們提出了一個涵蓋五個具有不同領域、隱私約束和效用目標的資料集的 benchmark。在所有評估設定中，我們的框架始終比現有的 baselines 實現更好的 privacy-utility trade-off，同時在 open-source language models 上保持計算效率和有效性，其性能可與更大的 closed-source models 媲美。此外，我們展示了我們的方法可以發現新穎的匿名化策略，這些策略探索了 privacy-utility trade-off 邊界上的不同點。",
      "title": "Adaptive Text Anonymization: Learning Privacy-Utility Trade-offs via Prompt Optimization",
      "title_zh": "自適應文本匿名化：透過提示優化學習隱私-效用權衡"
    },
    {
      "arxiv_id": "2602.21035",
      "authors": [
        "Junhao Xiao",
        "Zhiyu Wu",
        "Hao Lin",
        "Yi Chen",
        "Yahui Liu",
        "Xiaoran Zhao",
        "Zixu Wang",
        "Zejiang He"
      ],
      "categories": [
        "cs.CV",
        "cs.MM"
      ],
      "entities": [
        "01-ai"
      ],
      "first_seen_at": "2026-02-25T06:31:33.024704+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "Not Just What's There: Enabling CLIP to Comprehend Negated Visual Descriptions Without Fine-tuning",
          "url": "https://arxiv.org/abs/2602.21035"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "Not Just What's There: Enabling CLIP to Comprehend Negated Visual Descriptions Without Fine-tuning",
        "url": "https://arxiv.org/abs/2602.21035"
      },
      "published_at": "2026-02-24T15:55:39+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 2.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9286383741060332,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 31.128638374106032
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21035",
      "summary": "Vision-Language Models (VLMs) like CLIP struggle to understand negation, often embedding affirmatives and negatives similarly (e.g., matching \"no dog\" with dog images). Existing methods refine negation understanding via fine-tuning CLIP's text encoder, risking overfitting. In this work, we propose CLIPGlasses, a plug-and-play framework that enhances CLIP's ability to comprehend negated visual descriptions. CLIPGlasses adopts a dual-stage design: a Lens module disentangles negated semantics from ",
      "summary_zh": "Vision-Language Models (VLMs) 例如 CLIP 在理解否定詞方面存在困難，常常將肯定詞和否定詞嵌入相似（例如，將「no dog」與狗的圖像匹配）。現有方法透過 fine-tuning CLIP 的 text encoder 來改進否定詞的理解，但存在過度擬合的風險。在這項工作中，我們提出了 CLIPGlasses，這是一個即插即用的框架，可以增強 CLIP 理解否定式視覺描述的能力。CLIPGlasses 採用雙階段設計：一個 Lens module 將否定語義從",
      "title": "Not Just What's There: Enabling CLIP to Comprehend Negated Visual Descriptions Without Fine-tuning",
      "title_zh": "不只所見：在不 fine-tuning 的情況下使 CLIP 理解否定式視覺描述"
    },
    {
      "arxiv_id": "2602.21202",
      "authors": [
        "Hanxiang Qin",
        "Alexander Martin",
        "Rohan Jha",
        "Chunsheng Zuo",
        "Reno Kriz",
        "Benjamin Van Durme"
      ],
      "categories": [
        "cs.IR",
        "cs.CL",
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.032436+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Multi-Vector Index Compression in Any Modality",
          "url": "https://arxiv.org/abs/2602.21202"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Multi-Vector Index Compression in Any Modality",
        "url": "https://arxiv.org/abs/2602.21202"
      },
      "published_at": "2026-02-24T18:57:33+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9404432849743801,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.54044328497438
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21202",
      "summary": "We study efficient multi-vector retrieval for late interaction in any modality. Late interaction has emerged as a dominant paradigm for information retrieval in text, images, visual documents, and videos, but its computation and storage costs grow linearly with document length, making it costly for image-, video-, and audio-rich corpora. To address this limitation, we explore query-agnostic methods for compressing multi-vector document representations under a constant vector budget. We introduce",
      "summary_zh": "我們研究了任意模態下用於 late interaction 的高效 multi-vector retrieval。Late interaction 已成為文本、圖像、視覺文件和影片中 information retrieval 的主流範式，但其計算和儲存成本隨 document length 線性增長，這使得其對於富含圖像、影片和音訊的 corpora 而言成本高昂。為解決此限制，我們探索了在恆定 vector budget 下壓縮 multi-vector document representations 的 query-agnostic 方法。我們引入了",
      "title": "Multi-Vector Index Compression in Any Modality",
      "title_zh": "任意模態下的多向量索引壓縮"
    },
    {
      "arxiv_id": "2602.21172",
      "authors": [
        "Ishaan Rawal",
        "Shubh Gupta",
        "Yihan Hu",
        "Wei Zhan"
      ],
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.262250+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning",
          "url": "https://arxiv.org/abs/2602.21172"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning",
        "url": "https://arxiv.org/abs/2602.21172"
      },
      "published_at": "2026-02-24T18:17:21+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9378215420227214,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.537821542022723
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21172",
      "summary": "Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challenges with \\modelname (\\textbf{No} \\textbf{R}easoning for \\textbf{D}riving). Compared to existing VLAs, \\modelname achieves competitive performance while being fine-tuned on $<$60\\% of the data and no r",
      "summary_zh": "Vision-Language-Action (VLA) 模型透過將模組化 pipelines 替換為統一的 end-to-end architectures，正在推動 autonomous driving 的發展。然而，目前的 VLAs 面臨兩個昂貴的要求：(1) 大規模 dataset collection，以及 (2) 密集的 reasoning annotations。在這項工作中，我們透過 \\modelname (\textbf{No} \textbf{R}easoning for \textbf{D}riving) 解決了這兩個挑戰。與現有的 VLAs 相比，\\modelname 在使用少於 60% 的數據進行 fine-tuning 且沒有 r 的情況下，實現了具有競爭力的性能。",
      "title": "NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning",
      "title_zh": "NoRD：一種無需推理即可駕駛的數據高效 Vision-Language-Action 模型"
    },
    {
      "arxiv_id": "2602.21144",
      "authors": [
        "Anurag Dutt",
        "Nimit Shah",
        "Hazem Masarani",
        "Anshul Gandhi"
      ],
      "categories": [
        "cs.DC",
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.396382+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Scaling State-Space Models on Multiple GPUs with Tensor Parallelism",
          "url": "https://arxiv.org/abs/2602.21144"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Scaling State-Space Models on Multiple GPUs with Tensor Parallelism",
        "url": "https://arxiv.org/abs/2602.21144"
      },
      "published_at": "2026-02-24T17:47:54+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9359055266429015,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.535905526642903
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21144",
      "summary": "Selective state space models (SSMs) have rapidly become a compelling backbone for large language models, especially for long-context workloads. Yet in deployment, their inference performance is often bounded by the memory capacity, bandwidth, and latency limits of a single GPU, making multi-GPU execution increasingly necessary. Although tensor parallelism (TP) is widely used to scale Transformer inference, applying it to selective SSM blocks is non-trivial because the SSM mixer couples large pro",
      "summary_zh": "Selective state space models (SSMs) 已迅速成為 large language models 引人注目的骨幹，尤其適用於 long-context workloads。然而在部署中，其 inference performance 常常受到單個 GPU 的 memory capacity、bandwidth 和 latency 限制，使得 multi-GPU execution 變得越來越必要。儘管 tensor parallelism (TP) 被廣泛用於擴展 Transformer inference，但將其應用於 selective SSM blocks 並非易事，因為 SSM mixer 耦合了大量的 pro",
      "title": "Scaling State-Space Models on Multiple GPUs with Tensor Parallelism",
      "title_zh": "使用 Tensor Parallelism 在多個 GPU 上擴展 State-Space Models"
    },
    {
      "arxiv_id": "2602.21044",
      "authors": [
        "Yanrui Wu",
        "Lingling Zhang",
        "Xinyu Zhang",
        "Jiayu Chang",
        "Pengyu Li",
        "Xu Jiang",
        "Jingtao Hu",
        "Jun Liu"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.265947+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "LogicGraph : Benchmarking Multi-Path Logical Reasoning via Neuro-Symbolic Generation and Verification",
          "url": "https://arxiv.org/abs/2602.21044"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "LogicGraph : Benchmarking Multi-Path Logical Reasoning via Neuro-Symbolic Generation and Verification",
        "url": "https://arxiv.org/abs/2602.21044"
      },
      "published_at": "2026-02-24T16:04:26+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9292049733037935,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.529204973303795
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21044",
      "summary": "Evaluations of large language models (LLMs) primarily emphasize convergent logical reasoning, where success is defined by producing a single correct proof. However, many real-world reasoning problems admit multiple valid derivations, requiring models to explore diverse logical paths rather than committing to one route. To address this limitation, we introduce LogicGraph, the first benchmark aimed to systematically evaluate multi-path logical reasoning, constructed via a neuro-symbolic framework ",
      "summary_zh": "對 large language models (LLMs) 的評估主要強調 convergent logical reasoning，其中成功定義為產生單一正確的證明。然而，許多現實世界的推理問題允許存在多個有效的 derivations，要求模型探索 diverse logical paths，而不是只遵循一條路線。為解決此限制，我們引入了 LogicGraph，這是第一個旨在系統性評估 multi-path logical reasoning 的基準，它透過一個 neuro-symbolic framework 構建而成。",
      "title": "LogicGraph : Benchmarking Multi-Path Logical Reasoning via Neuro-Symbolic Generation and Verification",
      "title_zh": "LogicGraph：透過 Neuro-Symbolic Generation 和 Verification 基準測試多路徑邏輯推理"
    },
    {
      "arxiv_id": "2602.20980",
      "authors": [
        "Yang Zhang",
        "Danyang Li",
        "Yuxuan Li",
        "Xin Zhang",
        "Tianyu Xie",
        "Mingming Cheng",
        "Xiang Li"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.266863+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "CrystaL: Spontaneous Emergence of Visual Latents in MLLMs",
          "url": "https://arxiv.org/abs/2602.20980"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "CrystaL: Spontaneous Emergence of Visual Latents in MLLMs",
        "url": "https://arxiv.org/abs/2602.20980"
      },
      "published_at": "2026-02-24T15:01:30+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9251528644782909,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.525152864478294
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20980",
      "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable performance by integrating powerful language backbones with large-scale visual encoders. Among these, latent Chain-of-Thought (CoT) methods enable implicit reasoning in continuous hidden states, facilitating seamless vision-language integration and faster inference. However, existing heuristically predefined supervision signals in latent CoT provide limited guidance for preserving critical visual information in intermediate latent",
      "summary_zh": "Multimodal Large Language Models (MLLMs) 透過將強大的 language backbones 與 large-scale visual encoders 整合，實現了卓越的性能。其中，latent Chain-of-Thought (CoT) 方法能夠在 continuous hidden states 中實現 implicit reasoning，促進 seamless vision-language integration 和更快的 inference。然而，latent CoT 中現有的啟發式預定義 supervision signals 為在 intermediate latent 中保留關鍵視覺信息提供的指導有限。",
      "title": "CrystaL: Spontaneous Emergence of Visual Latents in MLLMs",
      "title_zh": "CrystaL：MLLMs 中視覺潛在表示的自發湧現"
    },
    {
      "arxiv_id": "2602.20976",
      "authors": [
        "Xuan Luo",
        "Yubin Chen",
        "Zhiyu Hou",
        "Linpu Yu",
        "Geng Tu",
        "Jing Li",
        "Ruifeng Xu"
      ],
      "categories": [
        "cs.CL",
        "cs.CY"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.035480+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Evaluating Proactive Risk Awareness of Large Language Models",
          "url": "https://arxiv.org/abs/2602.20976"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Evaluating Proactive Risk Awareness of Large Language Models",
        "url": "https://arxiv.org/abs/2602.20976"
      },
      "published_at": "2026-02-24T15:00:00+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9250564994073424,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.525056499407345
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20976",
      "summary": "As large language models (LLMs) are increasingly embedded in everyday decision-making, their safety responsibilities extend beyond reacting to explicit harmful intent toward anticipating unintended but consequential risks. In this work, we introduce a proactive risk awareness evaluation framework that measures whether LLMs can anticipate potential harms and provide warnings before damage occurs. We construct the Butterfly dataset to instantiate this framework in the environmental and ecological ",
      "summary_zh": "隨著 Large Language Models (LLMs) 日益融入日常決策中，其安全責任不僅限於對明確有害意圖的反應，更延伸到預測意想不到但具有嚴重後果的風險。在這項工作中，我們引入了一個主動風險意識評估框架，用以衡量 LLMs 是否能夠預測潛在危害並在損害發生前提供警告。我們構建了 Butterfly dataset，將此框架應用於環境和生態",
      "title": "Evaluating Proactive Risk Awareness of Large Language Models",
      "title_zh": "評估大型語言模型的主動風險意識"
    },
    {
      "arxiv_id": "2602.20966",
      "authors": [
        "Paola Merlo",
        "Chunyang Jiang",
        "Giuseppe Samo",
        "Vivi Nastase"
      ],
      "categories": [
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.035862+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models",
          "url": "https://arxiv.org/abs/2602.20966"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models",
        "url": "https://arxiv.org/abs/2602.20966"
      },
      "published_at": "2026-02-24T14:45:08+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9241019570481694,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.524101957048174
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20966",
      "summary": "This article describes a novel language task, the Blackbird Language Matrices (BLM) task, inspired by intelligence tests, and illustrates the BLM datasets, their construction and benchmarking, and targeted experiments on chunking and systematicity. BLMs are multiple-choice problems, structured at multiple levels: within each sentence, across the input sequence, within each candidate answer. Because of their rich structure, these curated, but naturalistic datasets are key to answer some core ques",
      "summary_zh": "本文描述了一項受智力測驗啟發的新型語言任務，即 Blackbird Language Matrices (BLM) 任務，並闡述了 BLM datasets、其建構、基準測試，以及針對 chunking 和 systematicity 的目標實驗。BLMs 是多重選擇問題，其結構分為多個層次：在每個句子內、跨輸入序列、在每個候選答案內。由於其豐富的結構，這些經過策劃但自然化的 datasets 是回答一些核心問題的關鍵",
      "title": "Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models",
      "title_zh": "Blackbird Language Matrices：一個探討語言模型語言能力的框架"
    },
    {
      "arxiv_id": "2602.20904",
      "authors": [
        "Nathan Hu",
        "Jake Ward",
        "Thomas Icard",
        "Christopher Potts"
      ],
      "categories": [
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.402520+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Transcoder Adapters for Reasoning-Model Diffing",
          "url": "https://arxiv.org/abs/2602.20904"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Transcoder Adapters for Reasoning-Model Diffing",
        "url": "https://arxiv.org/abs/2602.20904"
      },
      "published_at": "2026-02-24T13:40:28+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9199613588760387,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.51996135887604
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20904",
      "summary": "While reasoning models are increasingly ubiquitous, the effects of reasoning training on a model's internal mechanisms remain poorly understood. In this work, we introduce transcoder adapters, a technique for learning an interpretable approximation of the difference in MLP computation before and after fine-tuning. We apply transcoder adapters to characterize the differences between Qwen2.5-Math-7B and its reasoning-distilled variant, DeepSeek-R1-Distill-Qwen-7B. Learned adapters are faithful to ",
      "summary_zh": "儘管推理模型日益普及，推理訓練對模型內部機制造成的影響仍知之甚少。在這項工作中，我們引入了 transcoder adapters，這是一種學習 MLP 計算在 fine-tuning 前後差異的可解釋近似值的技術。我們應用 transcoder adapters 來表徵 Qwen2.5-Math-7B 及其推理蒸餾變體 DeepSeek-R1-Distill-Qwen-7B 之間的差異。學到的 adapters 忠實於",
      "title": "Transcoder Adapters for Reasoning-Model Diffing",
      "title_zh": "用於推理模型差異分析的 Transcoder Adapters"
    },
    {
      "arxiv_id": "2602.20880",
      "authors": [
        "Yongli Xiang",
        "Ziming Hong",
        "Zhaoqing Wang",
        "Xiangyu Zhao",
        "Bo Han",
        "Tongliang Liu"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.028922+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "When Safety Collides: Resolving Multi-Category Harmful Conflicts in Text-to-Image Diffusion via Adaptive Safety Guidance",
          "url": "https://arxiv.org/abs/2602.20880"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "When Safety Collides: Resolving Multi-Category Harmful Conflicts in Text-to-Image Diffusion via Adaptive Safety Guidance",
        "url": "https://arxiv.org/abs/2602.20880"
      },
      "published_at": "2026-02-24T13:20:31+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9186877115465991,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.5186877115466
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20880",
      "summary": "Text-to-Image (T2I) diffusion models have demonstrated significant advancements in generating high-quality images, while raising potential safety concerns regarding harmful content generation. Safety-guidance-based methods have been proposed to mitigate harmful outputs by steering generation away from harmful zones, where the zones are averaged across multiple harmful categories based on predefined keywords. However, these approaches fail to capture the complex interplay among different harm cat",
      "summary_zh": "Text-to-Image (T2I) diffusion models 在生成高品質圖像方面取得了顯著進展，但也引發了有關有害內容生成的潛在安全疑慮。基於 safety guidance 的方法被提出，旨在透過將生成引導遠離有害區域來減輕有害輸出，這些區域是根據預定義的關鍵字在多個有害類別中進行平均的。然而，這些方法未能捕捉不同危害類別之間複雜的相互作用",
      "title": "When Safety Collides: Resolving Multi-Category Harmful Conflicts in Text-to-Image Diffusion via Adaptive Safety Guidance",
      "title_zh": "當安全性衝突時：透過自適應安全引導解決 Text-to-Image Diffusion 中的多類有害衝突"
    },
    {
      "arxiv_id": "2602.20800",
      "authors": [
        "Dalia Nahhas",
        "Xiaohao Cai",
        "Imran Razzak",
        "Shoaib Jameel"
      ],
      "categories": [
        "cs.IR"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:37.770328+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ir",
          "tier": 1,
          "title": "Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking",
          "url": "https://arxiv.org/abs/2602.20800"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ir",
        "tier": 1,
        "title": "Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking",
        "url": "https://arxiv.org/abs/2602.20800"
      },
      "published_at": "2026-02-24T11:38:36+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9122086118460506,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.512208611846052
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20800",
      "summary": "In Generative Information Retrieval (GenIR), the bottleneck has shifted from generation to the selection of candidates, particularly for normative criteria such as cultural relevance. Current LLM-as-a-Judge evaluations often suffer from circularity and preference leakage, where overlapping supervision and evaluation models inflate performance. We address this by formalising cultural relevance as a within-query ranking task and introducing a leakage-free two-judge framework that strictly separate",
      "summary_zh": "在 Generative Information Retrieval (GenIR) 中，瓶頸已從生成轉向候選選擇，尤其是在文化相關性等規範性標準方面。目前的 LLM-as-a-Judge 評估常遭受循環性和 preference leakage 的困擾，其中重疊的監督和評估模型會誇大性能。我們透過將文化相關性形式化為一個 within-query 排名任務，並引入一個無洩漏的雙評審框架來解決這個問題，該框架嚴格分離",
      "title": "Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking",
      "title_zh": "透過嚴格估計器分離來緩解規範性生成排名中的偏好洩漏"
    },
    {
      "arxiv_id": "2602.20751",
      "authors": [
        "Yifei Xu",
        "Guilherme Potje",
        "Shivam Shandilya",
        "Tiancheng Yuan",
        "Leonardo de Oliveira Nunes",
        "Rakshanda Agarwal",
        "Saeid Asgari",
        "Adam Atkinson",
        "Emre Kıcıman",
        "Songwu Lu",
        "Ranveer Chandra",
        "Tusher Chakraborty"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.271920+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing",
          "url": "https://arxiv.org/abs/2602.20751"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing",
        "url": "https://arxiv.org/abs/2602.20751"
      },
      "published_at": "2026-02-24T10:28:44+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9077934303678882,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 30.50779343036789
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20751",
      "summary": "Designing aligned and robust rewards for open-ended generation remains a key barrier to RL post-training. Rubrics provide structured, interpretable supervision, but scaling rubric construction is difficult: expert rubrics are costly, prompted rubrics are often superficial or inconsistent, and fixed-pool discriminative rubrics can saturate and drift, enabling reward hacking. We present SibylSense, an inference-time learning approach that adapts a frozen rubric generator through a tunable memory b",
      "summary_zh": "為開放式生成設計對齊且穩健的獎勵，仍然是 RL 後訓練的一個關鍵障礙。評分標準（Rubrics）提供結構化、可解釋的監督，但擴展評分標準的建構卻很困難：專家評分標準成本高昂，提示生成的評分標準往往膚淺或不一致，而固定池的判別性評分標準可能會飽和和漂移，從而導致獎勵駭客攻擊。我們提出了 SibylSense，這是一種推論時學習方法，它透過可調的 memory b 來適應凍結的評分標準生成器。",
      "title": "SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing",
      "title_zh": "SibylSense: 透過記憶體微調和對抗性探測實現自適應評分標準學習"
    },
    {
      "arxiv_id": "2602.21020",
      "authors": [
        "Antoine Bergerault",
        "Volkan Cevher",
        "Negar Mehr"
      ],
      "categories": [
        "cs.LG",
        "cs.GT",
        "cs.MA"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.400355+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning",
          "url": "https://arxiv.org/abs/2602.21020"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning",
        "url": "https://arxiv.org/abs/2602.21020"
      },
      "published_at": "2026-02-24T15:38:11+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.8,
        "llm_relevance_score": 22.400000000000002,
        "recency_score": 0.9275126530192697,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 3.75,
        "total_score": 30.277512653019272
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21020",
      "summary": "Multi-agent imitation learning (MA-IL) aims to learn optimal policies from expert demonstrations of interactions in multi-agent interactive domains. Despite existing guarantees on the performance of the resulting learned policies, characterizations of how far the learned polices are from a Nash equilibrium are missing for offline MA-IL. In this paper, we demonstrate impossibility and hardness results of learning low-exploitable policies in general $n$-player Markov Games. We do so by providing e",
      "summary_zh": "Multi-agent imitation learning (MA-IL) 旨在從多智能體互動領域中的專家示範中學習最佳策略。儘管現有的保證了學習策略的性能，但對於 offline MA-IL 而言，關於學習策略與 Nash equilibrium 之間距離的特性描述卻是缺失的。在本文中，我們展示了在一般 $n$-player Markov Games 中學習低可利用性策略的不可能性和困難性結果。我們透過提供...",
      "title": "Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning",
      "title_zh": "匹配多個專家：關於多智能體模仿學習的可利用性"
    },
    {
      "arxiv_id": "2602.21054",
      "authors": [
        "Seongheon Park",
        "Changdae Oh",
        "Hyeong Kyu Choi",
        "Xuefeng Du",
        "Sharon Li"
      ],
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.265457+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "VAUQ: Vision-Aware Uncertainty Quantification for LVLM Self-Evaluation",
          "url": "https://arxiv.org/abs/2602.21054"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "VAUQ: Vision-Aware Uncertainty Quantification for LVLM Self-Evaluation",
        "url": "https://arxiv.org/abs/2602.21054"
      },
      "published_at": "2026-02-24T16:11:14+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.78,
        "llm_relevance_score": 21.84,
        "recency_score": 0.9296438681609834,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.969643868160983
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21054",
      "summary": "Large Vision-Language Models (LVLMs) frequently hallucinate, limiting their safe deployment in real-world applications. Existing LLM self-evaluation methods rely on a model's ability to estimate the correctness of its own outputs, which can improve deployment reliability; however, they depend heavily on language priors and are therefore ill-suited for evaluating vision-conditioned predictions. We propose VAUQ, a vision-aware uncertainty quantification framework for LVLM self-evaluation that expl",
      "summary_zh": "Large Vision-Language Models (LVLMs) 經常產生幻覺，限制了它們在現實世界應用中的安全部署。現有的 LLM 自我評估方法依賴模型評估其自身輸出正確性的能力，這可以提高部署可靠性；然而，它們嚴重依賴 language priors，因此不適合評估 vision-conditioned predictions。我們提出了 VAUQ，一個用於 LVLM 自我評估的 vision-aware uncertainty quantification 框架，它利用了...",
      "title": "VAUQ: Vision-Aware Uncertainty Quantification for LVLM Self-Evaluation",
      "title_zh": "VAUQ: 視覺感知不確定性量化用於 LVLM 自我評估"
    },
    {
      "arxiv_id": "2602.21013",
      "authors": [
        "Sanjay Haresh",
        "Daniel Dijkman",
        "Apratim Bhattacharyya",
        "Roland Memisevic"
      ],
      "categories": [
        "cs.RO"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:35.630866+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ro",
          "tier": 1,
          "title": "Notes-to-Self: Scratchpad Augmented VLAs for Memory Dependent Manipulation Tasks",
          "url": "https://arxiv.org/abs/2602.21013"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ro",
        "tier": 1,
        "title": "Notes-to-Self: Scratchpad Augmented VLAs for Memory Dependent Manipulation Tasks",
        "url": "https://arxiv.org/abs/2602.21013"
      },
      "published_at": "2026-02-24T15:30:55+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.78,
        "llm_relevance_score": 21.84,
        "recency_score": 0.9270447207288789,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.96704472072888
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21013",
      "summary": "Many dexterous manipulation tasks are non-markovian in nature, yet little attention has been paid to this fact in the recent upsurge of the vision-language-action (VLA) paradigm. Although they are successful in bringing internet-scale semantic understanding to robotics, existing VLAs are primarily \"stateless\" and struggle with memory-dependent long horizon tasks. In this work, we explore a way to impart both spatial and temporal memory to a VLA by incorporating a language scratchpad. The scratch",
      "summary_zh": "許多靈巧操作任務本質上是非馬可夫（non-markovian）的，然而在最近 vision-language-action (VLA) 範式的興起中，這一事實卻鮮受關注。儘管它們成功地將互聯網規模的語義理解引入機器人學，但現有的 VLA 主要都是「無狀態」（\"stateless\"）的，並且在記憶依賴的長時程任務上表現不佳。在這項工作中，我們探索了一種透過整合 language scratchpad 來賦予 VLA 空間和時間記憶的方法。這個 scratchpad...",
      "title": "Notes-to-Self: Scratchpad Augmented VLAs for Memory Dependent Manipulation Tasks",
      "title_zh": "Notes-to-Self: 帶有暫存器增強的 VLA 用於記憶依賴型操作任務"
    },
    {
      "arxiv_id": "2602.20973",
      "authors": [
        "Yuliang Ji",
        "Fuchen Shen",
        "Jian Wu",
        "Qiujie Xie",
        "Yue Zhang"
      ],
      "categories": [
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.035664+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving",
          "url": "https://arxiv.org/abs/2602.20973"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving",
        "url": "https://arxiv.org/abs/2602.20973"
      },
      "published_at": "2026-02-24T14:53:34+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.78,
        "llm_relevance_score": 21.84,
        "recency_score": 0.9246433141549352,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.964643314154934
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20973",
      "summary": "To comprehensively evaluate the mathematical reasoning capabilities of Large Language Models (LLMs), researchers have introduced abundant mathematical reasoning datasets. However, most existing datasets primarily focus on linear reasoning, neglecting other parts such as proof by contradiction and proof by cases, which are crucial for investigating LLMs' reasoning abilities. To address this limitation, we first introduce a novel first-order logic (FOL) dataset named PC-FOL, annotated by professio",
      "summary_zh": "為了全面評估 Large Language Models (LLMs) 的數學推理能力，研究人員引入了豐富的數學推理資料集。然而，大多數現有資料集主要關注線性推理（linear reasoning），忽略了諸如反證法（proof by contradiction）和分情況證明（proof by cases）等其他部分，這些對於探究 LLMs 的推理能力至關重要。為了解決這個限制，我們首先引入了一個新的 first-order logic (FOL) 資料集，名為 PC-FOL，由專業人員進行註釋...",
      "title": "Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving",
      "title_zh": "線性推理與分情況證明：大型語言模型在 FOL 問題解決中的障礙"
    },
    {
      "arxiv_id": "2602.20913",
      "authors": [
        "Jihao Qiu",
        "Lingxi Xie",
        "Xinyue Huo",
        "Qi Tian",
        "Qixiang Ye"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.028144+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding",
          "url": "https://arxiv.org/abs/2602.20913"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding",
        "url": "https://arxiv.org/abs/2602.20913"
      },
      "published_at": "2026-02-24T13:49:47+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.78,
        "llm_relevance_score": 21.84,
        "recency_score": 0.9205567579451438,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.96055675794514
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20913",
      "summary": "This paper addresses the critical and underexplored challenge of long video understanding with low computational budgets. We propose LongVideo-R1, an active, reasoning-equipped multimodal large language model (MLLM) agent designed for efficient video context navigation, avoiding the redundancy of exhaustive search. At the core of LongVideo-R1 lies a reasoning module that leverages high-level visual cues to infer the most informative video clip for subsequent processing. During inference, the age",
      "summary_zh": "本文探討了在計算預算有限的情況下，長影片理解這一關鍵且未充分探索的挑戰。我們提出了 LongVideo-R1，這是一個主動的、具備推理能力的 multimodal large language model (MLLM) agent，旨在實現高效的影片內容導航，避免了窮舉搜索的冗餘。LongVideo-R1 的核心是一個推理模組，它利用高階視覺線索來推斷出最具資訊量的影片片段，以便進行後續處理。在推論過程中，該 agent...",
      "title": "LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding",
      "title_zh": "LongVideo-R1：低成本長影片理解的智能導航"
    },
    {
      "arxiv_id": "2602.20799",
      "authors": [
        "Guangsheng Ou",
        "Qiming Zhang",
        "Sirong Chen",
        "Anji Li",
        "Dong Xu",
        "Tiancheng Luo",
        "Dekun Dai",
        "Cuiyun Gao",
        "Long Wang",
        "Jun Zhou",
        "Mingwei Liu",
        "Zibin Zheng"
      ],
      "categories": [
        "cs.SE"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:36.798264+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-se",
          "tier": 1,
          "title": "Unseen-Codebases-Domain Data Synthesis and Training Based on Code Graphs",
          "url": "https://arxiv.org/abs/2602.20799"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-se",
        "tier": 1,
        "title": "Unseen-Codebases-Domain Data Synthesis and Training Based on Code Graphs",
        "url": "https://arxiv.org/abs/2602.20799"
      },
      "published_at": "2026-02-24T11:36:34+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.78,
        "llm_relevance_score": 21.84,
        "recency_score": 0.9120798137051087,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.952079813705108
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20799",
      "summary": "In the context of newly release software frameworks, large language models (LLMs) often exhibit poor performance and a high rate of hallucination, as they are not exposed to such environments during training. Although inference-time augmentation techniques such as retrieval-augmented generation (RAG) can partially mitigate hallucinations, knowledge injection through prompting alone is insufficient to enable models to fully understand the intrinsic relationships among different components of a co",
      "summary_zh": "在發佈新的軟體框架的背景下，large language models (LLMs) 由於在訓練期間未接觸過此類環境，因此通常表現不佳且幻覺率高。儘管 retrieval-augmented generation (RAG) 等推論時增強技術可以部分緩解幻覺，但僅通過 prompting 進行知識注入不足以使模型完全理解程式碼不同組件之間的內在關係。",
      "title": "Unseen-Codebases-Domain Data Synthesis and Training Based on Code Graphs",
      "title_zh": "基於程式碼圖的未見程式碼庫領域數據合成與訓練"
    },
    {
      "arxiv_id": "2602.20794",
      "authors": [
        "Jie Wang",
        "Guang Li",
        "Zhijian Huang",
        "Chenxu Dang",
        "Hangjun Ye",
        "Yahong Han",
        "Long Chen"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.030826+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving",
          "url": "https://arxiv.org/abs/2602.20794"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving",
        "url": "https://arxiv.org/abs/2602.20794"
      },
      "published_at": "2026-02-24T11:33:44+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.78,
        "llm_relevance_score": 21.84,
        "recency_score": 0.9119003712106438,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.951900371210645
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20794",
      "summary": "The significance of cross-view 3D geometric modeling capabilities for autonomous driving is self-evident, yet existing Vision-Language Models (VLMs) inherently lack this capability, resulting in their mediocre performance. While some promising approaches attempt to mitigate this by constructing Q&A data for auxiliary training, they still fail to fundamentally equip VLMs with the ability to comprehensively handle diverse evaluation protocols. We thus chart a new course, advocating for the infusio",
      "summary_zh": "跨視角 3D 幾何建模能力對於自動駕駛的重要性不言而喻，然而現有的 Vision-Language Models (VLMs) 本質上缺乏這種能力，導致其性能平庸。儘管一些有前景的方法試圖通過構建 Q&A 數據進行輔助訓練來緩解此問題，但它們仍然未能從根本上賦予 VLMs 處理多樣化評估協議的全面能力。因此，我們開闢了一條新路徑，提倡將...",
      "title": "VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving",
      "title_zh": "VGGDrive：賦予 Vision-Language Models 跨視角幾何基礎能力以實現自動駕駛"
    },
    {
      "arxiv_id": "2602.21186",
      "authors": [
        "Haoyi Jiang",
        "Liu Liu",
        "Xinjie Wang",
        "Yonghao He",
        "Wei Sui",
        "Zhizhong Su",
        "Wenyu Liu",
        "Xinggang Wang"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.020866+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "Spa3R: Predictive Spatial Field Modeling for 3D Visual Reasoning",
          "url": "https://arxiv.org/abs/2602.21186"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "Spa3R: Predictive Spatial Field Modeling for 3D Visual Reasoning",
        "url": "https://arxiv.org/abs/2602.21186"
      },
      "published_at": "2026-02-24T18:37:34+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.939139107354742,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.139139107354744
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21186",
      "summary": "While Vision-Language Models (VLMs) exhibit exceptional 2D visual understanding, their ability to comprehend and reason about 3D space--a cornerstone of spatial intelligence--remains superficial. Current methodologies attempt to bridge this domain gap either by relying on explicit 3D modalities or by augmenting VLMs with partial, view-conditioned geometric priors. However, such approaches hinder scalability and ultimately burden the language model with the ill-posed task of implicitly reconstruc",
      "summary_zh": "儘管 Vision-Language Models (VLMs) 在 2D 視覺理解方面表現出色，但其理解和推理 3D 空間（空間智能的基石）的能力仍然膚淺。當前的方法試圖通過依賴顯式 3D 模態或用部分、視角條件的幾何先驗來增強 VLMs 來彌補這一領域差距。然而，這些方法阻礙了可擴展性，並最終使語言模型承擔了隱式重建的病態任務。",
      "title": "Spa3R: Predictive Spatial Field Modeling for 3D Visual Reasoning",
      "title_zh": "Spa3R：用於 3D 視覺推理的預測性空間場建模"
    },
    {
      "arxiv_id": "2602.21175",
      "authors": [
        "Jianglin Lu",
        "Simon Jenni",
        "Kushal Kafle",
        "Jing Shi",
        "Handong Zhao",
        "Yun Fu"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.021511+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "Seeing Through Words: Controlling Visual Retrieval Quality with Language Models",
          "url": "https://arxiv.org/abs/2602.21175"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "Seeing Through Words: Controlling Visual Retrieval Quality with Language Models",
        "url": "https://arxiv.org/abs/2602.21175"
      },
      "published_at": "2026-02-24T18:20:57+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9380560267175926,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.138056026717592
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21175",
      "summary": "Text-to-image retrieval is a fundamental task in vision-language learning, yet in real-world scenarios it is often challenged by short and underspecified user queries. Such queries are typically only one or two words long, rendering them semantically ambiguous, prone to collisions across diverse visual interpretations, and lacking explicit control over the quality of retrieved images. To address these issues, we propose a new paradigm of quality-controllable retrieval, which enriches short queri",
      "summary_zh": "文字到圖片檢索是視覺-語言學習中的一項基本任務，然而在現實世界情境中，它常常受到簡短且不夠明確的使用者查詢的挑戰。此類查詢通常只有一兩個單字長，這使得它們在語義上模稜兩可，容易在多樣化的視覺解釋中產生衝突，並且缺乏對檢索圖片品質的明確控制。為了解決這些問題，我們提出了一種新的品質可控檢索範式，它豐富了簡短的查詢...",
      "title": "Seeing Through Words: Controlling Visual Retrieval Quality with Language Models",
      "title_zh": "透過文字看見：使用語言模型控制視覺檢索品質"
    },
    {
      "arxiv_id": "2602.21161",
      "authors": [
        "Guangming Wang",
        "Qizhen Ying",
        "Yixiong Jing",
        "Olaf Wysocki",
        "Brian Sheil"
      ],
      "categories": [
        "cs.RO"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:35.629475+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ro",
          "tier": 1,
          "title": "ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking",
          "url": "https://arxiv.org/abs/2602.21161"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ro",
        "tier": 1,
        "title": "ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking",
        "url": "https://arxiv.org/abs/2602.21161"
      },
      "published_at": "2026-02-24T18:07:06+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9371542329643128,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.137154232964313
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21161",
      "summary": "Classical robotic systems typically rely on custom planners designed for constrained environments. While effective in restricted settings, these systems lack generalization capabilities, limiting the scalability of embodied AI and general-purpose robots. Recent data-driven Vision-Language-Action (VLA) approaches aim to learn policies from large-scale simulation and real-world data. However, the continuous action space of the physical world significantly exceeds the representational capacity of l",
      "summary_zh": "傳統機器人系統通常依賴為受限環境設計的客製化規劃器。儘管在受限環境中有效，這些系統缺乏泛化能力，限制了 embodied AI 和通用機器人的可擴展性。最近的資料驅動 Vision-Language-Action (VLA) 方法旨在從大規模模擬和真實世界資料中學習策略。然而，物理世界的連續動作空間顯著超出了其表徵能力。",
      "title": "ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking",
      "title_zh": "ActionReasoning: 利用 LLM 實現 3D 空間中機器人動作推理以進行機器人積木堆疊"
    },
    {
      "arxiv_id": "2602.21059",
      "authors": [
        "Anna Martin-Boyle",
        "William Humphreys",
        "Martha Brown",
        "Cara Leckey",
        "Harmanpreet Kaur"
      ],
      "categories": [
        "cs.HC",
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.034258+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "An Expert Schema for Evaluating Large Language Model Errors in Scholarly Question-Answering Systems",
          "url": "https://arxiv.org/abs/2602.21059"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "An Expert Schema for Evaluating Large Language Model Errors in Scholarly Question-Answering Systems",
        "url": "https://arxiv.org/abs/2602.21059"
      },
      "published_at": "2026-02-24T16:16:44+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9299990082893216,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.12999900828932
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21059",
      "summary": "Large Language Models (LLMs) are transforming scholarly tasks like search and summarization, but their reliability remains uncertain. Current evaluation metrics for testing LLM reliability are primarily automated approaches that prioritize efficiency and scalability, but lack contextual nuance and fail to reflect how scientific domain experts assess LLM outputs in practice. We developed and validated a schema for evaluating LLM errors in scholarly question-answering systems that reflects the ass",
      "summary_zh": "大型語言模型 (LLMs) 正在改變搜尋和摘要等學術任務，但其可靠性仍不確定。目前用於測試 LLM 可靠性的評估指標主要是自動化方法，這些方法優先考慮效率和可擴展性，但缺乏情境細微性，並且未能反映科學領域專家在實踐中如何評估 LLM 輸出。我們開發並驗證了一種評估學術問答系統中 LLM 錯誤的模式，該模式反映了...",
      "title": "An Expert Schema for Evaluating Large Language Model Errors in Scholarly Question-Answering Systems",
      "title_zh": "一種用於評估學術問答系統中大型語言模型錯誤的專家模式"
    },
    {
      "arxiv_id": "2602.21052",
      "authors": [
        "Timur Nabiev",
        "Evgeny Frolov"
      ],
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.265728+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Position-Aware Sequential Attention for Accurate Next Item Recommendations",
          "url": "https://arxiv.org/abs/2602.21052"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Position-Aware Sequential Attention for Accurate Next Item Recommendations",
        "url": "https://arxiv.org/abs/2602.21052"
      },
      "published_at": "2026-02-24T16:09:47+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9295502629009917,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.12955026290099
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21052",
      "summary": "Sequential self-attention models usually rely on additive positional embeddings, which inject positional information into item representations at the input. In the absence of positional signals, the attention block is permutation-equivariant over sequence positions and thus has no intrinsic notion of temporal order beyond causal masking. We argue that additive positional embeddings make the attention mechanism only superficially sensitive to sequence order: positional information is entangled wi",
      "summary_zh": "序列自注意力模型通常依賴於加性 positional embeddings，其在輸入時將位置資訊注入到項目表徵中。在缺乏位置訊號的情況下，注意力區塊對於序列位置是排列等變的，因此除了 causal masking 之外，沒有內在的時間順序概念。我們認為加性 positional embeddings 使得注意力機制僅在表面上對序列順序敏感：位置資訊與...",
      "title": "Position-Aware Sequential Attention for Accurate Next Item Recommendations",
      "title_zh": "用於準確下一項推薦的位置感知序列注意力"
    },
    {
      "arxiv_id": "2602.20951",
      "authors": [
        "Jaehyun Park",
        "Minyoung Ahn",
        "Minkyu Kim",
        "Jonghyun Lee",
        "Jae-Gil Lee",
        "Dongmin Park"
      ],
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.268027+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis",
          "url": "https://arxiv.org/abs/2602.20951"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis",
        "url": "https://arxiv.org/abs/2602.20951"
      },
      "published_at": "2026-02-24T14:34:13+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9234016591253469,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.12340165912535
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20951",
      "summary": "Despite recent advances in diffusion models, AI generated images still often contain visual artifacts that compromise realism. Although more thorough pre-training and bigger models might reduce artifacts, there is no assurance that they can be completely eliminated, which makes artifact mitigation a highly crucial area of study. Previous artifact-aware methodologies depend on human-labeled artifact datasets, which are costly and difficult to scale, underscoring the need for an automated approach",
      "summary_zh": "儘管 Diffusion Models 近來取得了進展，AI 生成的圖像仍常包含損害真實感的視覺偽影。雖然更徹底的 pre-training 和更大的模型可能會減少偽影，但無法保證它們能被完全消除，這使得偽影緩解成為一個至關重要的研究領域。先前的偽影感知方法依賴於人工標記的偽影資料集，這些資料集成本高昂且難以擴展，突顯了自動化方法的需求。",
      "title": "See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis",
      "title_zh": "發現並修正缺陷：透過 Agentic Data Synthesis 使 VLM 和 Diffusion Models 能夠理解視覺偽影"
    },
    {
      "arxiv_id": "2602.20934",
      "authors": [
        "ChengYou Li",
        "XiaoDong Liu",
        "XiangBao Meng",
        "XinYu Zhao"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.268764+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence",
          "url": "https://arxiv.org/abs/2602.20934"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence",
        "url": "https://arxiv.org/abs/2602.20934"
      },
      "published_at": "2026-02-24T14:12:21+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9220005207024956,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.122000520702496
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20934",
      "summary": "The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between micro scale token processing and macro scale systemic intelligence remains fragmented.This paper proposes AgentOS,a holistic conceptual framework that redefines the LLM as a \"Reasoning Kernel\" governed by structured opera",
      "summary_zh": "大型語言模型的範式正在經歷從靜態推理引擎到動態自主認知系統的根本性轉變。儘管目前的研究主要關注擴展 context windows 或優化 prompt engineering，但微觀 token 處理和宏觀系統智慧之間的理論橋樑仍然支離破碎。本文提出了 AgentOS，一個整體概念框架，它將 LLM 重新定義為一個由結構化操作管轄的「Reasoning Kernel」。",
      "title": "Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence",
      "title_zh": "架構 AgentOS：從 Token 層級上下文到湧現的系統層級智慧"
    },
    {
      "arxiv_id": "2602.20926",
      "authors": [
        "Yuqi Huang",
        "Ning Liao",
        "Kai Yang",
        "Anning Hu",
        "Shengchao Hu",
        "Xiaoxing Wang",
        "Junchi Yan"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.268981+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG",
          "url": "https://arxiv.org/abs/2602.20926"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG",
        "url": "https://arxiv.org/abs/2602.20926"
      },
      "published_at": "2026-02-24T14:05:29+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9215609678559137,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.121560967855913
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20926",
      "summary": "Large Language Models (LLMs) often struggle with inherent knowledge boundaries and hallucinations, limiting their reliability in knowledge-intensive tasks. While Retrieval-Augmented Generation (RAG) mitigates these issues, it frequently overlooks structural interdependencies essential for multi-hop reasoning. Graph-based RAG approaches attempt to bridge this gap, yet they typically face trade-offs between accuracy and efficiency due to challenges such as costly graph traversals and semantic nois",
      "summary_zh": "大型語言模型 (LLMs) 經常在知識密集型任務中面臨固有的知識邊界和幻覺問題，這限制了它們的可靠性。雖然 Retrieval-Augmented Generation (RAG) 能夠緩解這些問題，但它經常忽略對於 multi-hop reasoning 至關重要的結構性相互依賴。基於圖的 RAG 方法試圖彌補這一鴻溝，然而它們通常在準確性和效率之間面臨權衡，原因包括昂貴的 graph traversals 和語義噪聲（semantic noise）。",
      "title": "HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG",
      "title_zh": "HELP：用於準確高效 GraphRAG 的 HyperNode 擴展與邏輯路徑引導證據定位"
    },
    {
      "arxiv_id": "2602.20901",
      "authors": [
        "Yuechen Xie",
        "Xiaoyan Zhang",
        "Yicheng Shan",
        "Hao Zhu",
        "Rui Tang",
        "Rong Wei",
        "Mingli Song",
        "Yuanyu Wan",
        "Jie Song"
      ],
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.402771+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "SpatiaLQA: A Benchmark for Evaluating Spatial Logical Reasoning in Vision-Language Models",
          "url": "https://arxiv.org/abs/2602.20901"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "SpatiaLQA: A Benchmark for Evaluating Spatial Logical Reasoning in Vision-Language Models",
        "url": "https://arxiv.org/abs/2602.20901"
      },
      "published_at": "2026-02-24T13:38:37+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9198431769876129,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.119843176987615
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20901",
      "summary": "Vision-Language Models (VLMs) have been increasingly applied in real-world scenarios due to their outstanding understanding and reasoning capabilities. Although VLMs have already demonstrated impressive capabilities in common visual question answering and logical reasoning, they still lack the ability to make reasonable decisions in complex real-world environments. We define this ability as spatial logical reasoning, which not only requires understanding the spatial relationships among objects i",
      "summary_zh": "Vision-Language Models (VLMs) 因其出色的理解和推理能力，已越來越多地應用於現實世界場景。儘管 VLMs 已在常見的視覺問答和邏輯推理方面展現出令人印象深刻的能力，但它們仍然缺乏在複雜現實世界環境中做出合理決策的能力。我們將這種能力定義為 spatial logical reasoning，它不僅需要理解物體之間的空間關係（spatial relationships among objects）。",
      "title": "SpatiaLQA: A Benchmark for Evaluating Spatial Logical Reasoning in Vision-Language Models",
      "title_zh": "SpatiaLQA：一個用於評估 Vision-Language Models 中空間邏輯推理的基準"
    },
    {
      "arxiv_id": "2602.20810",
      "authors": [
        "Yaacov Pariente",
        "Vadim Indelman"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.270889+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "POMDPPlanners: Open-Source Package for POMDP Planning",
          "url": "https://arxiv.org/abs/2602.20810"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "POMDPPlanners: Open-Source Package for POMDP Planning",
        "url": "https://arxiv.org/abs/2602.20810"
      },
      "published_at": "2026-02-24T11:50:04+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9129352894720661,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.112935289472066
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20810",
      "summary": "We present POMDPPlanners, an open-source Python package for empirical evaluation of Partially Observable Markov Decision Process (POMDP) planning algorithms. The package integrates state-of-the-art planning algorithms, a suite of benchmark environments with safety-critical variants, automated hyperparameter optimization via Optuna, persistent caching with failure recovery, and configurable parallel simulation -- reducing the overhead of extensive simulation studies. POMDPPlanners is designed to ",
      "summary_zh": "我們介紹 POMDPPlanners，一個用於對 Partially Observable Markov Decision Process (POMDP) 規劃演算法進行實證評估的開源 Python 套件。該套件整合了最先進的規劃演算法、一套包含安全關鍵變體的基準環境、透過 Optuna 實現的自動 hyperparameter optimization、帶有故障恢復功能的持久性快取，以及可配置的並行模擬——從而減少了廣泛模擬研究的開銷。POMDPPlanners 旨在為研究人員和開發者提供一個全面且易於使用的平台。",
      "title": "POMDPPlanners: Open-Source Package for POMDP Planning",
      "title_zh": "POMDPPlanners：用於 POMDP 規劃的開源套件"
    },
    {
      "arxiv_id": "2602.20770",
      "authors": [
        "Varvara Sazonova",
        "Dmitri Shmelkin",
        "Stanislav Kikot",
        "Vasily Motolygin"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.271452+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Pipeline for Verifying LLM-Generated Mathematical Solutions",
          "url": "https://arxiv.org/abs/2602.20770"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Pipeline for Verifying LLM-Generated Mathematical Solutions",
        "url": "https://arxiv.org/abs/2602.20770"
      },
      "published_at": "2026-02-24T11:01:25+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9098561672491249,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.109856167249127
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20770",
      "summary": "With the growing popularity of Large Reasoning Models and their results in solving mathematical problems, it becomes crucial to measure their capabilities. We introduce a pipeline for both automatic and interactive verification as a more accurate alternative to only checking the answer which is currently the most popular approach for benchmarks. The pipeline can also be used as a generator of correct solutions both in formal and informal languages. 3 AI agents, which can be chosen for the benchm",
      "summary_zh": "隨著 Large Reasoning Models 及其在解決數學問題方面的成果日益普及，衡量其能力變得至關重要。我們引入了一個用於自動和互動式驗證的流程，作為目前基準測試中最流行方法（僅檢查答案）的一個更準確的替代方案。該流程還可以用作生成正式和非正式語言正確解決方案的生成器。三個 AI agents（代理）可以選擇用於基準測試。",
      "title": "Pipeline for Verifying LLM-Generated Mathematical Solutions",
      "title_zh": "驗證 LLM 生成數學解的流程"
    },
    {
      "arxiv_id": "2602.20735",
      "authors": [
        "Kun Ran",
        "Marwah Alaofi",
        "Danula Hettiachchi",
        "Chenglong Ma",
        "Khoi Nguyen Dinh Anh",
        "Khoi Vo Nguyen",
        "Sachin Pathiyan Cherumanal",
        "Lida Rashidi",
        "Falk Scholer",
        "Damiano Spina",
        "Shuoqi Sun",
        "Oleg Zendel"
      ],
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.272625+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition",
          "url": "https://arxiv.org/abs/2602.20735"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition",
        "url": "https://arxiv.org/abs/2602.20735"
      },
      "published_at": "2026-02-24T09:58:25+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9058842414405427,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.105884241440542
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20735",
      "summary": "This paper presents the award-winning RMIT-ADM+S system for the Text-to-Text\n  track of the NeurIPS~2025 MMU-RAG Competition. We introduce Routing-to-RAG\n  (R2RAG), a research-focused retrieval-augmented generation (RAG)\n  architecture composed of lightweight components that dynamically adapt the\n  retrieval strategy based on inferred query complexity and evidence\n  sufficiency. The system uses smaller LLMs, enabling operation on a single\n  consumer-grade GPU while supporting complex research ta",
      "summary_zh": "本文介紹了在 NeurIPS 2025 MMU-RAG 競賽的 Text-to-Text 賽道中獲獎的 RMIT-ADM+S 系統。我們引入了 Routing-to-RAG (R2RAG)，這是一個以研究為重點的 retrieval-augmented generation (RAG) 架構，由輕量級組件組成，這些組件根據推斷的查詢複雜性（query complexity）和證據充足性（evidence sufficiency）動態調整檢索策略。該系統使用較小的 LLMs，使其能夠在單一消費級 GPU 上運行，同時支持複雜的研究任務。",
      "title": "RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition",
      "title_zh": "RMIT-ADM+S 在 MMU-RAG NeurIPS 2025 競賽中的表現"
    },
    {
      "arxiv_id": "2602.20717",
      "authors": [
        "Xiting Liu",
        "Yuetong Liu",
        "Yitong Zhang",
        "Jia Li",
        "Shi-Min Hu"
      ],
      "categories": [
        "cs.SE",
        "cs.CR"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:36.798653+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-se",
          "tier": 1,
          "title": "PackMonitor: Enabling Zero Package Hallucinations Through Decoding-Time Monitoring",
          "url": "https://arxiv.org/abs/2602.20717"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-se",
        "tier": 1,
        "title": "PackMonitor: Enabling Zero Package Hallucinations Through Decoding-Time Monitoring",
        "url": "https://arxiv.org/abs/2602.20717"
      },
      "published_at": "2026-02-24T09:26:11+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9038587544656268,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 29.103858754465627
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20717",
      "summary": "As Large Language Models (LLMs) are increasingly integrated into software development workflows, their trustworthiness has become a critical concern. However, in dependency recommendation scenarios, the reliability of LLMs is undermined by widespread package hallucinations, where models often recommend hallucinated packages. Recent studies have proposed a range of approaches to mitigate this issue. Nevertheless, existing approaches typically merely reduce hallucination rates rather than eliminat",
      "summary_zh": "隨著 Large Language Models (LLMs) 越來越多地整合到軟體開發工作流程中，它們的可信度已成為一個關鍵問題。然而，在依賴項推薦場景中，LLMs 的可靠性受到普遍的 package hallucinations 影響，模型經常推薦 hallucinated packages。最近的研究提出了一系列方法來緩解這個問題。儘管如此，現有方法通常僅僅是降低 hallucination 率，而非消除",
      "title": "PackMonitor: Enabling Zero Package Hallucinations Through Decoding-Time Monitoring",
      "title_zh": "PackMonitor：透過解碼時監控實現零 Package Hallucinations"
    },
    {
      "arxiv_id": "2602.21133",
      "authors": [
        "Alessandro Londei",
        "Denise Lanzieri",
        "Matteo Benati"
      ],
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.397269+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "SOM-VQ: Topology-Aware Tokenization for Interactive Generative Models",
          "url": "https://arxiv.org/abs/2602.21133"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "SOM-VQ: Topology-Aware Tokenization for Interactive Generative Models",
        "url": "https://arxiv.org/abs/2602.21133"
      },
      "published_at": "2026-02-24T17:29:04+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9346822836311504,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 3.1500000000000004,
        "total_score": 28.28468228363115
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21133",
      "summary": "Vector-quantized representations enable powerful discrete generative models but lack semantic structure in token space, limiting interpretable human control. We introduce SOM-VQ, a tokenization method that combines vector quantization with Self-Organizing Maps to learn discrete codebooks with explicit low-dimensional topology. Unlike standard VQ-VAE, SOM-VQ uses topology-aware updates that preserve neighborhood structure: nearby tokens on a learned grid correspond to semantically similar states,",
      "summary_zh": "Vector-quantized representations 能夠實現強大的離散生成模型，但在 token 空間中缺乏語義結構，限制了可解釋的人類控制。我們引入了 SOM-VQ，這是一種將向量量化與 Self-Organizing Maps 相結合的 tokenization 方法，用於學習具有明確低維拓撲的離散 codebooks。與標準的 VQ-VAE 不同，SOM-VQ 使用 topology-aware 更新來保留鄰域結構：學習網格上相鄰的 token 對應於語義相似的狀態，",
      "title": "SOM-VQ: Topology-Aware Tokenization for Interactive Generative Models",
      "title_zh": "SOM-VQ：用於互動式生成模型的拓撲感知 Tokenization"
    },
    {
      "arxiv_id": "2602.21064",
      "authors": [
        "Mehdi Acheli",
        "Walid Gaaloul"
      ],
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.264936+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Motivation is Something You Need",
          "url": "https://arxiv.org/abs/2602.21064"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Motivation is Something You Need",
        "url": "https://arxiv.org/abs/2602.21064"
      },
      "published_at": "2026-02-24T16:26:52+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.7,
        "llm_relevance_score": 19.599999999999998,
        "recency_score": 0.9306536823571625,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 27.73065368235716
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21064",
      "summary": "This work introduces a novel training paradigm that draws from affective neuroscience. Inspired by the interplay of emotions and cognition in the human brain and more specifically the SEEKING motivational state, we design a dual-model framework where a smaller base model is trained continuously, while a larger motivated model is activated intermittently during predefined \"motivation conditions\". The framework mimics the emotional state of high curiosity and anticipation of reward in which broade",
      "summary_zh": "這項工作引入了一種從情感神經科學中汲取靈感的新穎訓練範式。受人腦中情感與認知相互作用的啟發，特別是 SEEKING 動機狀態，我們設計了一個雙模型框架：一個較小的基礎模型持續訓練，而一個較大的 motivated 模型在預定義的「motivation conditions」下間歇性激活。該框架模仿了高度好奇和對獎勵預期的情緒狀態，其中更廣泛的",
      "title": "Motivation is Something You Need",
      "title_zh": "動機是您所需"
    },
    {
      "arxiv_id": "2602.21045",
      "authors": [
        "Anna Martin-Boyle",
        "Cara A. C. Leckey",
        "Martha C. Brown",
        "Harmanpreet Kaur"
      ],
      "categories": [
        "cs.HC",
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.034683+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "PaperTrail: A Claim-Evidence Interface for Grounding Provenance in LLM-based Scholarly Q&A",
          "url": "https://arxiv.org/abs/2602.21045"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "PaperTrail: A Claim-Evidence Interface for Grounding Provenance in LLM-based Scholarly Q&A",
        "url": "https://arxiv.org/abs/2602.21045"
      },
      "published_at": "2026-02-24T16:04:50+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.7,
        "llm_relevance_score": 19.599999999999998,
        "recency_score": 0.9292307849115449,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 27.729230784911543
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21045",
      "summary": "Large language models (LLMs) are increasingly used in scholarly question-answering (QA) systems to help researchers synthesize vast amounts of literature. However, these systems often produce subtle errors (e.g., unsupported claims, errors of omission), and current provenance mechanisms like source citations are not granular enough for the rigorous verification that scholarly domain requires. To address this, we introduce PaperTrail, a novel interface that decomposes both LLM answers and source ",
      "summary_zh": "Large language models (LLMs) 越來越多地用於學術問答 (QA) 系統，以幫助研究人員綜合大量文獻。然而，這些系統經常產生細微錯誤（例如，未經支持的主張、遺漏錯誤），並且當前的 provenance 機制（如來源引用）對於學術領域所需的嚴格驗證來說不夠細粒度。為了解決這個問題，我們引入了 PaperTrail，這是一個新穎的介面，它分解了 LLM 答案和來源",
      "title": "PaperTrail: A Claim-Evidence Interface for Grounding Provenance in LLM-based Scholarly Q&A",
      "title_zh": "PaperTrail：一個用於在基於 LLM 的學術問答中建立 Provenance 的 Claim-Evidence 介面"
    },
    {
      "arxiv_id": "2602.20818",
      "authors": [
        "Yingying Guo",
        "Ke Zhang",
        "Zirong Zeng"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.030381+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "GatedCLIP: Gated Multimodal Fusion for Hateful Memes Detection",
          "url": "https://arxiv.org/abs/2602.20818"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "GatedCLIP: Gated Multimodal Fusion for Hateful Memes Detection",
        "url": "https://arxiv.org/abs/2602.20818"
      },
      "published_at": "2026-02-24T11:54:54+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.7,
        "llm_relevance_score": 19.599999999999998,
        "recency_score": 0.9132417659426091,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 27.713241765942605
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20818",
      "summary": "Detecting hateful content in multimodal memes presents unique challenges, as harmful messages often emerge from the complex interplay between benign images and text. We propose GatedCLIP, a Vision-Language model that enhances CLIP's multimodal capabilities with specialized architectural improvements for hateful memes detection. Our approach introduces learned projection heads that map CLIP embeddings to a task-optimized semantic space, a dynamic gated fusion mechanism that adaptively weights vis",
      "summary_zh": "檢測多模態 memes 中的惡意內容提出了獨特的挑戰，因為有害信息通常源於良性圖像和文本之間複雜的相互作用。我們提出了 GatedCLIP，這是一個 Vision-Language 模型，它透過專門的架構改進來增強 CLIP 的多模態能力，用於 hateful memes detection。我們的方法引入了學習到的 projection heads，將 CLIP embeddings 映射到任務優化的 semantic space，這是一種動態門控融合機制，可以自適應地加權視覺",
      "title": "GatedCLIP: Gated Multimodal Fusion for Hateful Memes Detection",
      "title_zh": "GatedCLIP：用於惡意 Memes 檢測的門控多模態融合"
    },
    {
      "arxiv_id": "2602.20809",
      "authors": [
        "Yun-Jui Tsai",
        "Wei-Yu Chen",
        "Yan-Ru Ju",
        "Yu-Hung Chang",
        "Ti-Rong Wu"
      ],
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.271151+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Regret-Guided Search Control for Efficient Learning in AlphaZero",
          "url": "https://arxiv.org/abs/2602.20809"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Regret-Guided Search Control for Efficient Learning in AlphaZero",
        "url": "https://arxiv.org/abs/2602.20809"
      },
      "published_at": "2026-02-24T11:49:59+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.7,
        "llm_relevance_score": 19.599999999999998,
        "recency_score": 0.9129300062970205,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 27.712930006297018
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20809",
      "summary": "Reinforcement learning (RL) agents achieve remarkable performance but remain far less learning-efficient than humans. While RL agents require extensive self-play games to extract useful signals, humans often need only a few games, improving rapidly by repeatedly revisiting states where mistakes occurred. This idea, known as search control, aims to restart from valuable states rather than always from the initial state. In AlphaZero, prior work Go-Exploit applies this idea by sampling past states ",
      "summary_zh": "儘管 Reinforcement learning (RL) agents 取得了卓越的表現，但其學習效率仍遠低於人類。RL agents 需要大量的 self-play 遊戲才能提取有用的訊號，而人類通常只需少量遊戲，透過重複回溯錯誤發生的狀態即可快速改進。這種被稱為 search control 的思想，旨在從有價值的狀態重新開始，而非總是從初始狀態開始。在 AlphaZero 中，先前的研究 Go-Exploit 透過採樣過去的狀態來應用此思想",
      "title": "Regret-Guided Search Control for Efficient Learning in AlphaZero",
      "title_zh": "基於後悔引導的搜尋控制，提升 AlphaZero 的高效學習"
    },
    {
      "arxiv_id": "2602.20924",
      "authors": [
        "Alagappan Ramanathan",
        "Eunju Kang",
        "Dongsu Han",
        "Sangeetha Abdu Jyothi"
      ],
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.SE"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.269217+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Airavat: An Agentic Framework for Internet Measurement",
          "url": "https://arxiv.org/abs/2602.20924"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Airavat: An Agentic Framework for Internet Measurement",
        "url": "https://arxiv.org/abs/2602.20924"
      },
      "published_at": "2026-02-24T14:04:18+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.7,
        "llm_relevance_score": 19.599999999999998,
        "recency_score": 0.9214852408415943,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 3.75,
        "total_score": 27.47148524084159
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20924",
      "summary": "Internet measurement faces twin challenges: complex analyses require expert-level orchestration of tools, yet even syntactically correct implementations can have methodological flaws and can be difficult to verify. Democratizing measurement capabilities thus demands automating both workflow generation and verification against methodological standards established through decades of research.\n  We present Airavat, the first agentic framework for Internet measurement workflow generation with system",
      "summary_zh": "網際網路測量面臨雙重挑戰：複雜的分析需要專家級別的工具協調，然而即使語法正確的實作也可能存在方法論上的缺陷，且難以驗證。因此，普及測量能力需要自動化工作流程生成，並根據數十年研究建立的方法論標準進行驗證。我們提出了 Airavat，這是第一個用於網際網路測量工作流程生成的 Agentic 框架，具有系統",
      "title": "Airavat: An Agentic Framework for Internet Measurement",
      "title_zh": "Airavat：一個用於網際網路測量的 Agentic 框架"
    },
    {
      "arxiv_id": "2602.20796",
      "authors": [
        "JinLi He",
        "Liang Bai",
        "Xian Yang"
      ],
      "categories": [
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.404435+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Exploring the Impact of Parameter Update Magnitude on Forgetting and Generalization of Continual Learning",
          "url": "https://arxiv.org/abs/2602.20796"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Exploring the Impact of Parameter Update Magnitude on Forgetting and Generalization of Continual Learning",
        "url": "https://arxiv.org/abs/2602.20796"
      },
      "published_at": "2026-02-24T11:35:15+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9119964213309957,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 2.25,
        "total_score": 27.361996421330996
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20796",
      "summary": "The magnitude of parameter updates are considered a key factor in continual learning. However, most existing studies focus on designing diverse update strategies, while a theoretical understanding of the underlying mechanisms remains limited. Therefore, we characterize model's forgetting from the perspective of parameter update magnitude and formalize it as knowledge degradation induced by task-specific drift in the parameter space, which has not been fully captured in previous studies due to th",
      "summary_zh": "參數更新的幅度被視為 continual learning 中的一個關鍵因素。然而，大多數現有研究側重於設計多樣化的更新策略，而對其潛在機制的理論理解仍然有限。因此，我們從參數更新幅度的角度來描述模型的遺忘現象，並將其形式化為由參數空間中任務特定漂移（task-specific drift）引起的知識退化，這在先前的研究中並未完全捕捉到，由於其",
      "title": "Exploring the Impact of Parameter Update Magnitude on Forgetting and Generalization of Continual Learning",
      "title_zh": "探索參數更新幅度對 Continual Learning 中遺忘與泛化能力的影響"
    },
    {
      "arxiv_id": "2602.20791",
      "authors": [
        "JinLi He",
        "Liang Bai",
        "Xian Yang"
      ],
      "categories": [
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.404660+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Understanding the Role of Rehearsal Scale in Continual Learning under Varying Model Capacities",
          "url": "https://arxiv.org/abs/2602.20791"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Understanding the Role of Rehearsal Scale in Continual Learning under Varying Model Capacities",
        "url": "https://arxiv.org/abs/2602.20791"
      },
      "published_at": "2026-02-24T11:29:12+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.75,
        "llm_relevance_score": 21.0,
        "recency_score": 0.9116133366478886,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 2.25,
        "total_score": 27.36161333664789
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20791",
      "summary": "Rehearsal is one of the key techniques for mitigating catastrophic forgetting and has been widely adopted in continual learning algorithms due to its simplicity and practicality. However, the theoretical understanding of how rehearsal scale influences learning dynamics remains limited. To address this gap, we formulate rehearsal-based continual learning as a multidimensional effectiveness-driven iterative optimization problem, providing a unified characterization across diverse performance metri",
      "summary_zh": "Rehearsal 是緩解 catastrophic forgetting 的關鍵技術之一，由於其簡潔性和實用性，已廣泛應用於 continual learning 演算法中。然而，關於 rehearsal 規模如何影響學習動態的理論理解仍然有限。為彌補這一空白，我們將基於 rehearsal 的 continual learning 形式化為一個多維度、效果驅動的迭代優化問題，為多樣的效能指標提供統一的描述",
      "title": "Understanding the Role of Rehearsal Scale in Continual Learning under Varying Model Capacities",
      "title_zh": "理解 Rehearsal 規模在不同模型容量下對 Continual Learning 的作用"
    },
    {
      "arxiv_id": "2602.20918",
      "authors": [
        "Hyewon Jang",
        "Nikolai Ilinykh",
        "Sharid Loáiciga",
        "Jey Han Lau",
        "Shalom Lappin"
      ],
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.269469+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Predicting Sentence Acceptability Judgments in Multimodal Contexts",
          "url": "https://arxiv.org/abs/2602.20918"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Predicting Sentence Acceptability Judgments in Multimodal Contexts",
        "url": "https://arxiv.org/abs/2602.20918"
      },
      "published_at": "2026-02-24T13:54:38+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.68,
        "llm_relevance_score": 19.040000000000003,
        "recency_score": 0.9208668587943369,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 27.16086685879434
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20918",
      "summary": "Previous work has examined the capacity of deep neural networks (DNNs), particularly transformers, to predict human sentence acceptability judgments, both independently of context, and in document contexts. We consider the effect of prior exposure to visual images (i.e., visual context) on these judgments for humans and large language models (LLMs). Our results suggest that, in contrast to textual context, visual images appear to have little if any impact on human acceptability ratings. However,",
      "summary_zh": "先前的研究已經探討了 deep neural networks (DNNs)，特別是 transformers，預測人類句子可接受度判斷的能力，包括獨立於上下文和在文件上下文中的情況。我們考慮了先前接觸視覺圖像（即 visual context）對人類和 large language models (LLMs) 這些判斷的影響。我們的結果表明，與 textual context 相比，視覺圖像對人類的可接受度評級似乎影響甚微（甚至沒有影響）。然而，",
      "title": "Predicting Sentence Acceptability Judgments in Multimodal Contexts",
      "title_zh": "在多模態情境中預測句子可接受度判斷"
    },
    {
      "arxiv_id": "2602.21042",
      "authors": [],
      "categories": [],
      "entities": [
        "01-ai"
      ],
      "first_seen_at": "2026-02-25T06:31:33.024449+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "OmniOCR: Generalist OCR for Ethnic Minority Languages",
          "url": "https://arxiv.org/abs/2602.21042"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "OmniOCR: Generalist OCR for Ethnic Minority Languages",
        "url": "https://arxiv.org/abs/2602.21042"
      },
      "published_at": "2026-02-24T16:02:49+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 2.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.55,
        "llm_relevance_score": 15.400000000000002,
        "recency_score": 0.9291006586937736,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 26.52910065869378
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21042",
      "summary": "Optical character recognition (OCR) has advanced rapidly with deep learning and multimodal models, yet most methods focus on well-resourced scripts such as Latin and Chinese. Ethnic minority languages remain underexplored due to complex writing systems, scarce annotations, and diverse historical and modern forms, making generalization in low-resource or zero-shot settings challenging. To address these challenges, we present OmniOCR, a universal framework for ethnic minority scripts. OmniOCR introduces Dynamic Low-Rank Adaptation (Dynamic LoRA) to allocate model capacity across layers and scripts, enabling effective adaptation while preserving knowledge.A sparsity regularization prunes redundant updates, ensuring compact and efficient adaptation without extra inference cost. Evaluations on TibetanMNIST, Shui, ancient Yi, and Dongba show that OmniOCR outperforms zero-shot foundation models and standard post training, achieving state-of-the-art accuracy with superior parameter efficiency, and compared with the state-of-the-art baseline models, it improves accuracy by 39%-66% on these four datasets. Code: https://github.com/AIGeeksGroup/OmniOCR.",
      "summary_zh": "光學字元識別 (OCR) 隨著深度學習和多模態模型的發展而迅速進步，但大多數方法都集中在資源豐富的文字上，例如拉丁文和中文。由於書寫系統複雜、註釋稀缺以及多樣化的歷史和現代形式，少數民族語言的研究仍然不足，這使得在低資源或零樣本 (zero-shot) 情況下實現泛化變得具有挑戰性。為了解決這些挑戰，我們提出了 OmniOCR，一個針對少數民族文字的通用框架。OmniOCR 引入了動態低秩適應 (Dynamic Low-Rank Adaptation, Dynamic LoRA)，用於在各層和文字之間分配模型容量，從而實現有效的適應同時保留知識。稀疏性正則化 (sparsity regularization) 剪除了冗餘更新，確保了緊湊且高效的適應，而不會增加推理成本。在 TibetanMNIST、Shui、ancient Yi 和 Dongba 上的評估表明，OmniOCR 優於零樣本基礎模型 (zero-shot foundation models) 和標準後訓練 (post training)，以卓越的參數效率實現了最先進的準確性，與最先進的基準模型相比，它在這些四個數據集上的準確性提高了 39% 至 66%。程式碼：https://github.com/AIGeeksGroup/OmniOCR。",
      "title": "OmniOCR: Generalist OCR for Ethnic Minority Languages",
      "title_zh": "OmniOCR：適用於少數民族語言的通用 OCR"
    },
    {
      "arxiv_id": "2602.21137",
      "authors": [
        "Joseph Raj Vishal",
        "Nagasiri Poluri",
        "Katha Naik",
        "Rutuja Patil",
        "Kashyap Hegde Kota",
        "Krishna Vinod",
        "Prithvi Jai Ramesh",
        "Mohammad Farhadi",
        "Yezhou Yang",
        "Bharatesh Chakravarthi"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.022572+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "UDVideoQA: A Traffic Video Question Answering Dataset for Multi-Object Spatio-Temporal Reasoning in Urban Dynamics",
          "url": "https://arxiv.org/abs/2602.21137"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "UDVideoQA: A Traffic Video Question Answering Dataset for Multi-Object Spatio-Temporal Reasoning in Urban Dynamics",
        "url": "https://arxiv.org/abs/2602.21137"
      },
      "published_at": "2026-02-24T17:33:12+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.65,
        "llm_relevance_score": 18.2,
        "recency_score": 0.9349506105724577,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 26.334950610572456
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21137",
      "summary": "Understanding the complex, multi-agent dynamics of urban traffic remains a fundamental challenge for video language models. This paper introduces Urban Dynamics VideoQA, a benchmark dataset that captures the unscripted real-world behavior of dynamic urban scenes. UDVideoQA is curated from 16 hours of traffic footage recorded at multiple city intersections under diverse traffic, weather, and lighting conditions. It employs an event-driven dynamic blur technique to ensure privacy preservation with",
      "summary_zh": "理解城市交通中複雜的多代理動態對於影片語言模型 (video language models) 而言仍然是一個基本挑戰。本文介紹了 Urban Dynamics VideoQA (UDVideoQA)，這是一個基準資料集，它捕捉了動態城市場景中非腳本化的真實世界行為。UDVideoQA 整理自多個城市交叉路口在不同交通、天氣和照明條件下錄製的 16 小時交通影片。它採用事件驅動的動態模糊技術 (event-driven dynamic blur technique) 來確保隱私保護。",
      "title": "UDVideoQA: A Traffic Video Question Answering Dataset for Multi-Object Spatio-Temporal Reasoning in Urban Dynamics",
      "title_zh": "UDVideoQA：一個用於城市動態中多物件時空推理的交通影片問答資料集"
    },
    {
      "arxiv_id": "2602.20972",
      "authors": [
        "Ming-Kun Xie",
        "Jia-Hao Xiao",
        "Zhiqiang Kou",
        "Zhongnian Li",
        "Gang Niu",
        "Masashi Sugiyama"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.026727+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "Are Multimodal Large Language Models Good Annotators for Image Tagging?",
          "url": "https://arxiv.org/abs/2602.20972"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "Are Multimodal Large Language Models Good Annotators for Image Tagging?",
        "url": "https://arxiv.org/abs/2602.20972"
      },
      "published_at": "2026-02-24T14:53:16+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.65,
        "llm_relevance_score": 18.2,
        "recency_score": 0.924624050953216,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 26.324624050953215
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20972",
      "summary": "Image tagging, a fundamental vision task, traditionally relies on human-annotated datasets to train multi-label classifiers, which incurs significant labor and costs. While Multimodal Large Language Models (MLLMs) offer promising potential to automate annotation, their capability to replace human annotators remains underexplored. This paper aims to analyze the gap between MLLM-generated and human annotations and to propose an effective solution that enables MLLM-based annotation to replace manua",
      "summary_zh": "圖像標註 (Image tagging) 作為一項基礎的視覺任務，傳統上依賴人工標註的數據集來訓練多標籤分類器 (multi-label classifiers)，這會產生顯著的人力和成本。儘管多模態大型語言模型 (Multimodal Large Language Models, MLLMs) 為自動化標註提供了有前景的潛力，但它們取代人類標註者的能力仍未被充分探索。本文旨在分析 MLLM 生成的標註與人類標註之間的差距，並提出一種有效的解決方案，使基於 MLLM 的標註能夠取代人工標註。",
      "title": "Are Multimodal Large Language Models Good Annotators for Image Tagging?",
      "title_zh": "多模態大型語言模型是圖像標註的好幫手嗎？"
    },
    {
      "arxiv_id": "2602.20853",
      "authors": [
        "Stefanie Schneider"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.029549+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "On the Explainability of Vision-Language Models in Art History",
          "url": "https://arxiv.org/abs/2602.20853"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "On the Explainability of Vision-Language Models in Art History",
        "url": "https://arxiv.org/abs/2602.20853"
      },
      "published_at": "2026-02-24T12:53:28+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.65,
        "llm_relevance_score": 18.2,
        "recency_score": 0.916963602052441,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 26.31696360205244
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20853",
      "summary": "Vision-Language Models (VLMs) transfer visual and textual data into a shared embedding space. In so doing, they enable a wide range of multimodal tasks, while also raising critical questions about the nature of machine 'understanding.' In this paper, we examine how Explainable Artificial Intelligence (XAI) methods can render the visual reasoning of a VLM - namely, CLIP - legible in art-historical contexts. To this end, we evaluate seven methods, combining zero-shot localization experiments with ",
      "summary_zh": "視覺-語言模型 (Vision-Language Models, VLMs) 將視覺和文本數據轉換為共享的嵌入空間 (embedding space)。透過這樣做，它們實現了廣泛的多模態任務，同時也引發了關於機器「理解」本質的關鍵問題。在本文中，我們探討了可解釋人工智慧 (Explainable Artificial Intelligence, XAI) 方法如何使 VLM (即 CLIP) 的視覺推理在藝術史背景下變得易於理解。為此，我們評估了七種方法，將零樣本定位實驗 (zero-shot localization experiments) 與 ",
      "title": "On the Explainability of Vision-Language Models in Art History",
      "title_zh": "論視覺-語言模型在藝術史中的可解釋性"
    },
    {
      "arxiv_id": "2602.20839",
      "authors": [
        "Niki Foteinopoulou",
        "Ignas Budvytis",
        "Stephan Liwicki"
      ],
      "categories": [
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:33.030163+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cv",
          "tier": 1,
          "title": "Training-Free Multi-Concept Image Editing",
          "url": "https://arxiv.org/abs/2602.20839"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cv",
        "tier": 1,
        "title": "Training-Free Multi-Concept Image Editing",
        "url": "https://arxiv.org/abs/2602.20839"
      },
      "published_at": "2026-02-24T12:27:51+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.65,
        "llm_relevance_score": 18.2,
        "recency_score": 0.9153338332935088,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 26.315333833293508
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20839",
      "summary": "Editing images with diffusion models without training remains challenging. While recent optimisation-based methods achieve strong zero-shot edits from text, they struggle to preserve identity or capture details that language alone cannot express. Many visual concepts such as facial structure, material texture, or object geometry are impossible to express purely through text prompts alone. To address this gap, we introduce a training-free framework for concept-based image editing, which unifies O",
      "summary_zh": "使用 diffusion models 在不進行訓練的情況下編輯圖像仍然具有挑戰性。儘管最近基於優化的方法實現了強大的零樣本編輯 (zero-shot edits)，但它們難以保留身份或捕捉單獨語言無法表達的細節。許多視覺概念，例如面部結構、材料紋理或物體幾何形狀，單純透過文本提示是無法表達的。為了解決這個問題，我們引入了一個免訓練 (training-free) 的概念基礎圖像編輯框架，該框架統一了 O",
      "title": "Training-Free Multi-Concept Image Editing",
      "title_zh": "免訓練多概念圖像編輯"
    }
  ],
  "radar": [
    {
      "arxiv_id": "2602.20804",
      "authors": [
        "Kale-ab Tessera",
        "Leonard Hinckeldey",
        "Riccardo Zamboni",
        "David Abel",
        "Amos Storkey"
      ],
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.404167+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Probing Dec-POMDP Reasoning in Cooperative MARL",
          "url": "https://arxiv.org/abs/2602.20804"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Probing Dec-POMDP Reasoning in Cooperative MARL",
        "url": "https://arxiv.org/abs/2602.20804"
      },
      "published_at": "2026-02-24T11:44:46+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.65,
        "llm_relevance_score": 18.2,
        "recency_score": 0.9125993403946678,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 26.31259934039467
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20804",
      "summary": "Cooperative multi-agent reinforcement learning (MARL) is typically framed as a decentralised partially observable Markov decision process (Dec-POMDP), a setting whose hardness stems from two key challenges: partial observability and decentralised coordination. Genuinely solving such tasks requires Dec-POMDP reasoning, where agents use history to infer hidden states and coordinate based on local information. Yet it remains unclear whether popular benchmarks actually demand this reasoning or permi",
      "summary_zh": "合作式 multi-agent reinforcement learning (MARL) 通常被視為一個 decentralised partially observable Markov decision process (Dec-POMDP)，這種設定的難度源於兩個主要挑戰：partial observability 和 decentralised coordination。真正解決這類任務需要 Dec-POMDP reasoning，其中 agents 使用歷史資訊來推斷隱藏狀態並基於本地資訊進行協調。然而，目前尚不清楚流行的 benchmarks 是否真正需要這種推理或允許...",
      "title": "Probing Dec-POMDP Reasoning in Cooperative MARL",
      "title_zh": "探究合作式 MARL 中的 Dec-POMDP 推理"
    },
    {
      "arxiv_id": "2602.20728",
      "authors": [
        "Chenyang Zhao",
        "Vinny Cahill",
        "Ivana Dusparic"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.273288+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback",
          "url": "https://arxiv.org/abs/2602.20728"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback",
        "url": "https://arxiv.org/abs/2602.20728"
      },
      "published_at": "2026-02-24T09:47:25+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.65,
        "llm_relevance_score": 18.2,
        "recency_score": 0.9051925107702102,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 26.305192510770212
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20728",
      "summary": "Reward design has been one of the central challenges for real world reinforcement learning (RL) deployment, especially in settings with multiple objectives. Preference-based RL offers an appealing alternative by learning from human preferences over pairs of behavioural outcomes. More recently, RL from AI feedback (RLAIF) has demonstrated that large language models (LLMs) can generate preference labels at scale, mitigating the reliance on human annotators. However, existing RLAIF work typically f",
      "summary_zh": "獎勵設計一直是現實世界 reinforcement learning (RL) 部署的核心挑戰之一，尤其是在多重目標的設定中。基於偏好的 RL 提供了一種吸引人的替代方案，透過學習人類對行為結果對的偏好。最近，來自 AI feedback 的 RL (RLAIF) 已證明 large language models (LLMs) 能夠大規模生成偏好標籤，減輕了對人類標註者的依賴。然而，現有的 RLAIF 工作通常...",
      "title": "Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback",
      "title_zh": "透過來自 AI Feedback 的 Reinforcement Learning 平衡城市交通控制中的多重目標"
    },
    {
      "arxiv_id": "2602.20749",
      "authors": [
        "Azrin Sultana",
        "Firoz Ahmed"
      ],
      "categories": [
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.037342+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Explicit Grammar Semantic Feature Fusion for Robust Text Classification",
          "url": "https://arxiv.org/abs/2602.20749"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Explicit Grammar Semantic Feature Fusion for Robust Text Classification",
        "url": "https://arxiv.org/abs/2602.20749"
      },
      "published_at": "2026-02-24T10:25:29+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.62,
        "llm_relevance_score": 17.36,
        "recency_score": 0.9075885695527945,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 25.467588569552795
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20749",
      "summary": "Natural Language Processing enables computers to understand human language by analysing and classifying text efficiently with deep-level grammatical and semantic features. Existing models capture features by learning from large corpora with transformer models, which are computationally intensive and unsuitable for resource-constrained environments. Therefore, our proposed study incorporates comprehensive grammatical rules alongside semantic information to build a robust, lightweight classificati",
      "summary_zh": "Natural Language Processing 透過有效分析和分類帶有深度語法和語義特徵的文本，使電腦能夠理解人類語言。現有模型透過從大型 corpora 中學習 transformer models 來捕獲特徵，但這些模型計算量大且不適用於資源受限的環境。因此，我們提出的研究將全面的語法規則與語義資訊結合，以建立一個魯棒、輕量級的分類...",
      "title": "Explicit Grammar Semantic Feature Fusion for Robust Text Classification",
      "title_zh": "顯式語法語義特徵融合以實現魯棒的文本分類"
    },
    {
      "arxiv_id": "2602.21082",
      "authors": [
        "Vishal Patil",
        "Shree Vaishnavi Bacha",
        "Revanth Yamani",
        "Yidan Sun",
        "Mayank Kejriwal"
      ],
      "categories": [
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.034047+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Beyond the Star Rating: A Scalable Framework for Aspect-Based Sentiment Analysis Using LLMs and Text Classification",
          "url": "https://arxiv.org/abs/2602.21082"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Beyond the Star Rating: A Scalable Framework for Aspect-Based Sentiment Analysis Using LLMs and Text Classification",
        "url": "https://arxiv.org/abs/2602.21082"
      },
      "published_at": "2026-02-24T16:45:17+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.6,
        "llm_relevance_score": 16.8,
        "recency_score": 0.9318446895449086,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 24.93184468954491
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21082",
      "summary": "Customer-provided reviews have become an important source of information for business owners and other customers alike. However, effectively analyzing millions of unstructured reviews remains challenging. While large language models (LLMs) show promise for natural language understanding, their application to large-scale review analysis has been limited by computational costs and scalability concerns. This study proposes a hybrid approach that uses LLMs for aspect identification while employing c",
      "summary_zh": "客戶提供的評論已成為企業主和其他客戶的重要資訊來源。然而，有效分析數百萬條非結構化評論仍然具有挑戰性。儘管 large language models (LLMs) 在 natural language understanding 方面展現出前景，但它們在大規模評論分析中的應用一直受到計算成本和可擴展性問題的限制。本研究提出了一種混合方法，該方法使用 LLMs 進行 aspect identification，同時採用...",
      "title": "Beyond the Star Rating: A Scalable Framework for Aspect-Based Sentiment Analysis Using LLMs and Text Classification",
      "title_zh": "超越星級評分：使用 LLMs 和文本分類的 Aspect-Based Sentiment Analysis 可擴展框架"
    },
    {
      "arxiv_id": "2602.20986",
      "authors": [
        "Thibault Formal",
        "Maxime Louis",
        "Hervé Déjean",
        "Stéphane Clinchant"
      ],
      "categories": [
        "cs.IR"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:37.769908+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ir",
          "tier": 1,
          "title": "Naver Labs Europe @ WSDM CUP | Multilingual Retrieval",
          "url": "https://arxiv.org/abs/2602.20986"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ir",
        "tier": 1,
        "title": "Naver Labs Europe @ WSDM CUP | Multilingual Retrieval",
        "url": "https://arxiv.org/abs/2602.20986"
      },
      "published_at": "2026-02-24T15:09:01+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.6,
        "llm_relevance_score": 16.8,
        "recency_score": 0.9256359117694568,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 24.925635911769458
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20986",
      "summary": "This report presents our participation to the WSDM Cup 2026 shared task on multilingual document retrieval from English queries. The task provides a challenging benchmark for cross-lingual generalization. It also provides a natural testbed for evaluating SPLARE, our recently proposed learned sparse retrieval model, which produces generalizable sparse latent representations and is particularly well suited to multilingual retrieval settings.\n  We evaluate five progressively enhanced runs, starting",
      "summary_zh": "本報告介紹了我們參加 WSDM Cup 2026 關於從英文查詢進行 multilingual document retrieval 的 shared task。該任務為 cross-lingual generalization 提供了一個具有挑戰性的 benchmark。它還為評估 SPLARE（我們最近提出的 learned sparse retrieval model，它產生 generalizable sparse latent representations 並特別適合 multilingual retrieval 設定）提供了一個天然的測試平台。我們評估了五個逐步增強的運行，從...",
      "title": "Naver Labs Europe @ WSDM CUP | Multilingual Retrieval",
      "title_zh": "Naver Labs Europe @ WSDM CUP | 多語言檢索"
    },
    {
      "arxiv_id": "2602.21136",
      "authors": [
        "David Anugraha",
        "Vishakh Padmakumar",
        "Diyi Yang"
      ],
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.263225+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery",
          "url": "https://arxiv.org/abs/2602.21136"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery",
        "url": "https://arxiv.org/abs/2602.21136"
      },
      "published_at": "2026-02-24T17:33:02+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.55,
        "llm_relevance_score": 15.400000000000002,
        "recency_score": 0.9349397894474577,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 23.53493978944746
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21136",
      "summary": "Qualitative insights from user experiences are critical for informing product and policy decisions, but collecting such data at scale is constrained by the time and availability of experts to conduct semi-structured interviews. Recent work has explored using large language models (LLMs) to automate interviewing, yet existing systems lack a principled mechanism for balancing systematic coverage of predefined topics with adaptive exploration, or the ability to pursue follow-ups, deep dives, and em",
      "summary_zh": "從使用者體驗中獲取的定性洞察對於制定產品和政策決策至關重要，但大規模收集此類數據受到專家進行 semi-structured interviews 的時間和可用性的限制。最近的研究探索了使用 large language models (LLMs) 來自動化訪談，然而，現有系統缺乏一個原則性的機制，來平衡預定義主題的系統性覆蓋與自適應探索，也缺乏追蹤、深入探討以及...",
      "title": "SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery",
      "title_zh": "SparkMe: 針對定性洞察發現的自適應半結構化訪談"
    },
    {
      "arxiv_id": "2602.20921",
      "authors": [
        "Jinshu Huang",
        "Mingfei Sun",
        "Chunlin Wu"
      ],
      "categories": [
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.402063+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "On the Generalization Behavior of Deep Residual Networks From a Dynamical System Perspective",
          "url": "https://arxiv.org/abs/2602.20921"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "On the Generalization Behavior of Deep Residual Networks From a Dynamical System Perspective",
        "url": "https://arxiv.org/abs/2602.20921"
      },
      "published_at": "2026-02-24T13:59:06+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.65,
        "llm_relevance_score": 18.2,
        "recency_score": 0.9211525423565767,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 0.0,
        "total_score": 22.321152542356575
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20921",
      "summary": "Deep neural networks (DNNs) have significantly advanced machine learning, with model depth playing a central role in their successes. The dynamical system modeling approach has recently emerged as a powerful framework, offering new mathematical insights into the structure and learning behavior of DNNs. In this work, we establish generalization error bounds for both discrete- and continuous-time residual networks (ResNets) by combining Rademacher complexity, flow maps of dynamical systems, and th",
      "summary_zh": "Deep neural networks (DNNs) 大幅推動了 machine learning 的發展，其中模型深度在其成功中扮演了核心角色。動態系統建模方法最近成為一個強大的框架，為 DNNs 的結構和學習行為提供了新的數學見解。在這項工作中，我們透過結合 Rademacher complexity、動態系統的 flow maps 以及...",
      "title": "On the Generalization Behavior of Deep Residual Networks From a Dynamical System Perspective",
      "title_zh": "從動態系統角度看 Deep Residual Networks 的泛化行為"
    },
    {
      "arxiv_id": "2602.20892",
      "authors": [
        "Seyed Himan Ghaderi",
        "Saeed Sarbazi Azad",
        "Mohammad Mehdi Jaziriyan",
        "Ahmad Akbari"
      ],
      "categories": [
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.036422+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "Exa-PSD: a new Persian sentiment analysis dataset on Twitter",
          "url": "https://arxiv.org/abs/2602.20892"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "Exa-PSD: a new Persian sentiment analysis dataset on Twitter",
        "url": "https://arxiv.org/abs/2602.20892"
      },
      "published_at": "2026-02-24T13:28:23+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.5,
        "llm_relevance_score": 14.0,
        "recency_score": 0.9191897243522531,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 22.119189724352253
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20892",
      "summary": "Today, Social networks such as Twitter are the most widely used platforms for communication of people. Analyzing this data has useful information to recognize the opinion of people in tweets. Sentiment analysis plays a vital role in NLP, which identifies the opinion of the individuals about a specific topic. Natural language processing in Persian has many challenges despite the adventure of strong language models. The datasets available in Persian are generally in special topics such as products",
      "summary_zh": "如今，Twitter 等 Social networks 是人們最廣泛使用的交流平台。分析這些數據有助於識別人們在 tweets 中的意見。Sentiment analysis 在 NLP 中扮演著至關重要的角色，它識別個人對特定主題的看法。儘管強大的 language models 不斷發展，波斯語的 Natural language processing 仍面臨許多挑戰。波斯語可用的 datasets 通常集中在特定主題，例如產品...",
      "title": "Exa-PSD: a new Persian sentiment analysis dataset on Twitter",
      "title_zh": "Exa-PSD: 一個新的 Twitter 波斯語情感分析資料集"
    },
    {
      "arxiv_id": null,
      "authors": [
        "Bruno Pistone"
      ],
      "categories": [
        "Amazon SageMaker AI",
        "Artificial Intelligence",
        "Foundation models",
        "Generative AI",
        "Technical How-to",
        "AIML",
        "Amazon Machine Learning",
        "Amazon SageMaker",
        "AWS Deep Learning",
        "distributed training",
        "Hugging Face"
      ],
      "entities": [
        "aws"
      ],
      "first_seen_at": "2026-02-25T06:31:27.626522+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "blog",
          "source_id": "aws-ml-blog",
          "tier": 0,
          "title": "Train CodeFu-7B with veRL and Ray on Amazon SageMaker Training jobs",
          "url": "https://aws.amazon.com/blogs/machine-learning/train-codefu-7b-with-verl-and-ray-on-amazon-sagemaker-training-jobs"
        }
      ],
      "primary_link": {
        "link_type": "blog",
        "source_id": "aws-ml-blog",
        "tier": 0,
        "title": "Train CodeFu-7B with veRL and Ray on Amazon SageMaker Training jobs",
        "url": "https://aws.amazon.com/blogs/machine-learning/train-codefu-7b-with-verl-and-ray-on-amazon-sagemaker-training-jobs"
      },
      "published_at": "2026-02-24T15:46:50+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 2.0,
        "kind_score": 1.5,
        "llm_raw_score": 0.35,
        "llm_relevance_score": 9.799999999999999,
        "recency_score": 0.9280699720895667,
        "semantic_score": 0.0,
        "tier_score": 3.0,
        "topic_score": 4.0,
        "total_score": 21.228069972089564
      },
      "section": null,
      "source_name": "AWS Machine Learning Blog",
      "story_id": "fallback:bb52a5bca4fe6d16",
      "summary": "In this post, we demonstrate how to train CodeFu-7B, a specialized 7-billion parameter model for competitive programming, using Group Relative Policy Optimization (GRPO) with veRL, a flexible and efficient training library for large language models (LLMs) that enables straightforward extension of diverse RL algorithms and seamless integration with existing LLM infrastructure, within a distributed Ray cluster managed by SageMaker training jobs. We walk through the complete implementation, covering data preparation, distributed training setup, and comprehensive observability, showcasing how this unified approach delivers both computational scale and developer experience for sophisticated RL training workloads.",
      "summary_zh": "在這篇文章中，我們展示了如何使用 Group Relative Policy Optimization (GRPO) 配合 veRL（一個靈活高效的 large language models (LLMs) 訓練函式庫，它能直接擴展多樣的 RL algorithms 並與現有的 LLM infrastructure 無縫整合），在由 SageMaker training jobs 管理的分布式 Ray cluster 中，訓練 CodeFu-7B 這一專為 competitive programming 設計的 7-billion parameter model。我們將完整地闡述實作過程，涵蓋數據準備、分布式訓練設置和全面的 observability，展示這種統一方法如何為複雜的 RL training workloads 提供計算規模和開發者體驗。",
      "title": "Train CodeFu-7B with veRL and Ray on Amazon SageMaker Training jobs",
      "title_zh": "使用 veRL 和 Ray 在 Amazon SageMaker Training jobs 上訓練 CodeFu-7B"
    },
    {
      "arxiv_id": "2602.20947",
      "authors": [
        "Thorbjørn Mosekjær Iversen",
        "Zebin Duan",
        "Frederik Hagelskjær"
      ],
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.401174+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Estimation of Confidence Bounds in Binary Classification using Wilson Score Kernel Density Estimation",
          "url": "https://arxiv.org/abs/2602.20947"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Estimation of Confidence Bounds in Binary Classification using Wilson Score Kernel Density Estimation",
        "url": "https://arxiv.org/abs/2602.20947"
      },
      "published_at": "2026-02-24T14:31:28+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.55,
        "llm_relevance_score": 15.400000000000002,
        "recency_score": 0.9232253318958373,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 0.0,
        "total_score": 19.52322533189584
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20947",
      "summary": "The performance and ease of use of deep learning-based binary classifiers have improved significantly in recent years. This has opened up the potential for automating critical inspection tasks, which have traditionally only been trusted to be done manually. However, the application of binary classifiers in critical operations depends on the estimation of reliable confidence bounds such that system performance can be ensured up to a given statistical significance. We present Wilson Score Kernel D",
      "summary_zh": "近年來，基於 deep learning 的 binary classifiers 的性能和易用性顯著提升。這為自動化關鍵檢測任務帶來了潛力，這些任務傳統上僅被信任手動完成。然而，binary classifiers 在關鍵操作中的應用取決於可靠 Confidence Bounds 的估計，以確保系統性能達到給定的 statistical significance。我們提出了 Wilson Score Kernel D",
      "title": "Estimation of Confidence Bounds in Binary Classification using Wilson Score Kernel Density Estimation",
      "title_zh": "使用 Wilson Score Kernel Density Estimation 估計二元分類中的置信區間"
    },
    {
      "arxiv_id": "2602.21160",
      "authors": [
        "Mame Diarra Toure",
        "David A. Stephens"
      ],
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.AP",
        "stat.ME"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.395908+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Not Just How Much, But Where: Decomposing Epistemic Uncertainty into Per-Class Contributions",
          "url": "https://arxiv.org/abs/2602.21160"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Not Just How Much, But Where: Decomposing Epistemic Uncertainty into Per-Class Contributions",
        "url": "https://arxiv.org/abs/2602.21160"
      },
      "published_at": "2026-02-24T18:05:51+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.4,
        "llm_relevance_score": 11.200000000000001,
        "recency_score": 0.9370728863012012,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 3.75,
        "total_score": 19.0870728863012
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21160",
      "summary": "In safety-critical classification, the cost of failure is often asymmetric, yet Bayesian deep learning summarises epistemic uncertainty with a single scalar, mutual information (MI), that cannot distinguish whether a model's ignorance involves a benign or safety-critical class. We decompose MI into a per-class vector $C_k(x)=σ_k^{2}/(2μ_k)$, with $μ_k{=}\\mathbb{E}[p_k]$ and $σ_k^2{=}\\mathrm{Var}[p_k]$ across posterior samples. The decomposition follows from a second-order Taylor expansion of the",
      "summary_zh": "在安全關鍵的分類中，失敗的成本通常是不對稱的，然而 Bayesian deep learning 僅用單一 scalar 的 mutual information (MI) 來總結認知不確定性，無法區分模型的不確定性是涉及良性類別還是安全關鍵類別。我們將 MI 分解為一個 per-class vector $C_k(x)=σ_k^{2}/(2μ_k)$，其中 $μ_k{=}\\mathbb{E}[p_k]$ 和 $σ_k^2{=}\\mathrm{Var}[p_k]$ 是跨後驗樣本計算的。該分解是源於對",
      "title": "Not Just How Much, But Where: Decomposing Epistemic Uncertainty into Per-Class Contributions",
      "title_zh": "不僅是程度，更是位置：將認知不確定性分解為各類別的貢獻"
    },
    {
      "arxiv_id": "2602.21009",
      "authors": [
        "Kun Yuan",
        "Junyu Bi",
        "Daixuan Cheng",
        "Changfa Wu",
        "Shuwen Xiao",
        "Binbin Cao",
        "Jian Wu",
        "Yuning Jiang"
      ],
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.034896+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "HiSAC: Hierarchical Sparse Activation Compression for Ultra-long Sequence Modeling in Recommenders",
          "url": "https://arxiv.org/abs/2602.21009"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "HiSAC: Hierarchical Sparse Activation Compression for Ultra-long Sequence Modeling in Recommenders",
        "url": "https://arxiv.org/abs/2602.21009"
      },
      "published_at": "2026-02-24T15:28:58+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.35,
        "llm_relevance_score": 9.799999999999999,
        "recency_score": 0.926919191922485,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 17.926919191922487
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21009",
      "summary": "Modern recommender systems leverage ultra-long user behavior sequences to capture dynamic preferences, but end-to-end modeling is infeasible in production due to latency and memory constraints. While summarizing history via interest centers offers a practical alternative, existing methods struggle to (1) identify user-specific centers at appropriate granularity and (2) accurately assign behaviors, leading to quantization errors and loss of long-tail preferences. To alleviate these issues, we pro",
      "summary_zh": "現代推薦系統利用超長用戶行為序列來捕捉動態偏好，但由於延遲和記憶體限制，end-to-end 建模在生產環境中不可行。儘管透過興趣中心來總結歷史提供了一個實用的替代方案，現有方法難以 (1) 在適當的粒度上識別用戶特定的中心，以及 (2) 準確地分配行為，導致量化誤差和長尾偏好的損失。為了緩解這些問題，我們提",
      "title": "HiSAC: Hierarchical Sparse Activation Compression for Ultra-long Sequence Modeling in Recommenders",
      "title_zh": "HiSAC：用於推薦系統中超長序列建模的分層稀疏激活壓縮"
    },
    {
      "arxiv_id": "2602.20979",
      "authors": [
        "Mark Marron"
      ],
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.267106+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Toward an Agentic Infused Software Ecosystem",
          "url": "https://arxiv.org/abs/2602.20979"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Toward an Agentic Infused Software Ecosystem",
        "url": "https://arxiv.org/abs/2602.20979"
      },
      "published_at": "2026-02-24T15:01:29+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.35,
        "llm_relevance_score": 9.799999999999999,
        "recency_score": 0.9251517937001322,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 17.92515179370013
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20979",
      "summary": "Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the AI agents themselves, which in the past 5 years have moved from simple code completion and toward sophisticated independent development tasks, a trend which will only continue. The second pillar is the programming langua",
      "summary_zh": "充分利用 AI agents 在軟體開發中的能力，需要對軟體生態系統本身進行重新思考。為此，本文概述了一個 Agentic Infused Software Ecosystem (AISE) 的創建，它基於三個支柱。首先，當然是 AI agents 本身，在過去的五年中，它們已經從簡單的 code completion 轉向複雜的獨立開發任務，這種趨勢只會持續下去。第二個支柱是程式語言",
      "title": "Toward an Agentic Infused Software Ecosystem",
      "title_zh": "邁向代理融入的軟體生態系統"
    },
    {
      "arxiv_id": "2602.20859",
      "authors": [
        "Zirui He",
        "Huopu Zhang",
        "Yanguang Liu",
        "Sirui Wu",
        "Mengnan Du"
      ],
      "categories": [
        "cs.CL"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:32.036611+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-cl",
          "tier": 1,
          "title": "FinAnchor: Aligned Multi-Model Representations for Financial Prediction",
          "url": "https://arxiv.org/abs/2602.20859"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-cl",
        "tier": 1,
        "title": "FinAnchor: Aligned Multi-Model Representations for Financial Prediction",
        "url": "https://arxiv.org/abs/2602.20859"
      },
      "published_at": "2026-02-24T13:02:09+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.35,
        "llm_relevance_score": 9.799999999999999,
        "recency_score": 0.9175167063416262,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 17.917516706341626
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20859",
      "summary": "Financial prediction from long documents involves significant challenges, as actionable signals are often sparse and obscured by noise, and the optimal LLM for generating embeddings varies across tasks and time periods. In this paper, we propose FinAnchor(Financial Anchored Representations), a lightweight framework that integrates embeddings from multiple LLMs without fine-tuning the underlying models. FinAnchor addresses the incompatibility of feature spaces by selecting an anchor embedding spa",
      "summary_zh": "從長文件進行金融預測涉及重大挑戰，因為可操作的信號通常稀疏且被噪音遮蔽，並且用於生成 embeddings 的最佳 LLM 會因任務和時間段而異。在本文中，我們提出了 FinAnchor(Financial Anchored Representations)，這是一個輕量級框架，它整合了來自多個 LLM 的 embeddings，而無需 fine-tuning 底層模型。FinAnchor 透過選擇一個 anchor embedding spa",
      "title": "FinAnchor: Aligned Multi-Model Representations for Financial Prediction",
      "title_zh": "FinAnchor：用於金融預測的對齊多模型表示"
    },
    {
      "arxiv_id": "2602.20730",
      "authors": [
        "Zhenxing Xu",
        "Zeyuan Ma",
        "Weidong Bao",
        "Hui Yan",
        "Yan Zheng",
        "Ji Wang"
      ],
      "categories": [
        "cs.LG"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:30.405757+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-lg",
          "tier": 1,
          "title": "Rethink Efficiency Side of Neural Combinatorial Solver: An Offline and Self-Play Paradigm",
          "url": "https://arxiv.org/abs/2602.20730"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-lg",
        "tier": 1,
        "title": "Rethink Efficiency Side of Neural Combinatorial Solver: An Offline and Self-Play Paradigm",
        "url": "https://arxiv.org/abs/2602.20730"
      },
      "published_at": "2026-02-24T09:53:24+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.35,
        "llm_relevance_score": 9.799999999999999,
        "recency_score": 0.9055687047904843,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 17.905568704790483
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20730",
      "summary": "We propose ECO, a versatile learning paradigm that enables efficient offline self-play for Neural Combinatorial Optimization (NCO). ECO addresses key limitations in the field through: 1) Paradigm Shift: Moving beyond inefficient online paradigms, we introduce a two-phase offline paradigm consisting of supervised warm-up and iterative Direct Preference Optimization (DPO); 2) Architecture Shift: We deliberately design a Mamba-based architecture to further enhance the efficiency in the offline para",
      "summary_zh": "我們提出了 ECO，這是一個多功能的學習範式，能為 Neural Combinatorial Optimization (NCO) 實現高效的離線 self-play。ECO 透過以下方式解決了該領域的關鍵限制：1) Paradigm Shift：超越低效的 online 範式，我們引入了一個兩階段的 offline 範式，包括 supervised warm-up 和迭代的 Direct Preference Optimization (DPO)；2) Architecture Shift：我們特意設計了一個 Mamba-based 架構，以在 offline 範式中進一步提升效率",
      "title": "Rethink Efficiency Side of Neural Combinatorial Solver: An Offline and Self-Play Paradigm",
      "title_zh": "重新思考神經組合求解器的效率面向：一種離線與自博弈範式"
    },
    {
      "arxiv_id": null,
      "authors": [
        "Traci Lim"
      ],
      "categories": [
        "Amazon Bedrock",
        "Artificial Intelligence"
      ],
      "entities": [
        "anthropic",
        "aws"
      ],
      "first_seen_at": "2026-02-25T06:31:27.627009+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "blog",
          "source_id": "aws-ml-blog",
          "tier": 0,
          "title": "Global cross-Region inference for latest Anthropic Claude Opus, Sonnet and Haiku models on Amazon Bedrock in Thailand, Malaysia, Singapore, Indonesia, and Taiwan",
          "url": "https://aws.amazon.com/blogs/machine-learning/global-cross-region-inference-for-latest-anthropic-claude-opus-sonnet-and-haiku-models-on-amazon-bedrock-in-thailand-malaysia-singapore-indonesia-and-taiwan"
        }
      ],
      "primary_link": {
        "link_type": "blog",
        "source_id": "aws-ml-blog",
        "tier": 0,
        "title": "Global cross-Region inference for latest Anthropic Claude Opus, Sonnet and Haiku models on Amazon Bedrock in Thailand, Malaysia, Singapore, Indonesia, and Taiwan",
        "url": "https://aws.amazon.com/blogs/machine-learning/global-cross-region-inference-for-latest-anthropic-claude-opus-sonnet-and-haiku-models-on-amazon-bedrock-in-thailand-malaysia-singapore-indonesia-and-taiwan"
      },
      "published_at": "2026-02-24T15:38:22+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 4.0,
        "kind_score": 1.5,
        "llm_raw_score": 0.15,
        "llm_relevance_score": 4.2,
        "recency_score": 0.9275244617046063,
        "semantic_score": 0.0,
        "tier_score": 3.0,
        "topic_score": 4.0,
        "total_score": 17.627524461704606
      },
      "section": null,
      "source_name": "AWS Machine Learning Blog",
      "story_id": "fallback:e6cfe5e86bdcce2c",
      "summary": "In this post, we are exciting to announce availability of Global CRIS for customers in Thailand, Malaysia, Singapore, Indonesia, and Taiwan and give a walkthrough of technical implementation steps, and cover quota management best practices to maximize the value of your AI Inference deployments. We also provide guidance on best practices for production deployments.",
      "summary_zh": "在這篇文章中，我們很高興地宣布為泰國、馬來西亞、新加坡、印尼和台灣的客戶推出 Global CRIS，並逐步介紹技術實施步驟，同時涵蓋配額管理最佳實踐，以最大化您的 AI Inference 部署價值。我們也提供了生產部署的最佳實踐指南。",
      "title": "Global cross-Region inference for latest Anthropic Claude Opus, Sonnet and Haiku models on Amazon Bedrock in Thailand, Malaysia, Singapore, Indonesia, and Taiwan",
      "title_zh": "在泰國、馬來西亞、新加坡、印尼和台灣，於 Amazon Bedrock 上為最新的 Anthropic Claude Opus, Sonnet 和 Haiku 模型提供全球跨區域推論"
    },
    {
      "arxiv_id": null,
      "authors": [
        "Hossam Basudan"
      ],
      "categories": [
        "Amazon Bedrock",
        "Announcements",
        "Artificial Intelligence"
      ],
      "entities": [
        "anthropic",
        "aws"
      ],
      "first_seen_at": "2026-02-25T06:31:27.627235+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "blog",
          "source_id": "aws-ml-blog",
          "tier": 0,
          "title": "Introducing Amazon Bedrock global cross-Region inference for Anthropic’s Claude models in the Middle East Regions (UAE and Bahrain)",
          "url": "https://aws.amazon.com/blogs/machine-learning/introducing-amazon-bedrock-global-cross-region-inference-for-anthropics-claude-models-in-the-middle-east-regions"
        }
      ],
      "primary_link": {
        "link_type": "blog",
        "source_id": "aws-ml-blog",
        "tier": 0,
        "title": "Introducing Amazon Bedrock global cross-Region inference for Anthropic’s Claude models in the Middle East Regions (UAE and Bahrain)",
        "url": "https://aws.amazon.com/blogs/machine-learning/introducing-amazon-bedrock-global-cross-region-inference-for-anthropics-claude-models-in-the-middle-east-regions"
      },
      "published_at": "2026-02-24T15:33:51+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 4.0,
        "kind_score": 1.5,
        "llm_raw_score": 0.15,
        "llm_relevance_score": 4.2,
        "recency_score": 0.927233582407249,
        "semantic_score": 0.0,
        "tier_score": 3.0,
        "topic_score": 4.0,
        "total_score": 17.62723358240725
      },
      "section": null,
      "source_name": "AWS Machine Learning Blog",
      "story_id": "fallback:fd7b0ba93aa214c1",
      "summary": "We’re excited to announce the availability of Anthropic’s Claude Opus 4.6, Claude Sonnet 4.6, Claude Opus 4.5, Claude Sonnet 4.5, and Claude Haiku 4.5 through Amazon Bedrock global cross-Region inference for customers operating in the Middle East. In this post, we guide you through the capabilities of each Anthropic Claude model variant, the key advantages of global cross-Region inference including improved resilience, real-world use cases you can implement, and a code example to help you start building generative AI applications immediately.",
      "summary_zh": "我們很高興地宣布，透過 Amazon Bedrock 全球跨區域推論，Anthropic 的 Claude Opus 4.6, Claude Sonnet 4.6, Claude Opus 4.5, Claude Sonnet 4.5 和 Claude Haiku 4.5 已可供在中東地區營運的客戶使用。在這篇文章中，我們將引導您了解每種 Anthropic Claude 模型變體的性能，全球跨區域推論的主要優勢，包括改進的韌性，您可以實施的實際應用案例，以及一個程式碼範例，幫助您立即開始建構生成式 AI 應用程式。",
      "title": "Introducing Amazon Bedrock global cross-Region inference for Anthropic’s Claude models in the Middle East Regions (UAE and Bahrain)",
      "title_zh": "介紹 Amazon Bedrock 在中東地區（阿拉伯聯合大公國和巴林）為 Anthropic 的 Claude 模型提供全球跨區域推論"
    },
    {
      "arxiv_id": "2602.21072",
      "authors": [
        "Zhangjie Xia",
        "Yu Yang",
        "Pan Xu"
      ],
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.264439+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Localized Dynamics-Aware Domain Adaption for Off-Dynamics Offline Reinforcement Learning",
          "url": "https://arxiv.org/abs/2602.21072"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Localized Dynamics-Aware Domain Adaption for Off-Dynamics Offline Reinforcement Learning",
        "url": "https://arxiv.org/abs/2602.21072"
      },
      "published_at": "2026-02-24T16:32:50+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.35,
        "llm_relevance_score": 9.799999999999999,
        "recency_score": 0.9310393803356974,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 3.45,
        "total_score": 17.381039380335697
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21072",
      "summary": "Off-dynamics offline reinforcement learning (RL) aims to learn a policy for a target domain using limited target data and abundant source data collected under different transition dynamics. Existing methods typically address dynamics mismatch either globally over the state space or via pointwise data filtering; these approaches can miss localized cross-domain similarities or incur high computational cost. We propose Localized Dynamics-Aware Domain Adaptation (LoDADA), which exploits localized dy",
      "summary_zh": "Off-dynamics 離線強化學習 (RL) 旨在利用有限的目標數據和在不同過渡動態下收集的大量源數據，為目標領域學習策略。現有方法通常透過在狀態空間上全局處理或點式數據過濾來解決動態不匹配問題；這些方法可能會錯過局部跨領域相似性或產生高昂的計算成本。我們提出了局部動態感知領域適應 (LoDADA)，它利用局部動態。",
      "title": "Localized Dynamics-Aware Domain Adaption for Off-Dynamics Offline Reinforcement Learning",
      "title_zh": "適用於 Off-Dynamics 離線強化學習的局部動態感知領域適應"
    },
    {
      "arxiv_id": "2602.20812",
      "authors": [
        "Jia-Rui Lin",
        "Yun-Hong Cai",
        "Xiang-Rui Ni",
        "Shaojie Zhou",
        "Peng Pan"
      ],
      "categories": [
        "cs.AI"
      ],
      "entities": [
        "qwen"
      ],
      "first_seen_at": "2026-02-25T06:31:29.270642+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "arxiv-cs-ai",
          "tier": 1,
          "title": "Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset",
          "url": "https://arxiv.org/abs/2602.20812"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "arxiv-cs-ai",
        "tier": 1,
        "title": "Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset",
        "url": "https://arxiv.org/abs/2602.20812"
      },
      "published_at": "2026-02-24T11:51:21+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 2.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.25,
        "llm_relevance_score": 7.0,
        "recency_score": 0.9130166542287629,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 17.113016654228765
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20812",
      "summary": "As the construction industry advances toward digital transformation, BIM (Building Information Modeling)-based design has become a key driver supporting intelligent construction. Despite Large Language Models (LLMs) have shown potential in promoting BIM-based design, the lack of specific datasets and LLM evaluation benchmarks has significantly hindered the performance of LLMs. Therefore, this paper addresses this gap by proposing: 1) an evaluation benchmark for BIM-based design together with cor",
      "summary_zh": "隨著建築產業邁向數位轉型，BIM (Building Information Modeling)-based 設計已成為支援智慧建造的關鍵驅動力。儘管大型語言模型 (LLMs) 在推動 BIM-based 設計方面展現了潛力，但缺乏特定數據集和 LLM 評估基準已嚴重阻礙了 LLMs 的性能。因此，本文透過提出以下方案來解決這個問題：1) 一個用於 BIM-based 設計的評估基準，以及相應的。",
      "title": "Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset",
      "title_zh": "Qwen-BIM：開發用於 BIM-based 設計的大型語言模型，具備特定領域的基準和數據集"
    },
    {
      "arxiv_id": null,
      "authors": [
        "Clement Perrot"
      ],
      "categories": [
        "Amazon SageMaker",
        "Amazon SageMaker AI",
        "Artificial Intelligence",
        "Customer Solutions"
      ],
      "entities": [
        "aws"
      ],
      "first_seen_at": "2026-02-25T06:31:27.626780+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "blog",
          "source_id": "aws-ml-blog",
          "tier": 0,
          "title": "Generate structured output from LLMs with Dottxt Outlines in AWS",
          "url": "https://aws.amazon.com/blogs/machine-learning/generate-structured-output-from-llms-with-dottxt-outlines-in-aws"
        }
      ],
      "primary_link": {
        "link_type": "blog",
        "source_id": "aws-ml-blog",
        "tier": 0,
        "title": "Generate structured output from LLMs with Dottxt Outlines in AWS",
        "url": "https://aws.amazon.com/blogs/machine-learning/generate-structured-output-from-llms-with-dottxt-outlines-in-aws"
      },
      "published_at": "2026-02-24T15:42:34+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 0.0,
        "entity_score": 2.0,
        "kind_score": 1.5,
        "llm_raw_score": 0.2,
        "llm_relevance_score": 5.6000000000000005,
        "recency_score": 0.9277950291284347,
        "semantic_score": 0.0,
        "tier_score": 3.0,
        "topic_score": 3.75,
        "total_score": 16.777795029128434
      },
      "section": null,
      "source_name": "AWS Machine Learning Blog",
      "story_id": "fallback:c46101761e991db6",
      "summary": "This post explores the implementation of Dottxt’s Outlines framework as a practical approach to implementing structured outputs using AWS Marketplace in Amazon SageMaker.",
      "summary_zh": "這篇文章探討了在 Amazon SageMaker 中使用 AWS Marketplace，將 Dottxt 的 Outlines 框架實施為一種實作結構化輸出的實用方法。",
      "title": "Generate structured output from LLMs with Dottxt Outlines in AWS",
      "title_zh": "在 AWS 中使用 Dottxt Outlines 從 LLMs 生成結構化輸出"
    }
  ],
  "run_date": "2026-02-25",
  "run_id": "34c33285-72cc-473c-8c87-375a9a285bd5",
  "run_info": {
    "error_summary": null,
    "finished_at": "2026-02-25T09:53:45.933740+00:00",
    "items_total": 286,
    "run_id": "34c33285-72cc-473c-8c87-375a9a285bd5",
    "started_at": "2026-02-25T09:20:36.490131+00:00",
    "stories_total": 193,
    "success": true
  },
  "sources_status": [
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Agents",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-agents",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Alignment",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-alignment",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Efficiency",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-efficiency",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Evaluation",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-evaluation",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Interpretability",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-interpretability",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API LLM",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-llm",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Multimodal",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-multimodal",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Reasoning",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-reasoning",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Retrieval",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-retrieval",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Reinforcement Learning",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-rl",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv API Safety",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-api-safety",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 5,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.AI",
      "newest_item_date": "2026-02-24T18:59:30+00:00",
      "reason_code": "FETCH_PARSE_OK_HAS_UPDATED",
      "reason_text": "Fetch and parse succeeded; items updated.",
      "remediation_hint": null,
      "source_id": "arxiv-cs-ai",
      "status": "HAS_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 1,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.CL",
      "newest_item_date": "2026-02-24T18:57:33+00:00",
      "reason_code": "FETCH_PARSE_OK_HAS_UPDATED",
      "reason_text": "Fetch and parse succeeded; items updated.",
      "remediation_hint": null,
      "source_id": "arxiv-cs-cl",
      "status": "HAS_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.CR",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-cs-cr",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 4,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.CV",
      "newest_item_date": "2026-02-24T18:59:30+00:00",
      "reason_code": "FETCH_PARSE_OK_HAS_UPDATED",
      "reason_text": "Fetch and parse succeeded; items updated.",
      "remediation_hint": null,
      "source_id": "arxiv-cs-cv",
      "status": "HAS_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.HC",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "arxiv-cs-hc",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.IR",
      "newest_item_date": "2026-02-24T18:57:33+00:00",
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "arxiv-cs-ir",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 2,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.LG",
      "newest_item_date": "2026-02-24T18:59:30+00:00",
      "reason_code": "FETCH_PARSE_OK_HAS_UPDATED",
      "reason_text": "Fetch and parse succeeded; items updated.",
      "remediation_hint": null,
      "source_id": "arxiv-cs-lg",
      "status": "HAS_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.MA",
      "newest_item_date": "2026-02-24T17:49:56+00:00",
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "arxiv-cs-ma",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.RO",
      "newest_item_date": "2026-02-24T18:58:11+00:00",
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "arxiv-cs-ro",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv cs.SE",
      "newest_item_date": "2026-02-24T16:35:20+00:00",
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "arxiv-cs-se",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "arxiv_api",
      "name": "arXiv stat.ML",
      "newest_item_date": "2026-02-24T18:46:46+00:00",
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "arxiv-stat-ml",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "rss_atom",
      "name": "AWS Machine Learning Blog",
      "newest_item_date": "2026-02-24T18:22:26+00:00",
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "aws-ml-blog",
      "status": "NO_UPDATE",
      "tier": 0
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "rss_atom",
      "name": "DeepMind Blog",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "deepmind-blog",
      "status": "NO_UPDATE",
      "tier": 0
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "rss_atom",
      "name": "Google AI Blog",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "google-ai-blog",
      "status": "NO_UPDATE",
      "tier": 0
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face 01.AI (Yi)",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-01-ai",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face Cohere",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-cohere",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 14,
      "last_fetch_status_code": null,
      "method": "hf_daily_papers",
      "name": "Hugging Face Daily Papers",
      "newest_item_date": "2026-02-24T18:59:30+00:00",
      "reason_code": "FETCH_PARSE_OK_HAS_UPDATED",
      "reason_text": "Fetch and parse succeeded; items updated.",
      "remediation_hint": null,
      "source_id": "hf-daily-papers",
      "status": "HAS_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face DeepSeek AI",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-deepseek-ai",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face Google",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-google",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face Meta Llama",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-meta-llama",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face Microsoft",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-microsoft",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 2,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face Mistral AI",
      "newest_item_date": "2026-02-25T08:50:48+00:00",
      "reason_code": "FETCH_PARSE_OK_HAS_NEW",
      "reason_text": "Fetch and parse succeeded; new items found.",
      "remediation_hint": null,
      "source_id": "hf-mistralai",
      "status": "HAS_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face OpenAI",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-openai",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face Qwen",
      "newest_item_date": "2026-02-25T02:43:25+00:00",
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-qwen",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "hf_org",
      "name": "Hugging Face Stability AI",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "hf-stabilityai",
      "status": "NO_UPDATE",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "rss_atom",
      "name": "Meta AI Blog",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "meta-ai-blog",
      "status": "FETCH_FAILED",
      "tier": 0
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "rss_atom",
      "name": "Microsoft Research Blog",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "microsoft-research-blog",
      "status": "NO_UPDATE",
      "tier": 0
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "rss_atom",
      "name": "NVIDIA AI Blog",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "nvidia-ai-blog",
      "status": "NO_UPDATE",
      "tier": 0
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "rss_atom",
      "name": "OpenAI Blog",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "openai-blog",
      "status": "NO_UPDATE",
      "tier": 0
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "papers_with_code",
      "name": "Papers With Code",
      "newest_item_date": null,
      "reason_code": "FETCH_NETWORK_ERROR",
      "reason_text": "Network error during fetch.",
      "remediation_hint": "Check network connectivity and DNS resolution.",
      "source_id": "papers-with-code",
      "status": "FETCH_FAILED",
      "tier": 1
    },
    {
      "category": "other",
      "items_new": 0,
      "items_updated": 0,
      "last_fetch_status_code": null,
      "method": "rss_atom",
      "name": "Sebastian Raschka Blog",
      "newest_item_date": null,
      "reason_code": "FETCH_PARSE_OK_NO_DELTA",
      "reason_text": "Fetch and parse succeeded; no changes since last run.",
      "remediation_hint": null,
      "source_id": "sebastian-raschka-blog",
      "status": "NO_UPDATE",
      "tier": 0
    }
  ],
  "top5": [
    {
      "arxiv_id": "2602.21193",
      "authors": [],
      "categories": [],
      "entities": [
        "nvidia",
        "huggingface",
        "qwen"
      ],
      "first_seen_at": "2026-02-25T06:31:32.033083+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "On Data Engineering for Scaling LLM Terminal Capabilities",
          "url": "https://arxiv.org/abs/2602.21193"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "On Data Engineering for Scaling LLM Terminal Capabilities",
        "url": "https://arxiv.org/abs/2602.21193"
      },
      "published_at": "2026-02-24T18:51:04+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 6.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9400199631045041,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 38.940019963104504
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21193",
      "summary": "Despite rapid recent progress in the terminal capabilities of large language models, the training data strategies behind state-of-the-art terminal agents remain largely undisclosed. We address this gap through a systematic study of data engineering practices for terminal agents, making two key contributions: (1) Terminal-Task-Gen, a lightweight synthetic task generation pipeline that supports seed-based and skill-based task construction, and (2) a comprehensive analysis of data and training strategies, including filtering, curriculum learning, long context training, and scaling behavior. Our pipeline yields Terminal-Corpus, a large-scale open-source dataset for terminal tasks. Using this dataset, we train Nemotron-Terminal, a family of models initialized from Qwen3(8B, 14B, 32B) that achieve substantial gains on Terminal-Bench 2.0: Nemotron-Terminal-8B improves from 2.5% to 13.0% Nemotron-Terminal-14B improves from 4.0% to 20.2%, and Nemotron-Terminal-32B improves from 3.4% to 27.4%, matching the performance of significantly larger models. To accelerate research in this domain, we open-source our model checkpoints and most of our synthetic datasets at https://huggingface.co/collections/nvidia/nemotron-terminal.",
      "summary_zh": "儘管大型語言模型（LLM）的終端能力近期取得了快速進展，但最先進的終端代理（terminal agents）背後的訓練資料策略卻鮮為人知。我們透過對終端代理的資料工程實踐進行系統性研究來彌補這一空白，並做出了兩項關鍵貢獻：(1) Terminal-Task-Gen，一個輕量級的合成任務生成管線，支援基於種子（seed-based）和基於技能（skill-based）的任務建構；(2) 對資料和訓練策略的全面分析，包括過濾（filtering）、課程學習（curriculum learning）、長上下文訓練（long context training）和擴展行為（scaling behavior）。我們的管線產生了 Terminal-Corpus，一個用於終端任務的大規模開源資料集。利用這個資料集，我們訓練了 Nemotron-Terminal 系列模型，這些模型從 Qwen3 (8B, 14B, 32B) 初始化，並在 Terminal-Bench 2.0 上取得了顯著的提升：Nemotron-Terminal-8B 從 2.5% 提高到 13.0%，Nemotron-Terminal-14B 從 4.0% 提高到 20.2%，Nemotron-Terminal-32B 從 3.4% 提高到 27.4%，匹配了顯著更大的模型的性能。為了加速該領域的研究，我們在 https://huggingface.co/collections/nvidia/nemotron-terminal 開源了我們的模型檢查點和大部分合成資料集。",
      "title": "On Data Engineering for Scaling LLM Terminal Capabilities",
      "title_zh": "關於擴展 LLM 終端能力之資料工程"
    },
    {
      "arxiv_id": "2602.21196",
      "authors": [],
      "categories": [],
      "entities": [
        "huggingface"
      ],
      "first_seen_at": "2026-02-25T06:31:30.394739+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "Untied Ulysses: Memory-Efficient Context Parallelism via Headwise Chunking",
          "url": "https://arxiv.org/abs/2602.21196"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "Untied Ulysses: Memory-Efficient Context Parallelism via Headwise Chunking",
        "url": "https://arxiv.org/abs/2602.21196"
      },
      "published_at": "2026-02-24T18:54:39+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 2.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.9,
        "llm_relevance_score": 25.2,
        "recency_score": 0.940253909215883,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 36.34025390921588
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21196",
      "summary": "Efficiently processing long sequences with Transformer models usually requires splitting the computations across accelerators via context parallelism. The dominant approaches in this family of methods, such as Ring Attention or DeepSpeed Ulysses, enable scaling over the context dimension but do not focus on memory efficiency, which limits the sequence lengths they can support. More advanced techniques, such as Fully Pipelined Distributed Transformer or activation offloading, can further extend the possible context length at the cost of training throughput. In this paper, we present UPipe, a simple yet effective context parallelism technique that performs fine-grained chunking at the attention head level. This technique significantly reduces the activation memory usage of self-attention, breaking the activation memory barrier and unlocking much longer context lengths. Our approach reduces intermediate tensor memory usage in the attention layer by as much as 87.5% for 32B Transformers, while matching previous context parallelism techniques in terms of training speed. UPipe can support the context length of 5M tokens when training Llama3-8B on a single 8timesH100 node, improving upon prior methods by over 25%.",
      "summary_zh": "使用 Transformer 模型高效處理長序列通常需要透過上下文並行性（context parallelism）將計算分散到多個加速器上。此類方法中的主導方法，例如 Ring Attention 或 DeepSpeed Ulysses，雖然能夠在上下文維度上進行擴展，但並未著重於記憶體效率，這限制了它們所能支援的序列長度。更先進的技術，例如 Fully Pipelined Distributed Transformer 或 activation offloading，可以進一步延長可能的上下文長度，但代價是訓練吞吐量。在本文中，我們提出了 UPipe，一種簡單而有效的上下文並行技術，它在 attention head 層面執行細粒度分塊（fine-grained chunking）。這項技術顯著減少了自注意力（self-attention）的活化記憶體使用量，打破了活化記憶體瓶頸，並解鎖了更長的上下文長度。對於 32B 的 Transformers，我們的方法可將注意力層的內部張量記憶體使用量減少多達 87.5%，同時在訓練速度方面與先前的上下文並行技術相匹配。UPipe 在單個 8xH100 節點上訓練 Llama3-8B 時，可以支援 5M tokens 的上下文長度，比以前的方法提高了超過 25%。",
      "title": "Untied Ulysses: Memory-Efficient Context Parallelism via Headwise Chunking",
      "title_zh": "Untied Ulysses: 透過 Headwise Chunking 實現記憶體高效的上下文並行性"
    },
    {
      "arxiv_id": "2602.20945",
      "authors": [],
      "categories": [],
      "entities": [
        "qwen"
      ],
      "first_seen_at": "2026-02-25T06:31:29.268544+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "The Art of Efficient Reasoning: Data, Reward, and Optimization",
          "url": "https://arxiv.org/abs/2602.20945"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "The Art of Efficient Reasoning: Data, Reward, and Optimization",
        "url": "https://arxiv.org/abs/2602.20945"
      },
      "published_at": "2026-02-24T14:28:16+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 2.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.88,
        "llm_relevance_score": 24.64,
        "recency_score": 0.9230201935049703,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 35.76302019350497
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.20945",
      "summary": "Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward shaping with Reinforcement Learning (RL). In this paper, we systematically investigate the mechanics of efficient reasoning for LLMs. For comprehensive evaluation, we advocate for more fine-grained metrics, including length distribution conditioned on correctness and performance across a wide spectrum of token budgets ranging from 2k to 32k. First, we reveal that the training process follows a two-stage paradigm: length adaptation and reasoning refinement. After that, we conduct extensive experiments (about 0.2 million GPU hours) in a unified protocol, deconstructing training prompts and rollouts, reward shaping, and optimization strategies. In particular, a key finding is to train on relatively easier prompts, ensuring the density of positive reward signals and thus avoiding the length collapse. Meanwhile, the learned length bias can be generalized across domains. We distill all findings into valuable insights and practical guidelines, and further validate them across the Qwen3 series, ranging from 0.6B to 30B, demonstrating the robustness and generalization.",
      "summary_zh": "大型語言模型（LLMs）持續從擴展的 Chain-of-Thought (CoT) 推理中受益，但也因此面臨沉重的計算開銷。為了解決這個問題，高效推理旨在透過使用 Reinforcement Learning (RL) 的獎勵塑造（reward shaping）來鼓勵簡短而準確的思維軌跡。在本文中，我們系統性地研究了 LLMs 高效推理的機制。為了進行全面的評估，我們倡導使用更細粒度的指標，包括以正確性為條件的長度分佈，以及在 2k 到 32k tokens 預算範圍內的性能表現。首先，我們揭示了訓練過程遵循兩階段範式：長度適應（length adaptation）和推理精煉（reasoning refinement）。接著，我們在統一的協定下進行了大量的實驗（約 0.2 百萬 GPU 小時），解構了訓練提示（training prompts）和輸出（rollouts）、獎勵塑造以及優化策略。特別值得一提的關鍵發現是，在相對簡單的提示上進行訓練，可以確保正向獎勵訊號的密度，從而避免長度崩潰（length collapse）。同時，學習到的長度偏差可以跨領域泛化。我們將所有發現提煉成寶貴的見解和實用指南，並在 Qwen3 系列（從 0.6B 到 30B）中進一步驗證了它們的穩健性和泛化能力。",
      "title": "The Art of Efficient Reasoning: Data, Reward, and Optimization",
      "title_zh": "高效推理的藝術：資料、獎勵與優化"
    },
    {
      "arxiv_id": "2602.21201",
      "authors": [],
      "categories": [],
      "entities": [
        "deepmind"
      ],
      "first_seen_at": "2026-02-25T06:31:29.261038+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "Aletheia tackles FirstProof autonomously",
          "url": "https://arxiv.org/abs/2602.21201"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "Aletheia tackles FirstProof autonomously",
        "url": "https://arxiv.org/abs/2602.21201"
      },
      "published_at": "2026-02-24T18:56:10+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 2.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.85,
        "llm_relevance_score": 23.8,
        "recency_score": 0.9403529458036426,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 34.940352945803646
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21201",
      "summary": "We report the performance of Aletheia (Feng et al., 2026b), a mathematics research agent powered by Gemini 3 Deep Think, on the inaugural FirstProof challenge. Within the allowed timeframe of the challenge, Aletheia autonomously solved 6 problems (2, 5, 7, 8, 9, 10) out of 10 according to majority expert assessments; we note that experts were not unanimous on Problem 8 (only). For full transparency, we explain our interpretation of FirstProof and disclose details about our experiments as well as our evaluation. Raw prompts and outputs are available at https://github.com/google-deepmind/superhuman/tree/main/aletheia.",
      "summary_zh": "我們報告了 Aletheia（Feng et al., 2026b），一個由 Gemini 3 Deep Think 驅動的數學研究代理，在首屆 FirstProof 挑戰賽中的表現。在挑戰賽的允許時間範圍內，根據多數專家評估，Aletheia 自主解決了 10 個問題中的 6 個問題（2、5、7、8、9、10）；我們注意到專家對於問題 8 並非一致同意（僅此一問題）。為了完全透明，我們解釋了我們對 FirstProof 的理解，並披露了我們實驗和評估的詳細資訊。原始的提示（prompts）和輸出（outputs）可在 https://github.com/google-deepmind/superhuman/tree/main/aletheia 取得。",
      "title": "Aletheia tackles FirstProof autonomously",
      "title_zh": "Aletheia 自主應對 FirstProof"
    },
    {
      "arxiv_id": "2602.21204",
      "authors": [],
      "categories": [],
      "entities": [],
      "first_seen_at": "2026-02-25T06:31:29.260707+00:00",
      "github_release_url": null,
      "hf_metadata": null,
      "hf_model_id": null,
      "item_count": 1,
      "links": [
        {
          "link_type": "arxiv",
          "source_id": "hf-daily-papers",
          "tier": 1,
          "title": "Test-Time Training with KV Binding Is Secretly Linear Attention",
          "url": "https://arxiv.org/abs/2602.21204"
        }
      ],
      "primary_link": {
        "link_type": "arxiv",
        "source_id": "hf-daily-papers",
        "tier": 1,
        "title": "Test-Time Training with KV Binding Is Secretly Linear Attention",
        "url": "https://arxiv.org/abs/2602.21204"
      },
      "published_at": "2026-02-24T18:59:30+00:00",
      "scores": {
        "citation_score": 0.0,
        "cross_source_score": 1.0,
        "entity_score": 0.0,
        "kind_score": 1.2,
        "llm_raw_score": 0.9,
        "llm_relevance_score": 25.2,
        "recency_score": 0.9405706452923807,
        "semantic_score": 0.0,
        "tier_score": 2.0,
        "topic_score": 4.0,
        "total_score": 34.34057064529238
      },
      "section": null,
      "source_name": null,
      "story_id": "arxiv:2602.21204",
      "summary": "Test-time training (TTT) with KV binding as sequence modeling layer is commonly interpreted as a form of online meta-learning that memorizes a key-value mapping at test time. However, our analysis reveals multiple phenomena that contradict this memorization-based interpretation. Motivated by these findings, we revisit the formulation of TTT and show that a broad class of TTT architectures can be expressed as a form of learned linear attention operator. Beyond explaining previously puzzling model behaviors, this perspective yields multiple practical benefits: it enables principled architectural simplifications, admits fully parallel formulations that preserve performance while improving efficiency, and provides a systematic reduction of diverse TTT variants to a standard linear attention form. Overall, our results reframe TTT not as test-time memorization, but as learned linear attention with enhanced representational capacity.",
      "summary_zh": "將帶有 KV binding 作為序列建模層的 Test-Time Training (TTT) 通常被解釋為一種在測試時記憶鍵值映射（key-value mapping）的線上元學習形式。然而，我們的分析揭示了多個與這種基於記憶的解釋相矛盾的現象。受這些發現的啟發，我們重新審視了 TTT 的公式，並表明廣泛的 TTT 架構可以表示為一種習得的線性注意力操作子（learned linear attention operator）。除了解釋先前令人費解的模型行為之外，這種視角還帶來了多重實際好處：它實現了有原則的架構簡化，允許在保持性能的同時提高效率的完全並行公式，並提供了將多樣化的 TTT 變體系統性地歸約為標準線性注意力形式的方法。總體而言，我們的結果將 TTT 重新定義為具有增強表示能力的習得線性注意力，而非測試時記憶（test-time memorization）。",
      "title": "Test-Time Training with KV Binding Is Secretly Linear Attention",
      "title_zh": "帶有 KV Binding 的 Test-Time Training 實為線性注意力"
    }
  ]
}